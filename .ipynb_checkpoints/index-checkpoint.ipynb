{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ths notebook will perform an in-depth analysis of a churn dataset of a telco company. Each row includes user data ranging from 1 to 246 days in terms of account activation. \n",
    "\n",
    "This analysis will try to produce a model that both:\n",
    "\n",
    "1) Predicts whether a customer is likely to churn in the near future\n",
    "\n",
    "2) Identify the features that are more relevant when it comes to churn\n",
    "\n",
    "\n",
    "The notebook will be divided  into the following sections:\n",
    "\n",
    ".EDA\n",
    "\n",
    ".Baseline Modelling\n",
    "\n",
    ".Models Optimisations\n",
    "\n",
    ".Performance Evaluation\n",
    "\n",
    ".Findings and Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial EDA & Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer, OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score, f1_score, recall_score\n",
    "from sklearn.metrics import  roc_curve, confusion_matrix, precision_score\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3333 entries, 0 to 3332\n",
      "Data columns (total 21 columns):\n",
      "state                     3333 non-null object\n",
      "account length            3333 non-null int64\n",
      "area code                 3333 non-null int64\n",
      "phone number              3333 non-null object\n",
      "international plan        3333 non-null object\n",
      "voice mail plan           3333 non-null object\n",
      "number vmail messages     3333 non-null int64\n",
      "total day minutes         3333 non-null float64\n",
      "total day calls           3333 non-null int64\n",
      "total day charge          3333 non-null float64\n",
      "total eve minutes         3333 non-null float64\n",
      "total eve calls           3333 non-null int64\n",
      "total eve charge          3333 non-null float64\n",
      "total night minutes       3333 non-null float64\n",
      "total night calls         3333 non-null int64\n",
      "total night charge        3333 non-null float64\n",
      "total intl minutes        3333 non-null float64\n",
      "total intl calls          3333 non-null int64\n",
      "total intl charge         3333 non-null float64\n",
      "customer service calls    3333 non-null int64\n",
      "churn                     3333 non-null bool\n",
      "dtypes: bool(1), float64(8), int64(8), object(4)\n",
      "memory usage: 524.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# importing initial dataset\n",
    "df = pd.read_csv('data/bigml_59c28831336c6604c800002a.csv')\n",
    "\n",
    "# there are 3 types of data that are not numbers\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account length</th>\n",
       "      <th>area code</th>\n",
       "      <th>phone number</th>\n",
       "      <th>international plan</th>\n",
       "      <th>voice mail plan</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>total eve minutes</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>382-4657</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>371-7191</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>358-1921</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>375-9999</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>330-6626</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state  account length  area code phone number international plan  \\\n",
       "0    KS             128        415     382-4657                 no   \n",
       "1    OH             107        415     371-7191                 no   \n",
       "2    NJ             137        415     358-1921                 no   \n",
       "3    OH              84        408     375-9999                yes   \n",
       "4    OK              75        415     330-6626                yes   \n",
       "\n",
       "  voice mail plan  number vmail messages  total day minutes  total day calls  \\\n",
       "0             yes                     25              265.1              110   \n",
       "1             yes                     26              161.6              123   \n",
       "2              no                      0              243.4              114   \n",
       "3              no                      0              299.4               71   \n",
       "4              no                      0              166.7              113   \n",
       "\n",
       "   total day charge  total eve minutes  total eve calls  total eve charge  \\\n",
       "0             45.07              197.4               99             16.78   \n",
       "1             27.47              195.5              103             16.62   \n",
       "2             41.38              121.2              110             10.30   \n",
       "3             50.90               61.9               88              5.26   \n",
       "4             28.34              148.3              122             12.61   \n",
       "\n",
       "   total night minutes  total night calls  total night charge  \\\n",
       "0                244.7                 91               11.01   \n",
       "1                254.4                103               11.45   \n",
       "2                162.6                104                7.32   \n",
       "3                196.9                 89                8.86   \n",
       "4                186.9                121                8.41   \n",
       "\n",
       "   total intl minutes  total intl calls  total intl charge  \\\n",
       "0                10.0                 3               2.70   \n",
       "1                13.7                 3               3.70   \n",
       "2                12.2                 5               3.29   \n",
       "3                 6.6                 7               1.78   \n",
       "4                10.1                 3               2.73   \n",
       "\n",
       "   customer service calls  churn  \n",
       "0                       1  False  \n",
       "1                       1  False  \n",
       "2                       0  False  \n",
       "3                       2  False  \n",
       "4                       3  False  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account length</th>\n",
       "      <th>area code</th>\n",
       "      <th>phone number</th>\n",
       "      <th>international plan</th>\n",
       "      <th>voice mail plan</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>total eve minutes</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>382-4657</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>371-7191</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>358-1921</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>375-9999</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>330-6626</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3328</td>\n",
       "      <td>AZ</td>\n",
       "      <td>192</td>\n",
       "      <td>1</td>\n",
       "      <td>414-4276</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>156.2</td>\n",
       "      <td>77</td>\n",
       "      <td>26.55</td>\n",
       "      <td>215.5</td>\n",
       "      <td>126</td>\n",
       "      <td>18.32</td>\n",
       "      <td>279.1</td>\n",
       "      <td>83</td>\n",
       "      <td>12.56</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3329</td>\n",
       "      <td>WV</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>370-3271</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>231.1</td>\n",
       "      <td>57</td>\n",
       "      <td>39.29</td>\n",
       "      <td>153.4</td>\n",
       "      <td>55</td>\n",
       "      <td>13.04</td>\n",
       "      <td>191.3</td>\n",
       "      <td>123</td>\n",
       "      <td>8.61</td>\n",
       "      <td>9.6</td>\n",
       "      <td>4</td>\n",
       "      <td>2.59</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3330</td>\n",
       "      <td>RI</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>328-8230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180.8</td>\n",
       "      <td>109</td>\n",
       "      <td>30.74</td>\n",
       "      <td>288.8</td>\n",
       "      <td>58</td>\n",
       "      <td>24.55</td>\n",
       "      <td>191.9</td>\n",
       "      <td>91</td>\n",
       "      <td>8.64</td>\n",
       "      <td>14.1</td>\n",
       "      <td>6</td>\n",
       "      <td>3.81</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3331</td>\n",
       "      <td>CT</td>\n",
       "      <td>184</td>\n",
       "      <td>2</td>\n",
       "      <td>364-6381</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>213.8</td>\n",
       "      <td>105</td>\n",
       "      <td>36.35</td>\n",
       "      <td>159.6</td>\n",
       "      <td>84</td>\n",
       "      <td>13.57</td>\n",
       "      <td>139.2</td>\n",
       "      <td>137</td>\n",
       "      <td>6.26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3332</td>\n",
       "      <td>TN</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>400-4344</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>234.4</td>\n",
       "      <td>113</td>\n",
       "      <td>39.85</td>\n",
       "      <td>265.9</td>\n",
       "      <td>82</td>\n",
       "      <td>22.60</td>\n",
       "      <td>241.4</td>\n",
       "      <td>77</td>\n",
       "      <td>10.86</td>\n",
       "      <td>13.7</td>\n",
       "      <td>4</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3333 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     state  account length  area code phone number  international plan  \\\n",
       "0       KS             128          1     382-4657                   0   \n",
       "1       OH             107          1     371-7191                   0   \n",
       "2       NJ             137          1     358-1921                   0   \n",
       "3       OH              84          0     375-9999                   1   \n",
       "4       OK              75          1     330-6626                   1   \n",
       "...    ...             ...        ...          ...                 ...   \n",
       "3328    AZ             192          1     414-4276                   0   \n",
       "3329    WV              68          1     370-3271                   0   \n",
       "3330    RI              28          2     328-8230                   0   \n",
       "3331    CT             184          2     364-6381                   1   \n",
       "3332    TN              74          1     400-4344                   0   \n",
       "\n",
       "      voice mail plan  number vmail messages  total day minutes  \\\n",
       "0                   1                     25              265.1   \n",
       "1                   1                     26              161.6   \n",
       "2                   0                      0              243.4   \n",
       "3                   0                      0              299.4   \n",
       "4                   0                      0              166.7   \n",
       "...               ...                    ...                ...   \n",
       "3328                1                     36              156.2   \n",
       "3329                0                      0              231.1   \n",
       "3330                0                      0              180.8   \n",
       "3331                0                      0              213.8   \n",
       "3332                1                     25              234.4   \n",
       "\n",
       "      total day calls  total day charge  total eve minutes  total eve calls  \\\n",
       "0                 110             45.07              197.4               99   \n",
       "1                 123             27.47              195.5              103   \n",
       "2                 114             41.38              121.2              110   \n",
       "3                  71             50.90               61.9               88   \n",
       "4                 113             28.34              148.3              122   \n",
       "...               ...               ...                ...              ...   \n",
       "3328               77             26.55              215.5              126   \n",
       "3329               57             39.29              153.4               55   \n",
       "3330              109             30.74              288.8               58   \n",
       "3331              105             36.35              159.6               84   \n",
       "3332              113             39.85              265.9               82   \n",
       "\n",
       "      total eve charge  total night minutes  total night calls  \\\n",
       "0                16.78                244.7                 91   \n",
       "1                16.62                254.4                103   \n",
       "2                10.30                162.6                104   \n",
       "3                 5.26                196.9                 89   \n",
       "4                12.61                186.9                121   \n",
       "...                ...                  ...                ...   \n",
       "3328             18.32                279.1                 83   \n",
       "3329             13.04                191.3                123   \n",
       "3330             24.55                191.9                 91   \n",
       "3331             13.57                139.2                137   \n",
       "3332             22.60                241.4                 77   \n",
       "\n",
       "      total night charge  total intl minutes  total intl calls  \\\n",
       "0                  11.01                10.0                 3   \n",
       "1                  11.45                13.7                 3   \n",
       "2                   7.32                12.2                 5   \n",
       "3                   8.86                 6.6                 7   \n",
       "4                   8.41                10.1                 3   \n",
       "...                  ...                 ...               ...   \n",
       "3328               12.56                 9.9                 6   \n",
       "3329                8.61                 9.6                 4   \n",
       "3330                8.64                14.1                 6   \n",
       "3331                6.26                 5.0                10   \n",
       "3332               10.86                13.7                 4   \n",
       "\n",
       "      total intl charge  customer service calls  churn  \n",
       "0                  2.70                       1  False  \n",
       "1                  3.70                       1  False  \n",
       "2                  3.29                       0  False  \n",
       "3                  1.78                       2  False  \n",
       "4                  2.73                       3  False  \n",
       "...                 ...                     ...    ...  \n",
       "3328               2.67                       2  False  \n",
       "3329               2.59                       3  False  \n",
       "3330               3.81                       2  False  \n",
       "3331               1.35                       2  False  \n",
       "3332               3.70                       0  False  \n",
       "\n",
       "[3333 rows x 21 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting all non-numerical values apart from 'state' into categorical\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "df['international plan'] = label_encoder.fit_transform(df['international plan'])\n",
    "df['voice mail plan'] = label_encoder.fit_transform(df['voice mail plan'])\n",
    "df['area code'] = label_encoder.fit_transform(df['area code'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3333"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each customer has got a single number\n",
    "df['phone number'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping phone number as it is irrelevant in our model since each customer has got a unique numbers\n",
    "df.drop('phone number', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state                     0\n",
       "account length            0\n",
       "area code                 0\n",
       "international plan        0\n",
       "voice mail plan           0\n",
       "number vmail messages     0\n",
       "total day minutes         0\n",
       "total day calls           0\n",
       "total day charge          0\n",
       "total eve minutes         0\n",
       "total eve calls           0\n",
       "total eve charge          0\n",
       "total night minutes       0\n",
       "total night calls         0\n",
       "total night charge        0\n",
       "total intl minutes        0\n",
       "total intl calls          0\n",
       "total intl charge         0\n",
       "customer service calls    0\n",
       "churn                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are no missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account length</th>\n",
       "      <th>area code</th>\n",
       "      <th>international plan</th>\n",
       "      <th>voice mail plan</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>total eve minutes</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>101.064806</td>\n",
       "      <td>1.000600</td>\n",
       "      <td>0.096910</td>\n",
       "      <td>0.276628</td>\n",
       "      <td>8.099010</td>\n",
       "      <td>179.775098</td>\n",
       "      <td>100.435644</td>\n",
       "      <td>30.562307</td>\n",
       "      <td>200.980348</td>\n",
       "      <td>100.114311</td>\n",
       "      <td>17.083540</td>\n",
       "      <td>200.872037</td>\n",
       "      <td>100.107711</td>\n",
       "      <td>9.039325</td>\n",
       "      <td>10.237294</td>\n",
       "      <td>4.479448</td>\n",
       "      <td>2.764581</td>\n",
       "      <td>1.562856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>39.822106</td>\n",
       "      <td>0.709649</td>\n",
       "      <td>0.295879</td>\n",
       "      <td>0.447398</td>\n",
       "      <td>13.688365</td>\n",
       "      <td>54.467389</td>\n",
       "      <td>20.069084</td>\n",
       "      <td>9.259435</td>\n",
       "      <td>50.713844</td>\n",
       "      <td>19.922625</td>\n",
       "      <td>4.310668</td>\n",
       "      <td>50.573847</td>\n",
       "      <td>19.568609</td>\n",
       "      <td>2.275873</td>\n",
       "      <td>2.791840</td>\n",
       "      <td>2.461214</td>\n",
       "      <td>0.753773</td>\n",
       "      <td>1.315491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>143.700000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>24.430000</td>\n",
       "      <td>166.600000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>14.160000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>7.520000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>179.400000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>201.400000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>17.120000</td>\n",
       "      <td>201.200000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.050000</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>216.400000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>36.790000</td>\n",
       "      <td>235.300000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>235.300000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>10.590000</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.270000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>350.800000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>59.640000</td>\n",
       "      <td>363.700000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>30.910000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>17.770000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       account length    area code  international plan  voice mail plan  \\\n",
       "count     3333.000000  3333.000000         3333.000000      3333.000000   \n",
       "mean       101.064806     1.000600            0.096910         0.276628   \n",
       "std         39.822106     0.709649            0.295879         0.447398   \n",
       "min          1.000000     0.000000            0.000000         0.000000   \n",
       "25%         74.000000     0.000000            0.000000         0.000000   \n",
       "50%        101.000000     1.000000            0.000000         0.000000   \n",
       "75%        127.000000     2.000000            0.000000         1.000000   \n",
       "max        243.000000     2.000000            1.000000         1.000000   \n",
       "\n",
       "       number vmail messages  total day minutes  total day calls  \\\n",
       "count            3333.000000        3333.000000      3333.000000   \n",
       "mean                8.099010         179.775098       100.435644   \n",
       "std                13.688365          54.467389        20.069084   \n",
       "min                 0.000000           0.000000         0.000000   \n",
       "25%                 0.000000         143.700000        87.000000   \n",
       "50%                 0.000000         179.400000       101.000000   \n",
       "75%                20.000000         216.400000       114.000000   \n",
       "max                51.000000         350.800000       165.000000   \n",
       "\n",
       "       total day charge  total eve minutes  total eve calls  total eve charge  \\\n",
       "count       3333.000000        3333.000000      3333.000000       3333.000000   \n",
       "mean          30.562307         200.980348       100.114311         17.083540   \n",
       "std            9.259435          50.713844        19.922625          4.310668   \n",
       "min            0.000000           0.000000         0.000000          0.000000   \n",
       "25%           24.430000         166.600000        87.000000         14.160000   \n",
       "50%           30.500000         201.400000       100.000000         17.120000   \n",
       "75%           36.790000         235.300000       114.000000         20.000000   \n",
       "max           59.640000         363.700000       170.000000         30.910000   \n",
       "\n",
       "       total night minutes  total night calls  total night charge  \\\n",
       "count          3333.000000        3333.000000         3333.000000   \n",
       "mean            200.872037         100.107711            9.039325   \n",
       "std              50.573847          19.568609            2.275873   \n",
       "min              23.200000          33.000000            1.040000   \n",
       "25%             167.000000          87.000000            7.520000   \n",
       "50%             201.200000         100.000000            9.050000   \n",
       "75%             235.300000         113.000000           10.590000   \n",
       "max             395.000000         175.000000           17.770000   \n",
       "\n",
       "       total intl minutes  total intl calls  total intl charge  \\\n",
       "count         3333.000000       3333.000000        3333.000000   \n",
       "mean            10.237294          4.479448           2.764581   \n",
       "std              2.791840          2.461214           0.753773   \n",
       "min              0.000000          0.000000           0.000000   \n",
       "25%              8.500000          3.000000           2.300000   \n",
       "50%             10.300000          4.000000           2.780000   \n",
       "75%             12.100000          6.000000           3.270000   \n",
       "max             20.000000         20.000000           5.400000   \n",
       "\n",
       "       customer service calls  \n",
       "count             3333.000000  \n",
       "mean                 1.562856  \n",
       "std                  1.315491  \n",
       "min                  0.000000  \n",
       "25%                  1.000000  \n",
       "50%                  1.000000  \n",
       "75%                  2.000000  \n",
       "max                  9.000000  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there doesn't seem to be any massive outliers by looking at min and max for each column\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Churn rate is  14.49 %\n"
     ]
    }
   ],
   "source": [
    "# calculating overall churn rate\n",
    "churn = df['churn'].value_counts()\n",
    "sns.barplot(churn.index, churn.values)\n",
    "plt.title('Overall number of Churn')\n",
    "plt.style.use('seaborn')\n",
    "plt.show()\n",
    "\n",
    "churn_rate = ((sum(df['churn'] == True)/ len(df['churn'])*100))\n",
    "print('Overall Churn rate is ', round(churn_rate, 2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some clear **class imbalance** in our dataset that we will need to address when we apply our models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting all columns against churn rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converted the column names into a list\n",
    "list_index = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# going through each of the features vs churn to look at both the single distributions and also relationship with churn\n",
    "for i in list_index:\n",
    "    df.groupby([i, \"churn\"]).size().unstack().plot(kind='bar', stacked=True, figsize=(50,30))\n",
    "    plt.title(f'churn rate with {i}' , fontsize = 70)\n",
    "    plt.legend(fontsize = 30)\n",
    "    plt.xticks(fontsize = 50)\n",
    "    plt.yticks(fontsize = 50)\n",
    "  \n",
    "    plt.xlabel(i, fontsize = 50)\n",
    "    plt.style.use('seaborn')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "International calls and customer service calls are skewed to the left. Need to further investigate that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  What are the customer brackets (in terms of account length) with higher churn rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account length</th>\n",
       "      <th>area code</th>\n",
       "      <th>international plan</th>\n",
       "      <th>voice mail plan</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>total eve minutes</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3328</td>\n",
       "      <td>AZ</td>\n",
       "      <td>192</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>156.2</td>\n",
       "      <td>77</td>\n",
       "      <td>26.55</td>\n",
       "      <td>215.5</td>\n",
       "      <td>126</td>\n",
       "      <td>18.32</td>\n",
       "      <td>279.1</td>\n",
       "      <td>83</td>\n",
       "      <td>12.56</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3329</td>\n",
       "      <td>WV</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>231.1</td>\n",
       "      <td>57</td>\n",
       "      <td>39.29</td>\n",
       "      <td>153.4</td>\n",
       "      <td>55</td>\n",
       "      <td>13.04</td>\n",
       "      <td>191.3</td>\n",
       "      <td>123</td>\n",
       "      <td>8.61</td>\n",
       "      <td>9.6</td>\n",
       "      <td>4</td>\n",
       "      <td>2.59</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3330</td>\n",
       "      <td>RI</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180.8</td>\n",
       "      <td>109</td>\n",
       "      <td>30.74</td>\n",
       "      <td>288.8</td>\n",
       "      <td>58</td>\n",
       "      <td>24.55</td>\n",
       "      <td>191.9</td>\n",
       "      <td>91</td>\n",
       "      <td>8.64</td>\n",
       "      <td>14.1</td>\n",
       "      <td>6</td>\n",
       "      <td>3.81</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3331</td>\n",
       "      <td>CT</td>\n",
       "      <td>184</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>213.8</td>\n",
       "      <td>105</td>\n",
       "      <td>36.35</td>\n",
       "      <td>159.6</td>\n",
       "      <td>84</td>\n",
       "      <td>13.57</td>\n",
       "      <td>139.2</td>\n",
       "      <td>137</td>\n",
       "      <td>6.26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3332</td>\n",
       "      <td>TN</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>234.4</td>\n",
       "      <td>113</td>\n",
       "      <td>39.85</td>\n",
       "      <td>265.9</td>\n",
       "      <td>82</td>\n",
       "      <td>22.60</td>\n",
       "      <td>241.4</td>\n",
       "      <td>77</td>\n",
       "      <td>10.86</td>\n",
       "      <td>13.7</td>\n",
       "      <td>4</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3333 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     state  account length  area code  international plan  voice mail plan  \\\n",
       "0       KS             128          1                   0                1   \n",
       "1       OH             107          1                   0                1   \n",
       "2       NJ             137          1                   0                0   \n",
       "3       OH              84          0                   1                0   \n",
       "4       OK              75          1                   1                0   \n",
       "...    ...             ...        ...                 ...              ...   \n",
       "3328    AZ             192          1                   0                1   \n",
       "3329    WV              68          1                   0                0   \n",
       "3330    RI              28          2                   0                0   \n",
       "3331    CT             184          2                   1                0   \n",
       "3332    TN              74          1                   0                1   \n",
       "\n",
       "      number vmail messages  total day minutes  total day calls  \\\n",
       "0                        25              265.1              110   \n",
       "1                        26              161.6              123   \n",
       "2                         0              243.4              114   \n",
       "3                         0              299.4               71   \n",
       "4                         0              166.7              113   \n",
       "...                     ...                ...              ...   \n",
       "3328                     36              156.2               77   \n",
       "3329                      0              231.1               57   \n",
       "3330                      0              180.8              109   \n",
       "3331                      0              213.8              105   \n",
       "3332                     25              234.4              113   \n",
       "\n",
       "      total day charge  total eve minutes  total eve calls  total eve charge  \\\n",
       "0                45.07              197.4               99             16.78   \n",
       "1                27.47              195.5              103             16.62   \n",
       "2                41.38              121.2              110             10.30   \n",
       "3                50.90               61.9               88              5.26   \n",
       "4                28.34              148.3              122             12.61   \n",
       "...                ...                ...              ...               ...   \n",
       "3328             26.55              215.5              126             18.32   \n",
       "3329             39.29              153.4               55             13.04   \n",
       "3330             30.74              288.8               58             24.55   \n",
       "3331             36.35              159.6               84             13.57   \n",
       "3332             39.85              265.9               82             22.60   \n",
       "\n",
       "      total night minutes  total night calls  total night charge  \\\n",
       "0                   244.7                 91               11.01   \n",
       "1                   254.4                103               11.45   \n",
       "2                   162.6                104                7.32   \n",
       "3                   196.9                 89                8.86   \n",
       "4                   186.9                121                8.41   \n",
       "...                   ...                ...                 ...   \n",
       "3328                279.1                 83               12.56   \n",
       "3329                191.3                123                8.61   \n",
       "3330                191.9                 91                8.64   \n",
       "3331                139.2                137                6.26   \n",
       "3332                241.4                 77               10.86   \n",
       "\n",
       "      total intl minutes  total intl calls  total intl charge  \\\n",
       "0                   10.0                 3               2.70   \n",
       "1                   13.7                 3               3.70   \n",
       "2                   12.2                 5               3.29   \n",
       "3                    6.6                 7               1.78   \n",
       "4                   10.1                 3               2.73   \n",
       "...                  ...               ...                ...   \n",
       "3328                 9.9                 6               2.67   \n",
       "3329                 9.6                 4               2.59   \n",
       "3330                14.1                 6               3.81   \n",
       "3331                 5.0                10               1.35   \n",
       "3332                13.7                 4               3.70   \n",
       "\n",
       "      customer service calls  churn  \n",
       "0                          1  False  \n",
       "1                          1  False  \n",
       "2                          0  False  \n",
       "3                          2  False  \n",
       "4                          3  False  \n",
       "...                      ...    ...  \n",
       "3328                       2  False  \n",
       "3329                       3  False  \n",
       "3330                       2  False  \n",
       "3331                       2  False  \n",
       "3332                       0  False  \n",
       "\n",
       "[3333 rows x 20 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_brackets = df.copy()\n",
    "df_brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account length</th>\n",
       "      <th>area code</th>\n",
       "      <th>international plan</th>\n",
       "      <th>voice mail plan</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>total eve minutes</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "      <th>churn</th>\n",
       "      <th>brackets_accounts_l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>125-150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>100-125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>125-150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>75-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>50-75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3328</td>\n",
       "      <td>AZ</td>\n",
       "      <td>192</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>156.2</td>\n",
       "      <td>77</td>\n",
       "      <td>26.55</td>\n",
       "      <td>215.5</td>\n",
       "      <td>126</td>\n",
       "      <td>18.32</td>\n",
       "      <td>279.1</td>\n",
       "      <td>83</td>\n",
       "      <td>12.56</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>175-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3329</td>\n",
       "      <td>WV</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>231.1</td>\n",
       "      <td>57</td>\n",
       "      <td>39.29</td>\n",
       "      <td>153.4</td>\n",
       "      <td>55</td>\n",
       "      <td>13.04</td>\n",
       "      <td>191.3</td>\n",
       "      <td>123</td>\n",
       "      <td>8.61</td>\n",
       "      <td>9.6</td>\n",
       "      <td>4</td>\n",
       "      <td>2.59</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>50-75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3330</td>\n",
       "      <td>RI</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180.8</td>\n",
       "      <td>109</td>\n",
       "      <td>30.74</td>\n",
       "      <td>288.8</td>\n",
       "      <td>58</td>\n",
       "      <td>24.55</td>\n",
       "      <td>191.9</td>\n",
       "      <td>91</td>\n",
       "      <td>8.64</td>\n",
       "      <td>14.1</td>\n",
       "      <td>6</td>\n",
       "      <td>3.81</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>25-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3331</td>\n",
       "      <td>CT</td>\n",
       "      <td>184</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>213.8</td>\n",
       "      <td>105</td>\n",
       "      <td>36.35</td>\n",
       "      <td>159.6</td>\n",
       "      <td>84</td>\n",
       "      <td>13.57</td>\n",
       "      <td>139.2</td>\n",
       "      <td>137</td>\n",
       "      <td>6.26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>175-200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3332</td>\n",
       "      <td>TN</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>234.4</td>\n",
       "      <td>113</td>\n",
       "      <td>39.85</td>\n",
       "      <td>265.9</td>\n",
       "      <td>82</td>\n",
       "      <td>22.60</td>\n",
       "      <td>241.4</td>\n",
       "      <td>77</td>\n",
       "      <td>10.86</td>\n",
       "      <td>13.7</td>\n",
       "      <td>4</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>50-75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3333 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     state  account length  area code  international plan  voice mail plan  \\\n",
       "0       KS             128          1                   0                1   \n",
       "1       OH             107          1                   0                1   \n",
       "2       NJ             137          1                   0                0   \n",
       "3       OH              84          0                   1                0   \n",
       "4       OK              75          1                   1                0   \n",
       "...    ...             ...        ...                 ...              ...   \n",
       "3328    AZ             192          1                   0                1   \n",
       "3329    WV              68          1                   0                0   \n",
       "3330    RI              28          2                   0                0   \n",
       "3331    CT             184          2                   1                0   \n",
       "3332    TN              74          1                   0                1   \n",
       "\n",
       "      number vmail messages  total day minutes  total day calls  \\\n",
       "0                        25              265.1              110   \n",
       "1                        26              161.6              123   \n",
       "2                         0              243.4              114   \n",
       "3                         0              299.4               71   \n",
       "4                         0              166.7              113   \n",
       "...                     ...                ...              ...   \n",
       "3328                     36              156.2               77   \n",
       "3329                      0              231.1               57   \n",
       "3330                      0              180.8              109   \n",
       "3331                      0              213.8              105   \n",
       "3332                     25              234.4              113   \n",
       "\n",
       "      total day charge  total eve minutes  total eve calls  total eve charge  \\\n",
       "0                45.07              197.4               99             16.78   \n",
       "1                27.47              195.5              103             16.62   \n",
       "2                41.38              121.2              110             10.30   \n",
       "3                50.90               61.9               88              5.26   \n",
       "4                28.34              148.3              122             12.61   \n",
       "...                ...                ...              ...               ...   \n",
       "3328             26.55              215.5              126             18.32   \n",
       "3329             39.29              153.4               55             13.04   \n",
       "3330             30.74              288.8               58             24.55   \n",
       "3331             36.35              159.6               84             13.57   \n",
       "3332             39.85              265.9               82             22.60   \n",
       "\n",
       "      total night minutes  total night calls  total night charge  \\\n",
       "0                   244.7                 91               11.01   \n",
       "1                   254.4                103               11.45   \n",
       "2                   162.6                104                7.32   \n",
       "3                   196.9                 89                8.86   \n",
       "4                   186.9                121                8.41   \n",
       "...                   ...                ...                 ...   \n",
       "3328                279.1                 83               12.56   \n",
       "3329                191.3                123                8.61   \n",
       "3330                191.9                 91                8.64   \n",
       "3331                139.2                137                6.26   \n",
       "3332                241.4                 77               10.86   \n",
       "\n",
       "      total intl minutes  total intl calls  total intl charge  \\\n",
       "0                   10.0                 3               2.70   \n",
       "1                   13.7                 3               3.70   \n",
       "2                   12.2                 5               3.29   \n",
       "3                    6.6                 7               1.78   \n",
       "4                   10.1                 3               2.73   \n",
       "...                  ...               ...                ...   \n",
       "3328                 9.9                 6               2.67   \n",
       "3329                 9.6                 4               2.59   \n",
       "3330                14.1                 6               3.81   \n",
       "3331                 5.0                10               1.35   \n",
       "3332                13.7                 4               3.70   \n",
       "\n",
       "      customer service calls  churn brackets_accounts_l  \n",
       "0                          1  False             125-150  \n",
       "1                          1  False             100-125  \n",
       "2                          0  False             125-150  \n",
       "3                          2  False              75-100  \n",
       "4                          3  False               50-75  \n",
       "...                      ...    ...                 ...  \n",
       "3328                       2  False             175-200  \n",
       "3329                       3  False               50-75  \n",
       "3330                       2  False               25-50  \n",
       "3331                       2  False             175-200  \n",
       "3332                       0  False               50-75  \n",
       "\n",
       "[3333 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bracketing account_lengths\n",
    "bins = [0, 25, 50,75, 100, 125, 150, 175, 200, 225, 250]\n",
    "labels = ['0-25','25-50','50-75','75-100','100-125','125-150', '150-175', '175-200', '200-225','225-250']\n",
    "df_brackets['brackets_accounts_l'] = pd.cut(df_brackets['account length'], bins=bins, labels=labels)\n",
    "\n",
    "df_brackets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>churn</th>\n",
       "      <th>brackets_accounts_l</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>churn_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0-25</td>\n",
       "      <td>84.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.105590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>25-50</td>\n",
       "      <td>213.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6.004141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>50-75</td>\n",
       "      <td>474.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>15.320911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>75-100</td>\n",
       "      <td>659.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>24.016563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>100-125</td>\n",
       "      <td>666.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>25.051760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>125-150</td>\n",
       "      <td>452.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>15.320911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>150-175</td>\n",
       "      <td>203.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>7.453416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>175-200</td>\n",
       "      <td>79.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.484472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>200-225</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.242236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>225-250</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "churn brackets_accounts_l  False   True  churn_percentage\n",
       "0                    0-25   84.0   15.0          3.105590\n",
       "1                   25-50  213.0   29.0          6.004141\n",
       "2                   50-75  474.0   74.0         15.320911\n",
       "3                  75-100  659.0  116.0         24.016563\n",
       "4                 100-125  666.0  121.0         25.051760\n",
       "5                 125-150  452.0   74.0         15.320911\n",
       "6                 150-175  203.0   36.0          7.453416\n",
       "7                 175-200   79.0   12.0          2.484472\n",
       "8                 200-225   18.0    6.0          1.242236\n",
       "9                 225-250    2.0    NaN               NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_brack = df_brackets.groupby(['brackets_accounts_l', 'churn']).size().unstack().reset_index()\n",
    "\n",
    "sum_all_t = grouped_brack[True].sum()\n",
    "grouped_brack['churn_percentage'] = (grouped_brack[True] / sum_all_t) * 100\n",
    "grouped_brack\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "plt.bar(grouped_brack['brackets_accounts_l'], grouped_brack['churn_percentage'])\n",
    "plt.title('Churn percentage in relation to accounts lifespan', fontsize = 30)\n",
    "\n",
    "ax.set_xlabel(\"Account Activation in Days\",fontsize=25)\n",
    "ax.set_ylabel(\"Churn Percentage\",fontsize=25)\n",
    "\n",
    "plt.xticks(fontsize = 20)\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.style.use('seaborn')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a peak of account deactivations within the range 100-125 days. Customers after that time window seems to stick to the firm while customers prior to that haven't got enough info to drop out yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  What are the top 5 states for churn rate? Lowest 5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-33da24321964>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mstate_grouped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"state\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"churn\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"states\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfontsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, **kwargs)\u001b[0m\n\u001b[1;32m   7892\u001b[0m             \u001b[0msqueeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7893\u001b[0m             \u001b[0mobserved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7894\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7895\u001b[0m         )\n\u001b[1;32m   7896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(obj, by, **kwds)\u001b[0m\n\u001b[1;32m   2520\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"invalid type: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2522\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m                 \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mobserved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                 \u001b[0mmutated\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutated\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m             )\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36m_get_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate)\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;31m# Add key to exclusions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'state'"
     ]
    }
   ],
   "source": [
    "# plotting churn rate against states\n",
    "\n",
    "\n",
    "state_grouped = df.groupby([\"state\", \"churn\"]).size().unstack().plot(kind='bar', stacked=True, figsize=(30,10))\n",
    "plt.xlabel(\"states\", fontsize = 30)\n",
    "plt.xticks(fontsize = 25)\n",
    "plt.ylabel(\"churn rate\", fontsize = 30)\n",
    "plt.legend (loc = 2, fontsize = 40)\n",
    "plt.title ('Churn rate per state', fontsize = 30)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>churn</th>\n",
       "      <th>state</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>churn_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>LA</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>0.828157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AZ</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>0.828157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>HI</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>0.621118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>IA</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>0.621118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AK</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>0.621118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "churn state  False  True  churn_percentage\n",
       "18       LA     47     4          0.828157\n",
       "3        AZ     60     4          0.828157\n",
       "11       HI     50     3          0.621118\n",
       "12       IA     41     3          0.621118\n",
       "0        AK     49     3          0.621118"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting top5 and last 5 for churn rate percentage out of all the churned customers\n",
    "state_grouped_1 = df.groupby([\"state\", \"churn\"]).size().unstack().reset_index()\n",
    "sum_all_states = state_grouped_1[True].sum()\n",
    "state_grouped_1['churn_percentage'] = (state_grouped_1[True] / sum_all_t) * 100\n",
    "state_grouped_1.sort_values(by ='churn_percentage', ascending = False, inplace = True)\n",
    "top_five_churn = state_grouped_1[:5]\n",
    "lower_five_churn = state_grouped_1[-5:]\n",
    "lower_five_churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "plt.bar(top_five_churn['state'], top_five_churn['churn_percentage'])\n",
    "plt.title('Top 5 states for Churn rate', fontsize = 30)\n",
    "\n",
    "ax.set_xlabel(\"State\",fontsize=25)\n",
    "ax.set_ylabel(\"Churn Percentage\",fontsize=25)\n",
    "\n",
    "plt.xticks(fontsize = 20)\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "plt.bar(lower_five_churn['state'], lower_five_churn['churn_percentage'])\n",
    "plt.title('Lowest 5 states for Churn rate', fontsize = 30)\n",
    "\n",
    "ax.set_xlabel(\"State\",fontsize=25)\n",
    "ax.set_ylabel(\"Churn Percentage\",fontsize=25)\n",
    "\n",
    "plt.xticks(fontsize = 20)\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also since there is a significant difference across states in terms of churn rates, I am also encoding the states data to be used in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account length</th>\n",
       "      <th>area code</th>\n",
       "      <th>international plan</th>\n",
       "      <th>voice mail plan</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>total eve minutes</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3328</td>\n",
       "      <td>3</td>\n",
       "      <td>192</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>156.2</td>\n",
       "      <td>77</td>\n",
       "      <td>26.55</td>\n",
       "      <td>215.5</td>\n",
       "      <td>126</td>\n",
       "      <td>18.32</td>\n",
       "      <td>279.1</td>\n",
       "      <td>83</td>\n",
       "      <td>12.56</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3329</td>\n",
       "      <td>49</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>231.1</td>\n",
       "      <td>57</td>\n",
       "      <td>39.29</td>\n",
       "      <td>153.4</td>\n",
       "      <td>55</td>\n",
       "      <td>13.04</td>\n",
       "      <td>191.3</td>\n",
       "      <td>123</td>\n",
       "      <td>8.61</td>\n",
       "      <td>9.6</td>\n",
       "      <td>4</td>\n",
       "      <td>2.59</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3330</td>\n",
       "      <td>39</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180.8</td>\n",
       "      <td>109</td>\n",
       "      <td>30.74</td>\n",
       "      <td>288.8</td>\n",
       "      <td>58</td>\n",
       "      <td>24.55</td>\n",
       "      <td>191.9</td>\n",
       "      <td>91</td>\n",
       "      <td>8.64</td>\n",
       "      <td>14.1</td>\n",
       "      <td>6</td>\n",
       "      <td>3.81</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3331</td>\n",
       "      <td>6</td>\n",
       "      <td>184</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>213.8</td>\n",
       "      <td>105</td>\n",
       "      <td>36.35</td>\n",
       "      <td>159.6</td>\n",
       "      <td>84</td>\n",
       "      <td>13.57</td>\n",
       "      <td>139.2</td>\n",
       "      <td>137</td>\n",
       "      <td>6.26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3332</td>\n",
       "      <td>42</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>234.4</td>\n",
       "      <td>113</td>\n",
       "      <td>39.85</td>\n",
       "      <td>265.9</td>\n",
       "      <td>82</td>\n",
       "      <td>22.60</td>\n",
       "      <td>241.4</td>\n",
       "      <td>77</td>\n",
       "      <td>10.86</td>\n",
       "      <td>13.7</td>\n",
       "      <td>4</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3333 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      state  account length  area code  international plan  voice mail plan  \\\n",
       "0        16             128          1                   0                1   \n",
       "1        35             107          1                   0                1   \n",
       "2        31             137          1                   0                0   \n",
       "3        35              84          0                   1                0   \n",
       "4        36              75          1                   1                0   \n",
       "...     ...             ...        ...                 ...              ...   \n",
       "3328      3             192          1                   0                1   \n",
       "3329     49              68          1                   0                0   \n",
       "3330     39              28          2                   0                0   \n",
       "3331      6             184          2                   1                0   \n",
       "3332     42              74          1                   0                1   \n",
       "\n",
       "      number vmail messages  total day minutes  total day calls  \\\n",
       "0                        25              265.1              110   \n",
       "1                        26              161.6              123   \n",
       "2                         0              243.4              114   \n",
       "3                         0              299.4               71   \n",
       "4                         0              166.7              113   \n",
       "...                     ...                ...              ...   \n",
       "3328                     36              156.2               77   \n",
       "3329                      0              231.1               57   \n",
       "3330                      0              180.8              109   \n",
       "3331                      0              213.8              105   \n",
       "3332                     25              234.4              113   \n",
       "\n",
       "      total day charge  total eve minutes  total eve calls  total eve charge  \\\n",
       "0                45.07              197.4               99             16.78   \n",
       "1                27.47              195.5              103             16.62   \n",
       "2                41.38              121.2              110             10.30   \n",
       "3                50.90               61.9               88              5.26   \n",
       "4                28.34              148.3              122             12.61   \n",
       "...                ...                ...              ...               ...   \n",
       "3328             26.55              215.5              126             18.32   \n",
       "3329             39.29              153.4               55             13.04   \n",
       "3330             30.74              288.8               58             24.55   \n",
       "3331             36.35              159.6               84             13.57   \n",
       "3332             39.85              265.9               82             22.60   \n",
       "\n",
       "      total night minutes  total night calls  total night charge  \\\n",
       "0                   244.7                 91               11.01   \n",
       "1                   254.4                103               11.45   \n",
       "2                   162.6                104                7.32   \n",
       "3                   196.9                 89                8.86   \n",
       "4                   186.9                121                8.41   \n",
       "...                   ...                ...                 ...   \n",
       "3328                279.1                 83               12.56   \n",
       "3329                191.3                123                8.61   \n",
       "3330                191.9                 91                8.64   \n",
       "3331                139.2                137                6.26   \n",
       "3332                241.4                 77               10.86   \n",
       "\n",
       "      total intl minutes  total intl calls  total intl charge  \\\n",
       "0                   10.0                 3               2.70   \n",
       "1                   13.7                 3               3.70   \n",
       "2                   12.2                 5               3.29   \n",
       "3                    6.6                 7               1.78   \n",
       "4                   10.1                 3               2.73   \n",
       "...                  ...               ...                ...   \n",
       "3328                 9.9                 6               2.67   \n",
       "3329                 9.6                 4               2.59   \n",
       "3330                14.1                 6               3.81   \n",
       "3331                 5.0                10               1.35   \n",
       "3332                13.7                 4               3.70   \n",
       "\n",
       "      customer service calls  churn  \n",
       "0                          1  False  \n",
       "1                          1  False  \n",
       "2                          0  False  \n",
       "3                          2  False  \n",
       "4                          3  False  \n",
       "...                      ...    ...  \n",
       "3328                       2  False  \n",
       "3329                       3  False  \n",
       "3330                       2  False  \n",
       "3331                       2  False  \n",
       "3332                       0  False  \n",
       "\n",
       "[3333 rows x 20 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['state'] = label_encoder.fit_transform(df['state'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col0 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col1 {\n",
       "            background-color:  #445acc;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col2 {\n",
       "            background-color:  #485fd1;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col3 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col4 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col5 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col6 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col7 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col8 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col9 {\n",
       "            background-color:  #485fd1;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col10 {\n",
       "            background-color:  #3e51c5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col11 {\n",
       "            background-color:  #485fd1;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col12 {\n",
       "            background-color:  #4a63d3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col13 {\n",
       "            background-color:  #455cce;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col14 {\n",
       "            background-color:  #4a63d3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col15 {\n",
       "            background-color:  #4055c8;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col16 {\n",
       "            background-color:  #485fd1;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col17 {\n",
       "            background-color:  #4055c8;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col18 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col19 {\n",
       "            background-color:  #455cce;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col0 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col1 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col2 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col3 {\n",
       "            background-color:  #455cce;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col4 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col5 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col6 {\n",
       "            background-color:  #4055c8;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col7 {\n",
       "            background-color:  #4a63d3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col8 {\n",
       "            background-color:  #4055c8;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col9 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col10 {\n",
       "            background-color:  #445acc;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col11 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col12 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col13 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col14 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col15 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col16 {\n",
       "            background-color:  #445acc;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col17 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col18 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col19 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col0 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col1 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col2 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col3 {\n",
       "            background-color:  #4b64d5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col4 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col5 {\n",
       "            background-color:  #4055c8;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col6 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col7 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col8 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col9 {\n",
       "            background-color:  #3e51c5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col10 {\n",
       "            background-color:  #3e51c5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col11 {\n",
       "            background-color:  #3e51c5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col12 {\n",
       "            background-color:  #4055c8;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col13 {\n",
       "            background-color:  #465ecf;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col14 {\n",
       "            background-color:  #4055c8;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col15 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col16 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col17 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col18 {\n",
       "            background-color:  #465ecf;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col19 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col0 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col1 {\n",
       "            background-color:  #4a63d3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col2 {\n",
       "            background-color:  #506bda;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col3 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col4 {\n",
       "            background-color:  #445acc;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col5 {\n",
       "            background-color:  #455cce;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col6 {\n",
       "            background-color:  #516ddb;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col7 {\n",
       "            background-color:  #445acc;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col8 {\n",
       "            background-color:  #516ddb;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col9 {\n",
       "            background-color:  #485fd1;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col10 {\n",
       "            background-color:  #445acc;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col11 {\n",
       "            background-color:  #485fd1;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col12 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col13 {\n",
       "            background-color:  #465ecf;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col14 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col15 {\n",
       "            background-color:  #506bda;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col16 {\n",
       "            background-color:  #485fd1;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col17 {\n",
       "            background-color:  #506bda;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col18 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col19 {\n",
       "            background-color:  #97b8ff;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col0 {\n",
       "            background-color:  #4e68d8;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col1 {\n",
       "            background-color:  #5875e1;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col2 {\n",
       "            background-color:  #5a78e4;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col3 {\n",
       "            background-color:  #5977e3;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col4 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col5 {\n",
       "            background-color:  #c32e31;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col6 {\n",
       "            background-color:  #5673e0;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col7 {\n",
       "            background-color:  #5470de;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col8 {\n",
       "            background-color:  #5673e0;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col9 {\n",
       "            background-color:  #5d7ce6;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col10 {\n",
       "            background-color:  #5572df;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col11 {\n",
       "            background-color:  #5d7ce6;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col12 {\n",
       "            background-color:  #5977e3;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col13 {\n",
       "            background-color:  #5b7ae5;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col14 {\n",
       "            background-color:  #5977e3;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col15 {\n",
       "            background-color:  #5673e0;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col16 {\n",
       "            background-color:  #5977e3;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col17 {\n",
       "            background-color:  #5673e0;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col18 {\n",
       "            background-color:  #516ddb;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col19 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col0 {\n",
       "            background-color:  #4b64d5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col1 {\n",
       "            background-color:  #516ddb;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col2 {\n",
       "            background-color:  #5673e0;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col3 {\n",
       "            background-color:  #5673e0;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col4 {\n",
       "            background-color:  #c32e31;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col5 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col6 {\n",
       "            background-color:  #5470de;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col7 {\n",
       "            background-color:  #506bda;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col8 {\n",
       "            background-color:  #5470de;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col9 {\n",
       "            background-color:  #5977e3;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col10 {\n",
       "            background-color:  #516ddb;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col11 {\n",
       "            background-color:  #5977e3;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col12 {\n",
       "            background-color:  #5572df;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col13 {\n",
       "            background-color:  #5572df;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col14 {\n",
       "            background-color:  #5572df;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col15 {\n",
       "            background-color:  #5470de;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col16 {\n",
       "            background-color:  #5875e1;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col17 {\n",
       "            background-color:  #5470de;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col18 {\n",
       "            background-color:  #4f69d9;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col19 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col0 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col1 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col2 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col3 {\n",
       "            background-color:  #4c66d6;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col4 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col5 {\n",
       "            background-color:  #3e51c5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col6 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col7 {\n",
       "            background-color:  #4055c8;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col8 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col9 {\n",
       "            background-color:  #4055c8;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col10 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col11 {\n",
       "            background-color:  #4055c8;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col12 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col13 {\n",
       "            background-color:  #455cce;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col14 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col15 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col16 {\n",
       "            background-color:  #4055c8;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col17 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col18 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col19 {\n",
       "            background-color:  #81a4fb;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col0 {\n",
       "            background-color:  #4055c8;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col1 {\n",
       "            background-color:  #4c66d6;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col2 {\n",
       "            background-color:  #3e51c5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col3 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col4 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col5 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col6 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col7 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col8 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col9 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col10 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col11 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col12 {\n",
       "            background-color:  #485fd1;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col13 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col14 {\n",
       "            background-color:  #485fd1;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col15 {\n",
       "            background-color:  #465ecf;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col16 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col17 {\n",
       "            background-color:  #465ecf;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col18 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col19 {\n",
       "            background-color:  #465ecf;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col0 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col1 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col2 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col3 {\n",
       "            background-color:  #4c66d6;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col4 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col5 {\n",
       "            background-color:  #3e51c5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col6 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col7 {\n",
       "            background-color:  #4055c8;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col8 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col9 {\n",
       "            background-color:  #4055c8;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col10 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col11 {\n",
       "            background-color:  #4055c8;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col12 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col13 {\n",
       "            background-color:  #455cce;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col14 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col15 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col16 {\n",
       "            background-color:  #4055c8;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col17 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col18 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col19 {\n",
       "            background-color:  #81a4fb;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col0 {\n",
       "            background-color:  #445acc;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col1 {\n",
       "            background-color:  #3e51c5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col2 {\n",
       "            background-color:  #4055c8;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col3 {\n",
       "            background-color:  #465ecf;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col4 {\n",
       "            background-color:  #465ecf;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col5 {\n",
       "            background-color:  #455cce;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col6 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col7 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col8 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col9 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col10 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col11 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col12 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col13 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col14 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col15 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col16 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col17 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col18 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col19 {\n",
       "            background-color:  #5d7ce6;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col0 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col1 {\n",
       "            background-color:  #445acc;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col2 {\n",
       "            background-color:  #3e51c5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col3 {\n",
       "            background-color:  #4055c8;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col4 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col5 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col6 {\n",
       "            background-color:  #445acc;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col7 {\n",
       "            background-color:  #4055c8;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col8 {\n",
       "            background-color:  #445acc;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col9 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col10 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col11 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col12 {\n",
       "            background-color:  #3e51c5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col13 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col14 {\n",
       "            background-color:  #3e51c5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col15 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col16 {\n",
       "            background-color:  #445acc;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col17 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col18 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col19 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col0 {\n",
       "            background-color:  #445acc;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col1 {\n",
       "            background-color:  #3e51c5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col2 {\n",
       "            background-color:  #4055c8;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col3 {\n",
       "            background-color:  #465ecf;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col4 {\n",
       "            background-color:  #465ecf;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col5 {\n",
       "            background-color:  #455cce;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col6 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col7 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col8 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col9 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col10 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col11 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col12 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col13 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col14 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col15 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col16 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col17 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col18 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col19 {\n",
       "            background-color:  #5d7ce6;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col0 {\n",
       "            background-color:  #4a63d3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col1 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col2 {\n",
       "            background-color:  #445acc;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col3 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col4 {\n",
       "            background-color:  #445acc;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col5 {\n",
       "            background-color:  #455cce;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col6 {\n",
       "            background-color:  #445acc;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col7 {\n",
       "            background-color:  #4961d2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col8 {\n",
       "            background-color:  #445acc;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col9 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col10 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col11 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col12 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col13 {\n",
       "            background-color:  #455cce;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col14 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col15 {\n",
       "            background-color:  #3e51c5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col16 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col17 {\n",
       "            background-color:  #3e51c5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col18 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col19 {\n",
       "            background-color:  #4e68d8;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col0 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col1 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col2 {\n",
       "            background-color:  #4961d2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col3 {\n",
       "            background-color:  #445acc;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col4 {\n",
       "            background-color:  #445acc;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col5 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col6 {\n",
       "            background-color:  #465ecf;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col7 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col8 {\n",
       "            background-color:  #465ecf;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col9 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col10 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col11 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col12 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col13 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col14 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col15 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col16 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col17 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col18 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col19 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col0 {\n",
       "            background-color:  #4a63d3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col1 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col2 {\n",
       "            background-color:  #445acc;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col3 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col4 {\n",
       "            background-color:  #445acc;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col5 {\n",
       "            background-color:  #455cce;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col6 {\n",
       "            background-color:  #445acc;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col7 {\n",
       "            background-color:  #4961d2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col8 {\n",
       "            background-color:  #445acc;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col9 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col10 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col11 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col12 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col13 {\n",
       "            background-color:  #455cce;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col14 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col15 {\n",
       "            background-color:  #3e51c5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col16 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col17 {\n",
       "            background-color:  #3e51c5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col18 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col19 {\n",
       "            background-color:  #4e68d8;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col0 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col1 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col2 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col3 {\n",
       "            background-color:  #4c66d6;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col4 {\n",
       "            background-color:  #3e51c5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col5 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col6 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col7 {\n",
       "            background-color:  #455cce;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col8 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col9 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col10 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col11 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col12 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col13 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col14 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col15 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col16 {\n",
       "            background-color:  #485fd1;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col17 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col18 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col19 {\n",
       "            background-color:  #5470de;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col0 {\n",
       "            background-color:  #4e68d8;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col1 {\n",
       "            background-color:  #4f69d9;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col2 {\n",
       "            background-color:  #465ecf;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col3 {\n",
       "            background-color:  #4f69d9;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col4 {\n",
       "            background-color:  #4b64d5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col5 {\n",
       "            background-color:  #4e68d8;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col6 {\n",
       "            background-color:  #4b64d5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col7 {\n",
       "            background-color:  #4a63d3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col8 {\n",
       "            background-color:  #4b64d5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col9 {\n",
       "            background-color:  #4a63d3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col10 {\n",
       "            background-color:  #4f69d9;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col11 {\n",
       "            background-color:  #4a63d3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col12 {\n",
       "            background-color:  #455cce;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col13 {\n",
       "            background-color:  #4961d2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col14 {\n",
       "            background-color:  #455cce;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col15 {\n",
       "            background-color:  #536edd;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col16 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col17 {\n",
       "            background-color:  #536edd;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col18 {\n",
       "            background-color:  #445acc;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col19 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col0 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col1 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col2 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col3 {\n",
       "            background-color:  #4c66d6;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col4 {\n",
       "            background-color:  #3e51c5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col5 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col6 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col7 {\n",
       "            background-color:  #455cce;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col8 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col9 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col10 {\n",
       "            background-color:  #4257c9;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col11 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col12 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col13 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col14 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col15 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col16 {\n",
       "            background-color:  #485fd1;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col17 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col18 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col19 {\n",
       "            background-color:  #5470de;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col0 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col1 {\n",
       "            background-color:  #4055c8;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col2 {\n",
       "            background-color:  #4a63d3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col3 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col4 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col5 {\n",
       "            background-color:  #3e51c5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col6 {\n",
       "            background-color:  #3e51c5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col7 {\n",
       "            background-color:  #3c4ec2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col8 {\n",
       "            background-color:  #3e51c5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col9 {\n",
       "            background-color:  #3e51c5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col10 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col11 {\n",
       "            background-color:  #3e51c5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col12 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col13 {\n",
       "            background-color:  #3e51c5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col14 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col15 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col16 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col17 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col18 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col19 {\n",
       "            background-color:  #85a8fc;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col0 {\n",
       "            background-color:  #5977e3;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col1 {\n",
       "            background-color:  #5b7ae5;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col2 {\n",
       "            background-color:  #5875e1;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col3 {\n",
       "            background-color:  #a9c6fd;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col4 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col5 {\n",
       "            background-color:  #3d50c3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col6 {\n",
       "            background-color:  #97b8ff;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col7 {\n",
       "            background-color:  #5d7ce6;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col8 {\n",
       "            background-color:  #97b8ff;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col9 {\n",
       "            background-color:  #7396f5;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col10 {\n",
       "            background-color:  #5977e3;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col11 {\n",
       "            background-color:  #7396f5;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col12 {\n",
       "            background-color:  #6180e9;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col13 {\n",
       "            background-color:  #5977e3;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col14 {\n",
       "            background-color:  #6180e9;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col15 {\n",
       "            background-color:  #6b8df0;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col16 {\n",
       "            background-color:  #485fd1;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col17 {\n",
       "            background-color:  #6b8df0;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col18 {\n",
       "            background-color:  #98b9ff;\n",
       "            color:  #000000;\n",
       "        }    #T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col19 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >state</th>        <th class=\"col_heading level0 col1\" >account length</th>        <th class=\"col_heading level0 col2\" >area code</th>        <th class=\"col_heading level0 col3\" >international plan</th>        <th class=\"col_heading level0 col4\" >voice mail plan</th>        <th class=\"col_heading level0 col5\" >number vmail messages</th>        <th class=\"col_heading level0 col6\" >total day minutes</th>        <th class=\"col_heading level0 col7\" >total day calls</th>        <th class=\"col_heading level0 col8\" >total day charge</th>        <th class=\"col_heading level0 col9\" >total eve minutes</th>        <th class=\"col_heading level0 col10\" >total eve calls</th>        <th class=\"col_heading level0 col11\" >total eve charge</th>        <th class=\"col_heading level0 col12\" >total night minutes</th>        <th class=\"col_heading level0 col13\" >total night calls</th>        <th class=\"col_heading level0 col14\" >total night charge</th>        <th class=\"col_heading level0 col15\" >total intl minutes</th>        <th class=\"col_heading level0 col16\" >total intl calls</th>        <th class=\"col_heading level0 col17\" >total intl charge</th>        <th class=\"col_heading level0 col18\" >customer service calls</th>        <th class=\"col_heading level0 col19\" >churn</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72level0_row0\" class=\"row_heading level0 row0\" >state</th>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col0\" class=\"data row0 col0\" >1.0</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col1\" class=\"data row0 col1\" >0.0037</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col2\" class=\"data row0 col2\" >0.015</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col3\" class=\"data row0 col3\" >-0.0046</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col4\" class=\"data row0 col4\" >-0.032</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col5\" class=\"data row0 col5\" >-0.028</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col6\" class=\"data row0 col6\" >-0.0067</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col7\" class=\"data row0 col7\" >-0.00076</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col8\" class=\"data row0 col8\" >-0.0067</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col9\" class=\"data row0 col9\" >0.014</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col10\" class=\"data row0 col10\" >-0.016</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col11\" class=\"data row0 col11\" >0.014</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col12\" class=\"data row0 col12\" >0.025</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col13\" class=\"data row0 col13\" >0.0075</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col14\" class=\"data row0 col14\" >0.025</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col15\" class=\"data row0 col15\" >-0.0078</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col16\" class=\"data row0 col16\" >0.014</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col17\" class=\"data row0 col17\" >-0.0078</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col18\" class=\"data row0 col18\" >-0.026</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row0_col19\" class=\"data row0 col19\" >0.0078</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72level0_row1\" class=\"row_heading level0 row1\" >account length</th>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col0\" class=\"data row1 col0\" >0.0037</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col1\" class=\"data row1 col1\" >1.0</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col2\" class=\"data row1 col2\" >-0.015</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col3\" class=\"data row1 col3\" >0.025</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col4\" class=\"data row1 col4\" >0.0029</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col5\" class=\"data row1 col5\" >-0.0046</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col6\" class=\"data row1 col6\" >0.0062</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col7\" class=\"data row1 col7\" >0.038</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col8\" class=\"data row1 col8\" >0.0062</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col9\" class=\"data row1 col9\" >-0.0068</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col10\" class=\"data row1 col10\" >0.019</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col11\" class=\"data row1 col11\" >-0.0067</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col12\" class=\"data row1 col12\" >-0.009</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col13\" class=\"data row1 col13\" >-0.013</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col14\" class=\"data row1 col14\" >-0.009</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col15\" class=\"data row1 col15\" >0.0095</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col16\" class=\"data row1 col16\" >0.021</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col17\" class=\"data row1 col17\" >0.0095</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col18\" class=\"data row1 col18\" >-0.0038</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row1_col19\" class=\"data row1 col19\" >0.017</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72level0_row2\" class=\"row_heading level0 row2\" >area code</th>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col0\" class=\"data row2 col0\" >0.015</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col1\" class=\"data row2 col1\" >-0.015</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col2\" class=\"data row2 col2\" >1.0</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col3\" class=\"data row2 col3\" >0.044</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col4\" class=\"data row2 col4\" >0.0099</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col5\" class=\"data row2 col5\" >0.0091</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col6\" class=\"data row2 col6\" >0.01</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col7\" class=\"data row2 col7\" >-0.0071</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col8\" class=\"data row2 col8\" >0.01</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col9\" class=\"data row2 col9\" >0.00028</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col10\" class=\"data row2 col10\" >-0.0021</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col11\" class=\"data row2 col11\" >0.0003</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col12\" class=\"data row2 col12\" >0.0071</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col13\" class=\"data row2 col13\" >0.028</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col14\" class=\"data row2 col14\" >0.0071</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col15\" class=\"data row2 col15\" >0.0015</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col16\" class=\"data row2 col16\" >-0.0081</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col17\" class=\"data row2 col17\" >0.0014</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col18\" class=\"data row2 col18\" >0.028</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row2_col19\" class=\"data row2 col19\" >0.0033</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72level0_row3\" class=\"row_heading level0 row3\" >international plan</th>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col0\" class=\"data row3 col0\" >-0.0046</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col1\" class=\"data row3 col1\" >0.025</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col2\" class=\"data row3 col2\" >0.044</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col3\" class=\"data row3 col3\" >1.0</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col4\" class=\"data row3 col4\" >0.006</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col5\" class=\"data row3 col5\" >0.0087</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col6\" class=\"data row3 col6\" >0.049</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col7\" class=\"data row3 col7\" >0.0038</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col8\" class=\"data row3 col8\" >0.049</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col9\" class=\"data row3 col9\" >0.019</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col10\" class=\"data row3 col10\" >0.0061</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col11\" class=\"data row3 col11\" >0.019</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col12\" class=\"data row3 col12\" >-0.029</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col13\" class=\"data row3 col13\" >0.012</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col14\" class=\"data row3 col14\" >-0.029</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col15\" class=\"data row3 col15\" >0.046</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col16\" class=\"data row3 col16\" >0.017</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col17\" class=\"data row3 col17\" >0.046</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col18\" class=\"data row3 col18\" >-0.025</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row3_col19\" class=\"data row3 col19\" >0.26</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72level0_row4\" class=\"row_heading level0 row4\" >voice mail plan</th>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col0\" class=\"data row4 col0\" >-0.032</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col1\" class=\"data row4 col1\" >0.0029</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col2\" class=\"data row4 col2\" >0.0099</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col3\" class=\"data row4 col3\" >0.006</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col4\" class=\"data row4 col4\" >1.0</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col5\" class=\"data row4 col5\" >0.96</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col6\" class=\"data row4 col6\" >-0.0017</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col7\" class=\"data row4 col7\" >-0.011</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col8\" class=\"data row4 col8\" >-0.0017</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col9\" class=\"data row4 col9\" >0.022</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col10\" class=\"data row4 col10\" >-0.0064</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col11\" class=\"data row4 col11\" >0.022</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col12\" class=\"data row4 col12\" >0.0061</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col13\" class=\"data row4 col13\" >0.016</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col14\" class=\"data row4 col14\" >0.0061</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col15\" class=\"data row4 col15\" >-0.0013</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col16\" class=\"data row4 col16\" >0.0076</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col17\" class=\"data row4 col17\" >-0.0013</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col18\" class=\"data row4 col18\" >-0.018</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row4_col19\" class=\"data row4 col19\" >-0.1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72level0_row5\" class=\"row_heading level0 row5\" >number vmail messages</th>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col0\" class=\"data row5 col0\" >-0.028</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col1\" class=\"data row5 col1\" >-0.0046</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col2\" class=\"data row5 col2\" >0.0091</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col3\" class=\"data row5 col3\" >0.0087</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col4\" class=\"data row5 col4\" >0.96</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col5\" class=\"data row5 col5\" >1.0</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col6\" class=\"data row5 col6\" >0.00078</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col7\" class=\"data row5 col7\" >-0.0095</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col8\" class=\"data row5 col8\" >0.00078</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col9\" class=\"data row5 col9\" >0.018</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col10\" class=\"data row5 col10\" >-0.0059</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col11\" class=\"data row5 col11\" >0.018</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col12\" class=\"data row5 col12\" >0.0077</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col13\" class=\"data row5 col13\" >0.0071</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col14\" class=\"data row5 col14\" >0.0077</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col15\" class=\"data row5 col15\" >0.0029</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col16\" class=\"data row5 col16\" >0.014</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col17\" class=\"data row5 col17\" >0.0029</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col18\" class=\"data row5 col18\" >-0.013</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row5_col19\" class=\"data row5 col19\" >-0.09</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72level0_row6\" class=\"row_heading level0 row6\" >total day minutes</th>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col0\" class=\"data row6 col0\" >-0.0067</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col1\" class=\"data row6 col1\" >0.0062</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col2\" class=\"data row6 col2\" >0.01</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col3\" class=\"data row6 col3\" >0.049</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col4\" class=\"data row6 col4\" >-0.0017</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col5\" class=\"data row6 col5\" >0.00078</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col6\" class=\"data row6 col6\" >1.0</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col7\" class=\"data row6 col7\" >0.0068</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col8\" class=\"data row6 col8\" >1.0</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col9\" class=\"data row6 col9\" >0.007</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col10\" class=\"data row6 col10\" >0.016</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col11\" class=\"data row6 col11\" >0.007</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col12\" class=\"data row6 col12\" >0.0043</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col13\" class=\"data row6 col13\" >0.023</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col14\" class=\"data row6 col14\" >0.0043</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col15\" class=\"data row6 col15\" >-0.01</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col16\" class=\"data row6 col16\" >0.008</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col17\" class=\"data row6 col17\" >-0.01</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col18\" class=\"data row6 col18\" >-0.013</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row6_col19\" class=\"data row6 col19\" >0.21</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72level0_row7\" class=\"row_heading level0 row7\" >total day calls</th>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col0\" class=\"data row7 col0\" >-0.00076</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col1\" class=\"data row7 col1\" >0.038</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col2\" class=\"data row7 col2\" >-0.0071</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col3\" class=\"data row7 col3\" >0.0038</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col4\" class=\"data row7 col4\" >-0.011</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col5\" class=\"data row7 col5\" >-0.0095</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col6\" class=\"data row7 col6\" >0.0068</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col7\" class=\"data row7 col7\" >1.0</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col8\" class=\"data row7 col8\" >0.0068</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col9\" class=\"data row7 col9\" >-0.021</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col10\" class=\"data row7 col10\" >0.0065</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col11\" class=\"data row7 col11\" >-0.021</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col12\" class=\"data row7 col12\" >0.023</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col13\" class=\"data row7 col13\" >-0.02</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col14\" class=\"data row7 col14\" >0.023</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col15\" class=\"data row7 col15\" >0.022</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col16\" class=\"data row7 col16\" >0.0046</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col17\" class=\"data row7 col17\" >0.022</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col18\" class=\"data row7 col18\" >-0.019</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row7_col19\" class=\"data row7 col19\" >0.018</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72level0_row8\" class=\"row_heading level0 row8\" >total day charge</th>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col0\" class=\"data row8 col0\" >-0.0067</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col1\" class=\"data row8 col1\" >0.0062</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col2\" class=\"data row8 col2\" >0.01</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col3\" class=\"data row8 col3\" >0.049</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col4\" class=\"data row8 col4\" >-0.0017</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col5\" class=\"data row8 col5\" >0.00078</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col6\" class=\"data row8 col6\" >1.0</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col7\" class=\"data row8 col7\" >0.0068</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col8\" class=\"data row8 col8\" >1.0</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col9\" class=\"data row8 col9\" >0.007</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col10\" class=\"data row8 col10\" >0.016</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col11\" class=\"data row8 col11\" >0.007</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col12\" class=\"data row8 col12\" >0.0043</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col13\" class=\"data row8 col13\" >0.023</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col14\" class=\"data row8 col14\" >0.0043</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col15\" class=\"data row8 col15\" >-0.01</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col16\" class=\"data row8 col16\" >0.008</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col17\" class=\"data row8 col17\" >-0.01</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col18\" class=\"data row8 col18\" >-0.013</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row8_col19\" class=\"data row8 col19\" >0.21</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72level0_row9\" class=\"row_heading level0 row9\" >total eve minutes</th>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col0\" class=\"data row9 col0\" >0.014</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col1\" class=\"data row9 col1\" >-0.0068</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col2\" class=\"data row9 col2\" >0.00028</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col3\" class=\"data row9 col3\" >0.019</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col4\" class=\"data row9 col4\" >0.022</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col5\" class=\"data row9 col5\" >0.018</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col6\" class=\"data row9 col6\" >0.007</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col7\" class=\"data row9 col7\" >-0.021</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col8\" class=\"data row9 col8\" >0.007</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col9\" class=\"data row9 col9\" >1.0</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col10\" class=\"data row9 col10\" >-0.011</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col11\" class=\"data row9 col11\" >1.0</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col12\" class=\"data row9 col12\" >-0.013</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col13\" class=\"data row9 col13\" >0.0076</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col14\" class=\"data row9 col14\" >-0.013</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col15\" class=\"data row9 col15\" >-0.011</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col16\" class=\"data row9 col16\" >0.0025</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col17\" class=\"data row9 col17\" >-0.011</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col18\" class=\"data row9 col18\" >-0.013</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row9_col19\" class=\"data row9 col19\" >0.093</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72level0_row10\" class=\"row_heading level0 row10\" >total eve calls</th>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col0\" class=\"data row10 col0\" >-0.016</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col1\" class=\"data row10 col1\" >0.019</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col2\" class=\"data row10 col2\" >-0.0021</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col3\" class=\"data row10 col3\" >0.0061</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col4\" class=\"data row10 col4\" >-0.0064</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col5\" class=\"data row10 col5\" >-0.0059</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col6\" class=\"data row10 col6\" >0.016</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col7\" class=\"data row10 col7\" >0.0065</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col8\" class=\"data row10 col8\" >0.016</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col9\" class=\"data row10 col9\" >-0.011</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col10\" class=\"data row10 col10\" >1.0</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col11\" class=\"data row10 col11\" >-0.011</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col12\" class=\"data row10 col12\" >-0.0021</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col13\" class=\"data row10 col13\" >0.0077</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col14\" class=\"data row10 col14\" >-0.0021</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col15\" class=\"data row10 col15\" >0.0087</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col16\" class=\"data row10 col16\" >0.017</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col17\" class=\"data row10 col17\" >0.0087</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col18\" class=\"data row10 col18\" >0.0024</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row10_col19\" class=\"data row10 col19\" >0.0092</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72level0_row11\" class=\"row_heading level0 row11\" >total eve charge</th>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col0\" class=\"data row11 col0\" >0.014</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col1\" class=\"data row11 col1\" >-0.0067</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col2\" class=\"data row11 col2\" >0.0003</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col3\" class=\"data row11 col3\" >0.019</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col4\" class=\"data row11 col4\" >0.022</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col5\" class=\"data row11 col5\" >0.018</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col6\" class=\"data row11 col6\" >0.007</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col7\" class=\"data row11 col7\" >-0.021</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col8\" class=\"data row11 col8\" >0.007</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col9\" class=\"data row11 col9\" >1.0</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col10\" class=\"data row11 col10\" >-0.011</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col11\" class=\"data row11 col11\" >1.0</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col12\" class=\"data row11 col12\" >-0.013</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col13\" class=\"data row11 col13\" >0.0076</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col14\" class=\"data row11 col14\" >-0.013</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col15\" class=\"data row11 col15\" >-0.011</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col16\" class=\"data row11 col16\" >0.0025</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col17\" class=\"data row11 col17\" >-0.011</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col18\" class=\"data row11 col18\" >-0.013</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row11_col19\" class=\"data row11 col19\" >0.093</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72level0_row12\" class=\"row_heading level0 row12\" >total night minutes</th>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col0\" class=\"data row12 col0\" >0.025</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col1\" class=\"data row12 col1\" >-0.009</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col2\" class=\"data row12 col2\" >0.0071</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col3\" class=\"data row12 col3\" >-0.029</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col4\" class=\"data row12 col4\" >0.0061</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col5\" class=\"data row12 col5\" >0.0077</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col6\" class=\"data row12 col6\" >0.0043</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col7\" class=\"data row12 col7\" >0.023</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col8\" class=\"data row12 col8\" >0.0043</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col9\" class=\"data row12 col9\" >-0.013</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col10\" class=\"data row12 col10\" >-0.0021</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col11\" class=\"data row12 col11\" >-0.013</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col12\" class=\"data row12 col12\" >1.0</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col13\" class=\"data row12 col13\" >0.011</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col14\" class=\"data row12 col14\" >1.0</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col15\" class=\"data row12 col15\" >-0.015</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col16\" class=\"data row12 col16\" >-0.012</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col17\" class=\"data row12 col17\" >-0.015</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col18\" class=\"data row12 col18\" >-0.0093</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row12_col19\" class=\"data row12 col19\" >0.035</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72level0_row13\" class=\"row_heading level0 row13\" >total night calls</th>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col0\" class=\"data row13 col0\" >0.0075</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col1\" class=\"data row13 col1\" >-0.013</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col2\" class=\"data row13 col2\" >0.028</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col3\" class=\"data row13 col3\" >0.012</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col4\" class=\"data row13 col4\" >0.016</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col5\" class=\"data row13 col5\" >0.0071</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col6\" class=\"data row13 col6\" >0.023</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col7\" class=\"data row13 col7\" >-0.02</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col8\" class=\"data row13 col8\" >0.023</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col9\" class=\"data row13 col9\" >0.0076</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col10\" class=\"data row13 col10\" >0.0077</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col11\" class=\"data row13 col11\" >0.0076</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col12\" class=\"data row13 col12\" >0.011</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col13\" class=\"data row13 col13\" >1.0</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col14\" class=\"data row13 col14\" >0.011</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col15\" class=\"data row13 col15\" >-0.014</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col16\" class=\"data row13 col16\" >0.0003</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col17\" class=\"data row13 col17\" >-0.014</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col18\" class=\"data row13 col18\" >-0.013</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row13_col19\" class=\"data row13 col19\" >0.0061</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72level0_row14\" class=\"row_heading level0 row14\" >total night charge</th>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col0\" class=\"data row14 col0\" >0.025</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col1\" class=\"data row14 col1\" >-0.009</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col2\" class=\"data row14 col2\" >0.0071</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col3\" class=\"data row14 col3\" >-0.029</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col4\" class=\"data row14 col4\" >0.0061</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col5\" class=\"data row14 col5\" >0.0077</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col6\" class=\"data row14 col6\" >0.0043</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col7\" class=\"data row14 col7\" >0.023</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col8\" class=\"data row14 col8\" >0.0043</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col9\" class=\"data row14 col9\" >-0.013</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col10\" class=\"data row14 col10\" >-0.0021</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col11\" class=\"data row14 col11\" >-0.013</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col12\" class=\"data row14 col12\" >1.0</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col13\" class=\"data row14 col13\" >0.011</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col14\" class=\"data row14 col14\" >1.0</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col15\" class=\"data row14 col15\" >-0.015</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col16\" class=\"data row14 col16\" >-0.012</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col17\" class=\"data row14 col17\" >-0.015</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col18\" class=\"data row14 col18\" >-0.0093</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row14_col19\" class=\"data row14 col19\" >0.035</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72level0_row15\" class=\"row_heading level0 row15\" >total intl minutes</th>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col0\" class=\"data row15 col0\" >-0.0078</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col1\" class=\"data row15 col1\" >0.0095</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col2\" class=\"data row15 col2\" >0.0015</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col3\" class=\"data row15 col3\" >0.046</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col4\" class=\"data row15 col4\" >-0.0013</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col5\" class=\"data row15 col5\" >0.0029</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col6\" class=\"data row15 col6\" >-0.01</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col7\" class=\"data row15 col7\" >0.022</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col8\" class=\"data row15 col8\" >-0.01</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col9\" class=\"data row15 col9\" >-0.011</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col10\" class=\"data row15 col10\" >0.0087</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col11\" class=\"data row15 col11\" >-0.011</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col12\" class=\"data row15 col12\" >-0.015</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col13\" class=\"data row15 col13\" >-0.014</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col14\" class=\"data row15 col14\" >-0.015</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col15\" class=\"data row15 col15\" >1.0</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col16\" class=\"data row15 col16\" >0.032</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col17\" class=\"data row15 col17\" >1.0</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col18\" class=\"data row15 col18\" >-0.0096</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row15_col19\" class=\"data row15 col19\" >0.068</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72level0_row16\" class=\"row_heading level0 row16\" >total intl calls</th>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col0\" class=\"data row16 col0\" >0.014</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col1\" class=\"data row16 col1\" >0.021</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col2\" class=\"data row16 col2\" >-0.0081</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col3\" class=\"data row16 col3\" >0.017</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col4\" class=\"data row16 col4\" >0.0076</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col5\" class=\"data row16 col5\" >0.014</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col6\" class=\"data row16 col6\" >0.008</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col7\" class=\"data row16 col7\" >0.0046</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col8\" class=\"data row16 col8\" >0.008</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col9\" class=\"data row16 col9\" >0.0025</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col10\" class=\"data row16 col10\" >0.017</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col11\" class=\"data row16 col11\" >0.0025</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col12\" class=\"data row16 col12\" >-0.012</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col13\" class=\"data row16 col13\" >0.0003</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col14\" class=\"data row16 col14\" >-0.012</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col15\" class=\"data row16 col15\" >0.032</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col16\" class=\"data row16 col16\" >1.0</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col17\" class=\"data row16 col17\" >0.032</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col18\" class=\"data row16 col18\" >-0.018</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row16_col19\" class=\"data row16 col19\" >-0.053</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72level0_row17\" class=\"row_heading level0 row17\" >total intl charge</th>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col0\" class=\"data row17 col0\" >-0.0078</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col1\" class=\"data row17 col1\" >0.0095</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col2\" class=\"data row17 col2\" >0.0014</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col3\" class=\"data row17 col3\" >0.046</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col4\" class=\"data row17 col4\" >-0.0013</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col5\" class=\"data row17 col5\" >0.0029</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col6\" class=\"data row17 col6\" >-0.01</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col7\" class=\"data row17 col7\" >0.022</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col8\" class=\"data row17 col8\" >-0.01</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col9\" class=\"data row17 col9\" >-0.011</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col10\" class=\"data row17 col10\" >0.0087</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col11\" class=\"data row17 col11\" >-0.011</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col12\" class=\"data row17 col12\" >-0.015</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col13\" class=\"data row17 col13\" >-0.014</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col14\" class=\"data row17 col14\" >-0.015</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col15\" class=\"data row17 col15\" >1.0</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col16\" class=\"data row17 col16\" >0.032</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col17\" class=\"data row17 col17\" >1.0</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col18\" class=\"data row17 col18\" >-0.0097</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row17_col19\" class=\"data row17 col19\" >0.068</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72level0_row18\" class=\"row_heading level0 row18\" >customer service calls</th>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col0\" class=\"data row18 col0\" >-0.026</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col1\" class=\"data row18 col1\" >-0.0038</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col2\" class=\"data row18 col2\" >0.028</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col3\" class=\"data row18 col3\" >-0.025</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col4\" class=\"data row18 col4\" >-0.018</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col5\" class=\"data row18 col5\" >-0.013</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col6\" class=\"data row18 col6\" >-0.013</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col7\" class=\"data row18 col7\" >-0.019</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col8\" class=\"data row18 col8\" >-0.013</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col9\" class=\"data row18 col9\" >-0.013</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col10\" class=\"data row18 col10\" >0.0024</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col11\" class=\"data row18 col11\" >-0.013</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col12\" class=\"data row18 col12\" >-0.0093</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col13\" class=\"data row18 col13\" >-0.013</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col14\" class=\"data row18 col14\" >-0.0093</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col15\" class=\"data row18 col15\" >-0.0096</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col16\" class=\"data row18 col16\" >-0.018</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col17\" class=\"data row18 col17\" >-0.0097</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col18\" class=\"data row18 col18\" >1.0</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row18_col19\" class=\"data row18 col19\" >0.21</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72level0_row19\" class=\"row_heading level0 row19\" >churn</th>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col0\" class=\"data row19 col0\" >0.0078</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col1\" class=\"data row19 col1\" >0.017</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col2\" class=\"data row19 col2\" >0.0033</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col3\" class=\"data row19 col3\" >0.26</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col4\" class=\"data row19 col4\" >-0.1</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col5\" class=\"data row19 col5\" >-0.09</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col6\" class=\"data row19 col6\" >0.21</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col7\" class=\"data row19 col7\" >0.018</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col8\" class=\"data row19 col8\" >0.21</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col9\" class=\"data row19 col9\" >0.093</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col10\" class=\"data row19 col10\" >0.0092</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col11\" class=\"data row19 col11\" >0.093</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col12\" class=\"data row19 col12\" >0.035</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col13\" class=\"data row19 col13\" >0.0061</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col14\" class=\"data row19 col14\" >0.035</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col15\" class=\"data row19 col15\" >0.068</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col16\" class=\"data row19 col16\" >-0.053</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col17\" class=\"data row19 col17\" >0.068</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col18\" class=\"data row19 col18\" >0.21</td>\n",
       "                        <td id=\"T_26d0c88a_7e82_11ea_849a_98460a95cf72row19_col19\" class=\"data row19 col19\" >1.0</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1a25b49090>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr(method='pearson').style.format(\"{:.2}\").background_gradient(cmap=plt.get_cmap('coolwarm'), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no major correlation across any features apart from voicemail messages and active voicemail plan (it makes sense people with a voicemail plan wouls send more VM messages). Also, we have a perfect correlation between minutes and expenses charge, highlighting the fact that the company charges on a per minute basis across every time of the day day/evening/night."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we are dropping area code and State for the modelling because we are doing this for a Syrian company with marketshare exclusive to Syria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['area code', 'state'], axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2850\n",
       "1     483\n",
       "Name: churn, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting target variable into integers\n",
    "df['churn'] = df['churn'].astype(int)\n",
    "df['churn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# setting up the y target and X dataset\n",
    "y = df['churn']\n",
    "X = df.drop('churn', axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3333 entries, 0 to 3332\n",
      "Data columns (total 17 columns):\n",
      "account length            3333 non-null int64\n",
      "international plan        3333 non-null int64\n",
      "voice mail plan           3333 non-null int64\n",
      "number vmail messages     3333 non-null int64\n",
      "total day minutes         3333 non-null float64\n",
      "total day calls           3333 non-null int64\n",
      "total day charge          3333 non-null float64\n",
      "total eve minutes         3333 non-null float64\n",
      "total eve calls           3333 non-null int64\n",
      "total eve charge          3333 non-null float64\n",
      "total night minutes       3333 non-null float64\n",
      "total night calls         3333 non-null int64\n",
      "total night charge        3333 non-null float64\n",
      "total intl minutes        3333 non-null float64\n",
      "total intl calls          3333 non-null int64\n",
      "total intl charge         3333 non-null float64\n",
      "customer service calls    3333 non-null int64\n",
      "dtypes: float64(8), int64(9)\n",
      "memory usage: 442.8 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My training set is (2333, 17)\n",
      "My final test set is (1000, 17)\n",
      "My training set dependant variable is (2333,)\n",
      "My test set dependant variable is (1000,)\n"
     ]
    }
   ],
   "source": [
    "# splitting initial training data and test data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state = 42)\n",
    "\n",
    "print(f'My training set is {X_train.shape}')\n",
    "print(f'My final test set is {X_test.shape}')\n",
    "print(f'My training set dependant variable is {y_train.shape}')\n",
    "print(f'My test set dependant variable is {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8433266432513798"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline model using bayes naive learner\n",
    "\n",
    "# setting up the learner\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# fitting the model and predict\n",
    "model_naive = gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_naive.predict_proba(X_train)[:,1]\n",
    "# y_pred_50 = model_naive.predict(X_train)\n",
    "# len(y_pred)\n",
    "# model_naive \n",
    "\n",
    "roc_auc_score (y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Performance Evaluation Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00848751]),\n",
       " 'std_fit_time': array([0.00420884]),\n",
       " 'mean_score_time': array([0.00551701]),\n",
       " 'std_score_time': array([0.00236416]),\n",
       " 'param_var_smoothing': masked_array(data=[1e-09],\n",
       "              mask=[False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'var_smoothing': 1e-09}],\n",
       " 'split0_test_score': array([0.8725]),\n",
       " 'split1_test_score': array([0.82323529]),\n",
       " 'split2_test_score': array([0.90044118]),\n",
       " 'split3_test_score': array([0.85545374]),\n",
       " 'split4_test_score': array([0.85634053]),\n",
       " 'split5_test_score': array([0.83904818]),\n",
       " 'split6_test_score': array([0.70662134]),\n",
       " 'split7_test_score': array([0.84850724]),\n",
       " 'split8_test_score': array([0.82279042]),\n",
       " 'split9_test_score': array([0.84274313]),\n",
       " 'mean_test_score': array([0.83680491]),\n",
       " 'std_test_score': array([0.04853039]),\n",
       " 'rank_test_score': array([1], dtype=int32),\n",
       " 'split0_train_score': array([0.84042701]),\n",
       " 'split1_train_score': array([0.84728374]),\n",
       " 'split2_train_score': array([0.83806123]),\n",
       " 'split3_train_score': array([0.84357809]),\n",
       " 'split4_train_score': array([0.83975998]),\n",
       " 'split5_train_score': array([0.84491333]),\n",
       " 'split6_train_score': array([0.85573371]),\n",
       " 'split7_train_score': array([0.84154152]),\n",
       " 'split8_train_score': array([0.84472024]),\n",
       " 'split9_train_score': array([0.84147594]),\n",
       " 'mean_train_score': array([0.84374948]),\n",
       " 'std_train_score': array([0.00477278])}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits = 10, random_state = 600)\n",
    "\n",
    "param_grid = {'var_smoothing': [1e-09]}\n",
    "\n",
    "opt_model = GridSearchCV(model_naive,\n",
    "                         param_grid,\n",
    "                         cv=skf,\n",
    "                         scoring='roc_auc',\n",
    "                         return_train_score=True)\n",
    "opt_model.fit(X_train,y_train)\n",
    "\n",
    "opt_model.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation baseline roc_auc score is mean 0.8374 std 0.04\n",
      "The training baseline roc_auc_score is mean 0.8448 std 0.004 \n"
     ]
    }
   ],
   "source": [
    "print('The validation baseline roc_auc score is mean 0.8374 std 0.04')\n",
    "print('The training baseline roc_auc_score is mean 0.8448 std 0.004 ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning on 3 Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=2,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=10, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=40, splitter='best')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# setting up the learner\n",
    "model_tree = DecisionTreeClassifier(max_depth=2,min_samples_leaf=10,random_state=40, class_weight = 'balanced' )\n",
    "# fitting the model\n",
    "model_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7525611699772734"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicted values for unoptimised decision tree\n",
    "y_hat = model_tree.predict_proba(X_train)[:,1]\n",
    "# calculating initial roc_score for the decision tree\n",
    "initial_score_roc_auc = roc_auc_score (y_train, y_hat)\n",
    "initial_score_roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.009211</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.004245</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 5}</td>\n",
       "      <td>0.590147</td>\n",
       "      <td>0.568235</td>\n",
       "      <td>0.641471</td>\n",
       "      <td>0.572790</td>\n",
       "      <td>0.619051</td>\n",
       "      <td>0.610774</td>\n",
       "      <td>0.557715</td>\n",
       "      <td>0.565253</td>\n",
       "      <td>0.638782</td>\n",
       "      <td>0.666051</td>\n",
       "      <td>0.603023</td>\n",
       "      <td>0.035793</td>\n",
       "      <td>66</td>\n",
       "      <td>0.634240</td>\n",
       "      <td>0.622837</td>\n",
       "      <td>0.633365</td>\n",
       "      <td>0.622330</td>\n",
       "      <td>0.635856</td>\n",
       "      <td>0.652671</td>\n",
       "      <td>0.642671</td>\n",
       "      <td>0.641834</td>\n",
       "      <td>0.633665</td>\n",
       "      <td>0.630637</td>\n",
       "      <td>0.635011</td>\n",
       "      <td>0.008666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.006561</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>0.002540</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 10}</td>\n",
       "      <td>0.590147</td>\n",
       "      <td>0.568235</td>\n",
       "      <td>0.641471</td>\n",
       "      <td>0.572790</td>\n",
       "      <td>0.619051</td>\n",
       "      <td>0.610774</td>\n",
       "      <td>0.557715</td>\n",
       "      <td>0.565253</td>\n",
       "      <td>0.638782</td>\n",
       "      <td>0.666051</td>\n",
       "      <td>0.603023</td>\n",
       "      <td>0.035793</td>\n",
       "      <td>66</td>\n",
       "      <td>0.634240</td>\n",
       "      <td>0.622837</td>\n",
       "      <td>0.633365</td>\n",
       "      <td>0.622330</td>\n",
       "      <td>0.635856</td>\n",
       "      <td>0.652671</td>\n",
       "      <td>0.642671</td>\n",
       "      <td>0.641834</td>\n",
       "      <td>0.633665</td>\n",
       "      <td>0.630637</td>\n",
       "      <td>0.635011</td>\n",
       "      <td>0.008666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.005581</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 15}</td>\n",
       "      <td>0.590147</td>\n",
       "      <td>0.568235</td>\n",
       "      <td>0.641471</td>\n",
       "      <td>0.572790</td>\n",
       "      <td>0.619051</td>\n",
       "      <td>0.610774</td>\n",
       "      <td>0.557715</td>\n",
       "      <td>0.565253</td>\n",
       "      <td>0.638782</td>\n",
       "      <td>0.666051</td>\n",
       "      <td>0.603023</td>\n",
       "      <td>0.035793</td>\n",
       "      <td>66</td>\n",
       "      <td>0.634240</td>\n",
       "      <td>0.622837</td>\n",
       "      <td>0.633365</td>\n",
       "      <td>0.622330</td>\n",
       "      <td>0.635856</td>\n",
       "      <td>0.652671</td>\n",
       "      <td>0.642671</td>\n",
       "      <td>0.641834</td>\n",
       "      <td>0.633665</td>\n",
       "      <td>0.630637</td>\n",
       "      <td>0.635011</td>\n",
       "      <td>0.008666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.005593</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.002286</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 20}</td>\n",
       "      <td>0.590147</td>\n",
       "      <td>0.568235</td>\n",
       "      <td>0.641471</td>\n",
       "      <td>0.572790</td>\n",
       "      <td>0.619051</td>\n",
       "      <td>0.610774</td>\n",
       "      <td>0.557715</td>\n",
       "      <td>0.565253</td>\n",
       "      <td>0.638782</td>\n",
       "      <td>0.666051</td>\n",
       "      <td>0.603023</td>\n",
       "      <td>0.035793</td>\n",
       "      <td>66</td>\n",
       "      <td>0.634240</td>\n",
       "      <td>0.622837</td>\n",
       "      <td>0.633365</td>\n",
       "      <td>0.622330</td>\n",
       "      <td>0.635856</td>\n",
       "      <td>0.652671</td>\n",
       "      <td>0.642671</td>\n",
       "      <td>0.641834</td>\n",
       "      <td>0.633665</td>\n",
       "      <td>0.630637</td>\n",
       "      <td>0.635011</td>\n",
       "      <td>0.008666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.005544</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 25}</td>\n",
       "      <td>0.590147</td>\n",
       "      <td>0.568235</td>\n",
       "      <td>0.641471</td>\n",
       "      <td>0.572790</td>\n",
       "      <td>0.619051</td>\n",
       "      <td>0.610774</td>\n",
       "      <td>0.557715</td>\n",
       "      <td>0.565253</td>\n",
       "      <td>0.638782</td>\n",
       "      <td>0.666051</td>\n",
       "      <td>0.603023</td>\n",
       "      <td>0.035793</td>\n",
       "      <td>66</td>\n",
       "      <td>0.634240</td>\n",
       "      <td>0.622837</td>\n",
       "      <td>0.633365</td>\n",
       "      <td>0.622330</td>\n",
       "      <td>0.635856</td>\n",
       "      <td>0.652671</td>\n",
       "      <td>0.642671</td>\n",
       "      <td>0.641834</td>\n",
       "      <td>0.633665</td>\n",
       "      <td>0.630637</td>\n",
       "      <td>0.635011</td>\n",
       "      <td>0.008666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.020961</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 14, 'min_samples_leaf': 5}</td>\n",
       "      <td>0.854559</td>\n",
       "      <td>0.791912</td>\n",
       "      <td>0.905662</td>\n",
       "      <td>0.812666</td>\n",
       "      <td>0.883018</td>\n",
       "      <td>0.838900</td>\n",
       "      <td>0.824933</td>\n",
       "      <td>0.862918</td>\n",
       "      <td>0.818800</td>\n",
       "      <td>0.877845</td>\n",
       "      <td>0.847126</td>\n",
       "      <td>0.034022</td>\n",
       "      <td>51</td>\n",
       "      <td>0.989204</td>\n",
       "      <td>0.990688</td>\n",
       "      <td>0.987673</td>\n",
       "      <td>0.991688</td>\n",
       "      <td>0.990636</td>\n",
       "      <td>0.992968</td>\n",
       "      <td>0.994459</td>\n",
       "      <td>0.990365</td>\n",
       "      <td>0.990370</td>\n",
       "      <td>0.990069</td>\n",
       "      <td>0.990812</td>\n",
       "      <td>0.001793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.019089</td>\n",
       "      <td>0.001397</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 14, 'min_samples_leaf': 10}</td>\n",
       "      <td>0.904632</td>\n",
       "      <td>0.789779</td>\n",
       "      <td>0.880147</td>\n",
       "      <td>0.875185</td>\n",
       "      <td>0.891960</td>\n",
       "      <td>0.858705</td>\n",
       "      <td>0.827520</td>\n",
       "      <td>0.852719</td>\n",
       "      <td>0.881614</td>\n",
       "      <td>0.923884</td>\n",
       "      <td>0.868601</td>\n",
       "      <td>0.036759</td>\n",
       "      <td>16</td>\n",
       "      <td>0.982599</td>\n",
       "      <td>0.980334</td>\n",
       "      <td>0.983218</td>\n",
       "      <td>0.984262</td>\n",
       "      <td>0.983651</td>\n",
       "      <td>0.982975</td>\n",
       "      <td>0.986627</td>\n",
       "      <td>0.982259</td>\n",
       "      <td>0.982054</td>\n",
       "      <td>0.981900</td>\n",
       "      <td>0.982988</td>\n",
       "      <td>0.001585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.018642</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 14, 'min_samples_leaf': 15}</td>\n",
       "      <td>0.887279</td>\n",
       "      <td>0.798603</td>\n",
       "      <td>0.895956</td>\n",
       "      <td>0.812740</td>\n",
       "      <td>0.916568</td>\n",
       "      <td>0.857006</td>\n",
       "      <td>0.843852</td>\n",
       "      <td>0.880949</td>\n",
       "      <td>0.879619</td>\n",
       "      <td>0.926544</td>\n",
       "      <td>0.869900</td>\n",
       "      <td>0.039730</td>\n",
       "      <td>7</td>\n",
       "      <td>0.975125</td>\n",
       "      <td>0.976739</td>\n",
       "      <td>0.977748</td>\n",
       "      <td>0.975375</td>\n",
       "      <td>0.977677</td>\n",
       "      <td>0.974868</td>\n",
       "      <td>0.979805</td>\n",
       "      <td>0.972948</td>\n",
       "      <td>0.976556</td>\n",
       "      <td>0.974712</td>\n",
       "      <td>0.976155</td>\n",
       "      <td>0.001854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.017997</td>\n",
       "      <td>0.001349</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 14, 'min_samples_leaf': 20}</td>\n",
       "      <td>0.859338</td>\n",
       "      <td>0.773162</td>\n",
       "      <td>0.886765</td>\n",
       "      <td>0.839048</td>\n",
       "      <td>0.898167</td>\n",
       "      <td>0.859592</td>\n",
       "      <td>0.837053</td>\n",
       "      <td>0.874520</td>\n",
       "      <td>0.873559</td>\n",
       "      <td>0.894325</td>\n",
       "      <td>0.859527</td>\n",
       "      <td>0.035029</td>\n",
       "      <td>33</td>\n",
       "      <td>0.968821</td>\n",
       "      <td>0.968370</td>\n",
       "      <td>0.968491</td>\n",
       "      <td>0.967717</td>\n",
       "      <td>0.967918</td>\n",
       "      <td>0.970851</td>\n",
       "      <td>0.971070</td>\n",
       "      <td>0.968258</td>\n",
       "      <td>0.970051</td>\n",
       "      <td>0.968189</td>\n",
       "      <td>0.968974</td>\n",
       "      <td>0.001163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.017417</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.002372</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>14</td>\n",
       "      <td>25</td>\n",
       "      <td>{'max_depth': 14, 'min_samples_leaf': 25}</td>\n",
       "      <td>0.885368</td>\n",
       "      <td>0.779779</td>\n",
       "      <td>0.897794</td>\n",
       "      <td>0.835132</td>\n",
       "      <td>0.913686</td>\n",
       "      <td>0.862031</td>\n",
       "      <td>0.850281</td>\n",
       "      <td>0.878880</td>\n",
       "      <td>0.896542</td>\n",
       "      <td>0.888339</td>\n",
       "      <td>0.868764</td>\n",
       "      <td>0.037217</td>\n",
       "      <td>13</td>\n",
       "      <td>0.959846</td>\n",
       "      <td>0.960861</td>\n",
       "      <td>0.956503</td>\n",
       "      <td>0.960768</td>\n",
       "      <td>0.962291</td>\n",
       "      <td>0.958594</td>\n",
       "      <td>0.966351</td>\n",
       "      <td>0.957590</td>\n",
       "      <td>0.965586</td>\n",
       "      <td>0.959328</td>\n",
       "      <td>0.960772</td>\n",
       "      <td>0.003044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.009211      0.002892         0.004245        0.002489   \n",
       "1        0.006561      0.001898         0.002540        0.000541   \n",
       "2        0.005581      0.000498         0.002555        0.000619   \n",
       "3        0.005593      0.000281         0.002286        0.000261   \n",
       "4        0.005544      0.000437         0.002182        0.000201   \n",
       "..            ...           ...              ...             ...   \n",
       "65       0.020961      0.001222         0.002492        0.000191   \n",
       "66       0.019089      0.001397         0.002320        0.000093   \n",
       "67       0.018642      0.001035         0.002384        0.000139   \n",
       "68       0.017997      0.001349         0.002577        0.000495   \n",
       "69       0.017417      0.000808         0.002372        0.000121   \n",
       "\n",
       "   param_max_depth param_min_samples_leaf  \\\n",
       "0                1                      5   \n",
       "1                1                     10   \n",
       "2                1                     15   \n",
       "3                1                     20   \n",
       "4                1                     25   \n",
       "..             ...                    ...   \n",
       "65              14                      5   \n",
       "66              14                     10   \n",
       "67              14                     15   \n",
       "68              14                     20   \n",
       "69              14                     25   \n",
       "\n",
       "                                       params  split0_test_score  \\\n",
       "0     {'max_depth': 1, 'min_samples_leaf': 5}           0.590147   \n",
       "1    {'max_depth': 1, 'min_samples_leaf': 10}           0.590147   \n",
       "2    {'max_depth': 1, 'min_samples_leaf': 15}           0.590147   \n",
       "3    {'max_depth': 1, 'min_samples_leaf': 20}           0.590147   \n",
       "4    {'max_depth': 1, 'min_samples_leaf': 25}           0.590147   \n",
       "..                                        ...                ...   \n",
       "65   {'max_depth': 14, 'min_samples_leaf': 5}           0.854559   \n",
       "66  {'max_depth': 14, 'min_samples_leaf': 10}           0.904632   \n",
       "67  {'max_depth': 14, 'min_samples_leaf': 15}           0.887279   \n",
       "68  {'max_depth': 14, 'min_samples_leaf': 20}           0.859338   \n",
       "69  {'max_depth': 14, 'min_samples_leaf': 25}           0.885368   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.568235           0.641471           0.572790   \n",
       "1            0.568235           0.641471           0.572790   \n",
       "2            0.568235           0.641471           0.572790   \n",
       "3            0.568235           0.641471           0.572790   \n",
       "4            0.568235           0.641471           0.572790   \n",
       "..                ...                ...                ...   \n",
       "65           0.791912           0.905662           0.812666   \n",
       "66           0.789779           0.880147           0.875185   \n",
       "67           0.798603           0.895956           0.812740   \n",
       "68           0.773162           0.886765           0.839048   \n",
       "69           0.779779           0.897794           0.835132   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0            0.619051           0.610774           0.557715   \n",
       "1            0.619051           0.610774           0.557715   \n",
       "2            0.619051           0.610774           0.557715   \n",
       "3            0.619051           0.610774           0.557715   \n",
       "4            0.619051           0.610774           0.557715   \n",
       "..                ...                ...                ...   \n",
       "65           0.883018           0.838900           0.824933   \n",
       "66           0.891960           0.858705           0.827520   \n",
       "67           0.916568           0.857006           0.843852   \n",
       "68           0.898167           0.859592           0.837053   \n",
       "69           0.913686           0.862031           0.850281   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0            0.565253           0.638782           0.666051         0.603023   \n",
       "1            0.565253           0.638782           0.666051         0.603023   \n",
       "2            0.565253           0.638782           0.666051         0.603023   \n",
       "3            0.565253           0.638782           0.666051         0.603023   \n",
       "4            0.565253           0.638782           0.666051         0.603023   \n",
       "..                ...                ...                ...              ...   \n",
       "65           0.862918           0.818800           0.877845         0.847126   \n",
       "66           0.852719           0.881614           0.923884         0.868601   \n",
       "67           0.880949           0.879619           0.926544         0.869900   \n",
       "68           0.874520           0.873559           0.894325         0.859527   \n",
       "69           0.878880           0.896542           0.888339         0.868764   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0         0.035793               66            0.634240            0.622837   \n",
       "1         0.035793               66            0.634240            0.622837   \n",
       "2         0.035793               66            0.634240            0.622837   \n",
       "3         0.035793               66            0.634240            0.622837   \n",
       "4         0.035793               66            0.634240            0.622837   \n",
       "..             ...              ...                 ...                 ...   \n",
       "65        0.034022               51            0.989204            0.990688   \n",
       "66        0.036759               16            0.982599            0.980334   \n",
       "67        0.039730                7            0.975125            0.976739   \n",
       "68        0.035029               33            0.968821            0.968370   \n",
       "69        0.037217               13            0.959846            0.960861   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0             0.633365            0.622330            0.635856   \n",
       "1             0.633365            0.622330            0.635856   \n",
       "2             0.633365            0.622330            0.635856   \n",
       "3             0.633365            0.622330            0.635856   \n",
       "4             0.633365            0.622330            0.635856   \n",
       "..                 ...                 ...                 ...   \n",
       "65            0.987673            0.991688            0.990636   \n",
       "66            0.983218            0.984262            0.983651   \n",
       "67            0.977748            0.975375            0.977677   \n",
       "68            0.968491            0.967717            0.967918   \n",
       "69            0.956503            0.960768            0.962291   \n",
       "\n",
       "    split5_train_score  split6_train_score  split7_train_score  \\\n",
       "0             0.652671            0.642671            0.641834   \n",
       "1             0.652671            0.642671            0.641834   \n",
       "2             0.652671            0.642671            0.641834   \n",
       "3             0.652671            0.642671            0.641834   \n",
       "4             0.652671            0.642671            0.641834   \n",
       "..                 ...                 ...                 ...   \n",
       "65            0.992968            0.994459            0.990365   \n",
       "66            0.982975            0.986627            0.982259   \n",
       "67            0.974868            0.979805            0.972948   \n",
       "68            0.970851            0.971070            0.968258   \n",
       "69            0.958594            0.966351            0.957590   \n",
       "\n",
       "    split8_train_score  split9_train_score  mean_train_score  std_train_score  \n",
       "0             0.633665            0.630637          0.635011         0.008666  \n",
       "1             0.633665            0.630637          0.635011         0.008666  \n",
       "2             0.633665            0.630637          0.635011         0.008666  \n",
       "3             0.633665            0.630637          0.635011         0.008666  \n",
       "4             0.633665            0.630637          0.635011         0.008666  \n",
       "..                 ...                 ...               ...              ...  \n",
       "65            0.990370            0.990069          0.990812         0.001793  \n",
       "66            0.982054            0.981900          0.982988         0.001585  \n",
       "67            0.976556            0.974712          0.976155         0.001854  \n",
       "68            0.970051            0.968189          0.968974         0.001163  \n",
       "69            0.965586            0.959328          0.960772         0.003044  \n",
       "\n",
       "[70 rows x 32 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying hyperparameter optimisation\n",
    "skf = StratifiedKFold(n_splits = 10, random_state = 600)\n",
    "\n",
    "param_grid = {'max_depth': range(1,15), 'min_samples_leaf': [5,10,15, 20,25] }\n",
    "\n",
    "opt_model_tree = GridSearchCV(model_tree,\n",
    "                         param_grid,\n",
    "                         cv=skf,\n",
    "                         scoring='roc_auc',\n",
    "                         return_train_score=True)\n",
    "opt_model_tree.fit(X_train,y_train)\n",
    "\n",
    "pd.DataFrame(opt_model_tree.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values of the optimised hyperparameters for the best model found:\n",
      " {'max_depth': 11, 'min_samples_leaf': 10}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.875922288442287"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best hyperparameters and roc_auc score\n",
    "print('Values of the optimised hyperparameters for the best model found:\\n', opt_model.best_params_)\n",
    "opt_model_tree.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier and Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=15, max_features='auto',\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=20,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                       random_state=11, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up the learner and fitting\n",
    "model_random_forest = RandomForestClassifier(n_estimators=100, \n",
    "                                             random_state = 11, \n",
    "                                             class_weight= 'balanced',\n",
    "                                             max_depth = 15,\n",
    "                                             min_samples_leaf= 20 \n",
    "                                             )\n",
    "model_random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roc_score is  0.9702753755792332\n"
     ]
    }
   ],
   "source": [
    "# estimating initial performance\n",
    "y_hat_random = model_random_forest.predict_proba(X_train)[:,1]\n",
    "print('Roc_score is ',roc_auc_score(y_train, y_hat_random))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear signs of overfitting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.214973</td>\n",
       "      <td>0.056841</td>\n",
       "      <td>0.014358</td>\n",
       "      <td>0.009164</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 5}</td>\n",
       "      <td>0.845735</td>\n",
       "      <td>0.844044</td>\n",
       "      <td>0.915588</td>\n",
       "      <td>0.821017</td>\n",
       "      <td>0.850946</td>\n",
       "      <td>0.804685</td>\n",
       "      <td>0.718889</td>\n",
       "      <td>0.834023</td>\n",
       "      <td>0.838014</td>\n",
       "      <td>0.901641</td>\n",
       "      <td>0.837498</td>\n",
       "      <td>0.050918</td>\n",
       "      <td>66</td>\n",
       "      <td>0.857834</td>\n",
       "      <td>0.864395</td>\n",
       "      <td>0.853336</td>\n",
       "      <td>0.860551</td>\n",
       "      <td>0.855113</td>\n",
       "      <td>0.840393</td>\n",
       "      <td>0.854339</td>\n",
       "      <td>0.846937</td>\n",
       "      <td>0.843216</td>\n",
       "      <td>0.851320</td>\n",
       "      <td>0.852743</td>\n",
       "      <td>0.007143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.204097</td>\n",
       "      <td>0.012916</td>\n",
       "      <td>0.011413</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 10}</td>\n",
       "      <td>0.845735</td>\n",
       "      <td>0.844044</td>\n",
       "      <td>0.915588</td>\n",
       "      <td>0.821017</td>\n",
       "      <td>0.850946</td>\n",
       "      <td>0.804685</td>\n",
       "      <td>0.718889</td>\n",
       "      <td>0.834023</td>\n",
       "      <td>0.838014</td>\n",
       "      <td>0.901641</td>\n",
       "      <td>0.837498</td>\n",
       "      <td>0.050918</td>\n",
       "      <td>66</td>\n",
       "      <td>0.857834</td>\n",
       "      <td>0.864395</td>\n",
       "      <td>0.853336</td>\n",
       "      <td>0.860551</td>\n",
       "      <td>0.855113</td>\n",
       "      <td>0.840393</td>\n",
       "      <td>0.854339</td>\n",
       "      <td>0.846937</td>\n",
       "      <td>0.843216</td>\n",
       "      <td>0.851320</td>\n",
       "      <td>0.852743</td>\n",
       "      <td>0.007143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.193083</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.010512</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 15}</td>\n",
       "      <td>0.845735</td>\n",
       "      <td>0.844044</td>\n",
       "      <td>0.915588</td>\n",
       "      <td>0.821017</td>\n",
       "      <td>0.850946</td>\n",
       "      <td>0.804685</td>\n",
       "      <td>0.718889</td>\n",
       "      <td>0.834023</td>\n",
       "      <td>0.838014</td>\n",
       "      <td>0.901641</td>\n",
       "      <td>0.837498</td>\n",
       "      <td>0.050918</td>\n",
       "      <td>66</td>\n",
       "      <td>0.857834</td>\n",
       "      <td>0.864395</td>\n",
       "      <td>0.853336</td>\n",
       "      <td>0.860551</td>\n",
       "      <td>0.855113</td>\n",
       "      <td>0.840393</td>\n",
       "      <td>0.854339</td>\n",
       "      <td>0.846937</td>\n",
       "      <td>0.843216</td>\n",
       "      <td>0.851320</td>\n",
       "      <td>0.852743</td>\n",
       "      <td>0.007143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.192820</td>\n",
       "      <td>0.003181</td>\n",
       "      <td>0.010582</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 20}</td>\n",
       "      <td>0.845735</td>\n",
       "      <td>0.844044</td>\n",
       "      <td>0.915588</td>\n",
       "      <td>0.821017</td>\n",
       "      <td>0.850946</td>\n",
       "      <td>0.804685</td>\n",
       "      <td>0.718889</td>\n",
       "      <td>0.834023</td>\n",
       "      <td>0.838014</td>\n",
       "      <td>0.901641</td>\n",
       "      <td>0.837498</td>\n",
       "      <td>0.050918</td>\n",
       "      <td>66</td>\n",
       "      <td>0.857834</td>\n",
       "      <td>0.864395</td>\n",
       "      <td>0.853336</td>\n",
       "      <td>0.860551</td>\n",
       "      <td>0.855113</td>\n",
       "      <td>0.840393</td>\n",
       "      <td>0.854339</td>\n",
       "      <td>0.846937</td>\n",
       "      <td>0.843216</td>\n",
       "      <td>0.851320</td>\n",
       "      <td>0.852743</td>\n",
       "      <td>0.007143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.191961</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.010511</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 25}</td>\n",
       "      <td>0.845735</td>\n",
       "      <td>0.844044</td>\n",
       "      <td>0.915588</td>\n",
       "      <td>0.821017</td>\n",
       "      <td>0.850946</td>\n",
       "      <td>0.804685</td>\n",
       "      <td>0.718889</td>\n",
       "      <td>0.834023</td>\n",
       "      <td>0.838014</td>\n",
       "      <td>0.901641</td>\n",
       "      <td>0.837498</td>\n",
       "      <td>0.050918</td>\n",
       "      <td>66</td>\n",
       "      <td>0.857834</td>\n",
       "      <td>0.864395</td>\n",
       "      <td>0.853336</td>\n",
       "      <td>0.860551</td>\n",
       "      <td>0.855113</td>\n",
       "      <td>0.840393</td>\n",
       "      <td>0.854339</td>\n",
       "      <td>0.846937</td>\n",
       "      <td>0.843216</td>\n",
       "      <td>0.851320</td>\n",
       "      <td>0.852743</td>\n",
       "      <td>0.007143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.476381</td>\n",
       "      <td>0.045244</td>\n",
       "      <td>0.013677</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 14, 'min_samples_leaf': 5}</td>\n",
       "      <td>0.926765</td>\n",
       "      <td>0.796324</td>\n",
       "      <td>0.965441</td>\n",
       "      <td>0.900532</td>\n",
       "      <td>0.961277</td>\n",
       "      <td>0.874372</td>\n",
       "      <td>0.826190</td>\n",
       "      <td>0.903931</td>\n",
       "      <td>0.893586</td>\n",
       "      <td>0.928022</td>\n",
       "      <td>0.897642</td>\n",
       "      <td>0.051408</td>\n",
       "      <td>7</td>\n",
       "      <td>0.997104</td>\n",
       "      <td>0.997724</td>\n",
       "      <td>0.996923</td>\n",
       "      <td>0.997442</td>\n",
       "      <td>0.997166</td>\n",
       "      <td>0.997841</td>\n",
       "      <td>0.997716</td>\n",
       "      <td>0.997246</td>\n",
       "      <td>0.997548</td>\n",
       "      <td>0.997442</td>\n",
       "      <td>0.997415</td>\n",
       "      <td>0.000286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.459448</td>\n",
       "      <td>0.027468</td>\n",
       "      <td>0.015895</td>\n",
       "      <td>0.006447</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 14, 'min_samples_leaf': 10}</td>\n",
       "      <td>0.936912</td>\n",
       "      <td>0.808382</td>\n",
       "      <td>0.954118</td>\n",
       "      <td>0.886787</td>\n",
       "      <td>0.948862</td>\n",
       "      <td>0.872303</td>\n",
       "      <td>0.811853</td>\n",
       "      <td>0.903045</td>\n",
       "      <td>0.882205</td>\n",
       "      <td>0.916346</td>\n",
       "      <td>0.892091</td>\n",
       "      <td>0.048759</td>\n",
       "      <td>33</td>\n",
       "      <td>0.988310</td>\n",
       "      <td>0.989454</td>\n",
       "      <td>0.987909</td>\n",
       "      <td>0.988668</td>\n",
       "      <td>0.988604</td>\n",
       "      <td>0.989624</td>\n",
       "      <td>0.988970</td>\n",
       "      <td>0.988533</td>\n",
       "      <td>0.989265</td>\n",
       "      <td>0.989655</td>\n",
       "      <td>0.988899</td>\n",
       "      <td>0.000561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.449818</td>\n",
       "      <td>0.035806</td>\n",
       "      <td>0.013656</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 14, 'min_samples_leaf': 15}</td>\n",
       "      <td>0.931471</td>\n",
       "      <td>0.834265</td>\n",
       "      <td>0.953382</td>\n",
       "      <td>0.889004</td>\n",
       "      <td>0.944132</td>\n",
       "      <td>0.860922</td>\n",
       "      <td>0.809636</td>\n",
       "      <td>0.899645</td>\n",
       "      <td>0.884866</td>\n",
       "      <td>0.925067</td>\n",
       "      <td>0.893256</td>\n",
       "      <td>0.045093</td>\n",
       "      <td>28</td>\n",
       "      <td>0.976083</td>\n",
       "      <td>0.978972</td>\n",
       "      <td>0.976494</td>\n",
       "      <td>0.977907</td>\n",
       "      <td>0.977328</td>\n",
       "      <td>0.978017</td>\n",
       "      <td>0.979281</td>\n",
       "      <td>0.977421</td>\n",
       "      <td>0.977354</td>\n",
       "      <td>0.978257</td>\n",
       "      <td>0.977711</td>\n",
       "      <td>0.000947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.411927</td>\n",
       "      <td>0.004159</td>\n",
       "      <td>0.013808</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 14, 'min_samples_leaf': 20}</td>\n",
       "      <td>0.929265</td>\n",
       "      <td>0.838676</td>\n",
       "      <td>0.950735</td>\n",
       "      <td>0.876293</td>\n",
       "      <td>0.930387</td>\n",
       "      <td>0.852646</td>\n",
       "      <td>0.816287</td>\n",
       "      <td>0.900384</td>\n",
       "      <td>0.887821</td>\n",
       "      <td>0.918563</td>\n",
       "      <td>0.890127</td>\n",
       "      <td>0.041776</td>\n",
       "      <td>43</td>\n",
       "      <td>0.966925</td>\n",
       "      <td>0.971051</td>\n",
       "      <td>0.966586</td>\n",
       "      <td>0.968523</td>\n",
       "      <td>0.968856</td>\n",
       "      <td>0.969193</td>\n",
       "      <td>0.970565</td>\n",
       "      <td>0.967825</td>\n",
       "      <td>0.968568</td>\n",
       "      <td>0.968260</td>\n",
       "      <td>0.968635</td>\n",
       "      <td>0.001336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.423816</td>\n",
       "      <td>0.032959</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>14</td>\n",
       "      <td>25</td>\n",
       "      <td>{'max_depth': 14, 'min_samples_leaf': 25}</td>\n",
       "      <td>0.915882</td>\n",
       "      <td>0.849853</td>\n",
       "      <td>0.946324</td>\n",
       "      <td>0.882649</td>\n",
       "      <td>0.925510</td>\n",
       "      <td>0.857523</td>\n",
       "      <td>0.818356</td>\n",
       "      <td>0.899350</td>\n",
       "      <td>0.880432</td>\n",
       "      <td>0.912208</td>\n",
       "      <td>0.888828</td>\n",
       "      <td>0.036906</td>\n",
       "      <td>47</td>\n",
       "      <td>0.958816</td>\n",
       "      <td>0.964513</td>\n",
       "      <td>0.959138</td>\n",
       "      <td>0.960099</td>\n",
       "      <td>0.959668</td>\n",
       "      <td>0.959977</td>\n",
       "      <td>0.961894</td>\n",
       "      <td>0.958974</td>\n",
       "      <td>0.959048</td>\n",
       "      <td>0.960841</td>\n",
       "      <td>0.960297</td>\n",
       "      <td>0.001674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.214973      0.056841         0.014358        0.009164   \n",
       "1        0.204097      0.012916         0.011413        0.001287   \n",
       "2        0.193083      0.001476         0.010512        0.000693   \n",
       "3        0.192820      0.003181         0.010582        0.000792   \n",
       "4        0.191961      0.001092         0.010511        0.000710   \n",
       "..            ...           ...              ...             ...   \n",
       "65       0.476381      0.045244         0.013677        0.001639   \n",
       "66       0.459448      0.027468         0.015895        0.006447   \n",
       "67       0.449818      0.035806         0.013656        0.001458   \n",
       "68       0.411927      0.004159         0.013808        0.000856   \n",
       "69       0.423816      0.032959         0.014390        0.001471   \n",
       "\n",
       "   param_max_depth param_min_samples_leaf  \\\n",
       "0                1                      5   \n",
       "1                1                     10   \n",
       "2                1                     15   \n",
       "3                1                     20   \n",
       "4                1                     25   \n",
       "..             ...                    ...   \n",
       "65              14                      5   \n",
       "66              14                     10   \n",
       "67              14                     15   \n",
       "68              14                     20   \n",
       "69              14                     25   \n",
       "\n",
       "                                       params  split0_test_score  \\\n",
       "0     {'max_depth': 1, 'min_samples_leaf': 5}           0.845735   \n",
       "1    {'max_depth': 1, 'min_samples_leaf': 10}           0.845735   \n",
       "2    {'max_depth': 1, 'min_samples_leaf': 15}           0.845735   \n",
       "3    {'max_depth': 1, 'min_samples_leaf': 20}           0.845735   \n",
       "4    {'max_depth': 1, 'min_samples_leaf': 25}           0.845735   \n",
       "..                                        ...                ...   \n",
       "65   {'max_depth': 14, 'min_samples_leaf': 5}           0.926765   \n",
       "66  {'max_depth': 14, 'min_samples_leaf': 10}           0.936912   \n",
       "67  {'max_depth': 14, 'min_samples_leaf': 15}           0.931471   \n",
       "68  {'max_depth': 14, 'min_samples_leaf': 20}           0.929265   \n",
       "69  {'max_depth': 14, 'min_samples_leaf': 25}           0.915882   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.844044           0.915588           0.821017   \n",
       "1            0.844044           0.915588           0.821017   \n",
       "2            0.844044           0.915588           0.821017   \n",
       "3            0.844044           0.915588           0.821017   \n",
       "4            0.844044           0.915588           0.821017   \n",
       "..                ...                ...                ...   \n",
       "65           0.796324           0.965441           0.900532   \n",
       "66           0.808382           0.954118           0.886787   \n",
       "67           0.834265           0.953382           0.889004   \n",
       "68           0.838676           0.950735           0.876293   \n",
       "69           0.849853           0.946324           0.882649   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0            0.850946           0.804685           0.718889   \n",
       "1            0.850946           0.804685           0.718889   \n",
       "2            0.850946           0.804685           0.718889   \n",
       "3            0.850946           0.804685           0.718889   \n",
       "4            0.850946           0.804685           0.718889   \n",
       "..                ...                ...                ...   \n",
       "65           0.961277           0.874372           0.826190   \n",
       "66           0.948862           0.872303           0.811853   \n",
       "67           0.944132           0.860922           0.809636   \n",
       "68           0.930387           0.852646           0.816287   \n",
       "69           0.925510           0.857523           0.818356   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0            0.834023           0.838014           0.901641         0.837498   \n",
       "1            0.834023           0.838014           0.901641         0.837498   \n",
       "2            0.834023           0.838014           0.901641         0.837498   \n",
       "3            0.834023           0.838014           0.901641         0.837498   \n",
       "4            0.834023           0.838014           0.901641         0.837498   \n",
       "..                ...                ...                ...              ...   \n",
       "65           0.903931           0.893586           0.928022         0.897642   \n",
       "66           0.903045           0.882205           0.916346         0.892091   \n",
       "67           0.899645           0.884866           0.925067         0.893256   \n",
       "68           0.900384           0.887821           0.918563         0.890127   \n",
       "69           0.899350           0.880432           0.912208         0.888828   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0         0.050918               66            0.857834            0.864395   \n",
       "1         0.050918               66            0.857834            0.864395   \n",
       "2         0.050918               66            0.857834            0.864395   \n",
       "3         0.050918               66            0.857834            0.864395   \n",
       "4         0.050918               66            0.857834            0.864395   \n",
       "..             ...              ...                 ...                 ...   \n",
       "65        0.051408                7            0.997104            0.997724   \n",
       "66        0.048759               33            0.988310            0.989454   \n",
       "67        0.045093               28            0.976083            0.978972   \n",
       "68        0.041776               43            0.966925            0.971051   \n",
       "69        0.036906               47            0.958816            0.964513   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0             0.853336            0.860551            0.855113   \n",
       "1             0.853336            0.860551            0.855113   \n",
       "2             0.853336            0.860551            0.855113   \n",
       "3             0.853336            0.860551            0.855113   \n",
       "4             0.853336            0.860551            0.855113   \n",
       "..                 ...                 ...                 ...   \n",
       "65            0.996923            0.997442            0.997166   \n",
       "66            0.987909            0.988668            0.988604   \n",
       "67            0.976494            0.977907            0.977328   \n",
       "68            0.966586            0.968523            0.968856   \n",
       "69            0.959138            0.960099            0.959668   \n",
       "\n",
       "    split5_train_score  split6_train_score  split7_train_score  \\\n",
       "0             0.840393            0.854339            0.846937   \n",
       "1             0.840393            0.854339            0.846937   \n",
       "2             0.840393            0.854339            0.846937   \n",
       "3             0.840393            0.854339            0.846937   \n",
       "4             0.840393            0.854339            0.846937   \n",
       "..                 ...                 ...                 ...   \n",
       "65            0.997841            0.997716            0.997246   \n",
       "66            0.989624            0.988970            0.988533   \n",
       "67            0.978017            0.979281            0.977421   \n",
       "68            0.969193            0.970565            0.967825   \n",
       "69            0.959977            0.961894            0.958974   \n",
       "\n",
       "    split8_train_score  split9_train_score  mean_train_score  std_train_score  \n",
       "0             0.843216            0.851320          0.852743         0.007143  \n",
       "1             0.843216            0.851320          0.852743         0.007143  \n",
       "2             0.843216            0.851320          0.852743         0.007143  \n",
       "3             0.843216            0.851320          0.852743         0.007143  \n",
       "4             0.843216            0.851320          0.852743         0.007143  \n",
       "..                 ...                 ...               ...              ...  \n",
       "65            0.997548            0.997442          0.997415         0.000286  \n",
       "66            0.989265            0.989655          0.988899         0.000561  \n",
       "67            0.977354            0.978257          0.977711         0.000947  \n",
       "68            0.968568            0.968260          0.968635         0.001336  \n",
       "69            0.959048            0.960841          0.960297         0.001674  \n",
       "\n",
       "[70 rows x 32 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying hyperparameter optimisations\n",
    "skf = StratifiedKFold(n_splits = 10, random_state = 600)\n",
    "\n",
    "param_grid = {'max_depth': range(1,15), 'min_samples_leaf': [5,10,15,20,25]}\n",
    "\n",
    "opt_model_forest = GridSearchCV(model_random_forest,\n",
    "                         param_grid,\n",
    "                         cv=skf,\n",
    "                         scoring='roc_auc',\n",
    "                         return_train_score=True)\n",
    "\n",
    "opt_model_forest.fit(X_train,y_train)\n",
    "\n",
    "pd.DataFrame(opt_model_forest.cv_results_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values of the optimised hyperparameters\n",
      "for the best model found:\n",
      " {'max_depth': 6, 'min_samples_leaf': 5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9005610938381171"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Values of the optimised hyperparameters\\nfor the best model found:\\n',opt_model_forest.best_params_)\n",
    "opt_model_forest.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=-1, penalty='l2',\n",
       "                   random_state=39, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up the learner and fitting it\n",
    "log_model = LogisticRegression(class_weight = 'balanced', penalty = 'l2', random_state = 39, solver = 'liblinear', n_jobs = -1)\n",
    "log_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roc_score is  0.8205292051592337\n"
     ]
    }
   ],
   "source": [
    "# evaluating performance on roc_curve\n",
    "y_hat_log = log_model.predict_proba(X_train)[:,1]\n",
    "print('Roc_score is ',roc_auc_score(y_train, y_hat_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.007984</td>\n",
       "      <td>0.002946</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1e-10, 'penalty': 'l1'}</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.006980</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>0.003417</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1e-10, 'penalty': 'l2'}</td>\n",
       "      <td>0.674853</td>\n",
       "      <td>0.690147</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.695537</td>\n",
       "      <td>0.638487</td>\n",
       "      <td>0.613361</td>\n",
       "      <td>0.464972</td>\n",
       "      <td>0.566066</td>\n",
       "      <td>0.629027</td>\n",
       "      <td>0.634348</td>\n",
       "      <td>0.625739</td>\n",
       "      <td>0.064657</td>\n",
       "      <td>27</td>\n",
       "      <td>0.623128</td>\n",
       "      <td>0.621057</td>\n",
       "      <td>0.626077</td>\n",
       "      <td>0.620984</td>\n",
       "      <td>0.626527</td>\n",
       "      <td>0.629457</td>\n",
       "      <td>0.645975</td>\n",
       "      <td>0.634794</td>\n",
       "      <td>0.628349</td>\n",
       "      <td>0.627686</td>\n",
       "      <td>0.628403</td>\n",
       "      <td>0.007050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.005393</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.002925</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>1.12884e-09</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1.1288378916846883e-09, 'penalty': 'l1'}</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.007671</td>\n",
       "      <td>0.002829</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>1.12884e-09</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1.1288378916846883e-09, 'penalty': 'l2'}</td>\n",
       "      <td>0.679559</td>\n",
       "      <td>0.691765</td>\n",
       "      <td>0.652206</td>\n",
       "      <td>0.695093</td>\n",
       "      <td>0.632870</td>\n",
       "      <td>0.610996</td>\n",
       "      <td>0.462459</td>\n",
       "      <td>0.565622</td>\n",
       "      <td>0.628289</td>\n",
       "      <td>0.632131</td>\n",
       "      <td>0.625163</td>\n",
       "      <td>0.065827</td>\n",
       "      <td>28</td>\n",
       "      <td>0.622364</td>\n",
       "      <td>0.621001</td>\n",
       "      <td>0.625685</td>\n",
       "      <td>0.620536</td>\n",
       "      <td>0.626606</td>\n",
       "      <td>0.629438</td>\n",
       "      <td>0.645569</td>\n",
       "      <td>0.634433</td>\n",
       "      <td>0.627912</td>\n",
       "      <td>0.627342</td>\n",
       "      <td>0.628089</td>\n",
       "      <td>0.007044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.006874</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.002966</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>1.27427e-08</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1.274274985703132e-08, 'penalty': 'l1'}</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.007013</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>1.27427e-08</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1.274274985703132e-08, 'penalty': 'l2'}</td>\n",
       "      <td>0.701765</td>\n",
       "      <td>0.693529</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.691250</td>\n",
       "      <td>0.610257</td>\n",
       "      <td>0.598286</td>\n",
       "      <td>0.449897</td>\n",
       "      <td>0.562666</td>\n",
       "      <td>0.625185</td>\n",
       "      <td>0.622081</td>\n",
       "      <td>0.621824</td>\n",
       "      <td>0.071941</td>\n",
       "      <td>29</td>\n",
       "      <td>0.616388</td>\n",
       "      <td>0.617623</td>\n",
       "      <td>0.621436</td>\n",
       "      <td>0.617649</td>\n",
       "      <td>0.625868</td>\n",
       "      <td>0.627256</td>\n",
       "      <td>0.642545</td>\n",
       "      <td>0.631262</td>\n",
       "      <td>0.624454</td>\n",
       "      <td>0.625110</td>\n",
       "      <td>0.624959</td>\n",
       "      <td>0.007406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.005484</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.002645</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>1.43845e-07</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1.438449888287663e-07, 'penalty': 'l1'}</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>0.003459</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>1.43845e-07</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1.438449888287663e-07, 'penalty': 'l2'}</td>\n",
       "      <td>0.705735</td>\n",
       "      <td>0.690294</td>\n",
       "      <td>0.667647</td>\n",
       "      <td>0.678096</td>\n",
       "      <td>0.580993</td>\n",
       "      <td>0.581732</td>\n",
       "      <td>0.438368</td>\n",
       "      <td>0.536210</td>\n",
       "      <td>0.615726</td>\n",
       "      <td>0.604936</td>\n",
       "      <td>0.610074</td>\n",
       "      <td>0.077574</td>\n",
       "      <td>33</td>\n",
       "      <td>0.604838</td>\n",
       "      <td>0.607090</td>\n",
       "      <td>0.610869</td>\n",
       "      <td>0.608446</td>\n",
       "      <td>0.618108</td>\n",
       "      <td>0.619221</td>\n",
       "      <td>0.632460</td>\n",
       "      <td>0.622303</td>\n",
       "      <td>0.615126</td>\n",
       "      <td>0.615793</td>\n",
       "      <td>0.615425</td>\n",
       "      <td>0.007813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.005932</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.002651</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>1.62378e-06</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1.6237767391887209e-06, 'penalty': 'l1'}</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.008599</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>1.62378e-06</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1.6237767391887209e-06, 'penalty': 'l2'}</td>\n",
       "      <td>0.712059</td>\n",
       "      <td>0.700441</td>\n",
       "      <td>0.661029</td>\n",
       "      <td>0.681791</td>\n",
       "      <td>0.588383</td>\n",
       "      <td>0.579959</td>\n",
       "      <td>0.436890</td>\n",
       "      <td>0.533993</td>\n",
       "      <td>0.606562</td>\n",
       "      <td>0.611440</td>\n",
       "      <td>0.611358</td>\n",
       "      <td>0.079669</td>\n",
       "      <td>32</td>\n",
       "      <td>0.607907</td>\n",
       "      <td>0.608514</td>\n",
       "      <td>0.614479</td>\n",
       "      <td>0.611031</td>\n",
       "      <td>0.621278</td>\n",
       "      <td>0.621919</td>\n",
       "      <td>0.635881</td>\n",
       "      <td>0.625717</td>\n",
       "      <td>0.618944</td>\n",
       "      <td>0.617709</td>\n",
       "      <td>0.618338</td>\n",
       "      <td>0.008112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.005876</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>1.83298e-05</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1.8329807108324338e-05, 'penalty': 'l1'}</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.010636</td>\n",
       "      <td>0.002454</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>1.83298e-05</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1.8329807108324338e-05, 'penalty': 'l2'}</td>\n",
       "      <td>0.696324</td>\n",
       "      <td>0.719853</td>\n",
       "      <td>0.664265</td>\n",
       "      <td>0.686816</td>\n",
       "      <td>0.611440</td>\n",
       "      <td>0.587201</td>\n",
       "      <td>0.451670</td>\n",
       "      <td>0.547000</td>\n",
       "      <td>0.608631</td>\n",
       "      <td>0.630801</td>\n",
       "      <td>0.620494</td>\n",
       "      <td>0.075683</td>\n",
       "      <td>31</td>\n",
       "      <td>0.628514</td>\n",
       "      <td>0.621815</td>\n",
       "      <td>0.629026</td>\n",
       "      <td>0.627730</td>\n",
       "      <td>0.635144</td>\n",
       "      <td>0.634329</td>\n",
       "      <td>0.650334</td>\n",
       "      <td>0.639969</td>\n",
       "      <td>0.635286</td>\n",
       "      <td>0.631848</td>\n",
       "      <td>0.633399</td>\n",
       "      <td>0.007410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.013484</td>\n",
       "      <td>0.008109</td>\n",
       "      <td>0.004808</td>\n",
       "      <td>0.003271</td>\n",
       "      <td>0.000206914</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.00020691380811147902, 'penalty': 'l1'}</td>\n",
       "      <td>0.677353</td>\n",
       "      <td>0.675441</td>\n",
       "      <td>0.651176</td>\n",
       "      <td>0.668342</td>\n",
       "      <td>0.546409</td>\n",
       "      <td>0.604789</td>\n",
       "      <td>0.455365</td>\n",
       "      <td>0.545965</td>\n",
       "      <td>0.609666</td>\n",
       "      <td>0.594591</td>\n",
       "      <td>0.602993</td>\n",
       "      <td>0.067627</td>\n",
       "      <td>34</td>\n",
       "      <td>0.597305</td>\n",
       "      <td>0.599752</td>\n",
       "      <td>0.600064</td>\n",
       "      <td>0.598996</td>\n",
       "      <td>0.608058</td>\n",
       "      <td>0.605577</td>\n",
       "      <td>0.617500</td>\n",
       "      <td>0.609197</td>\n",
       "      <td>0.603981</td>\n",
       "      <td>0.605561</td>\n",
       "      <td>0.604599</td>\n",
       "      <td>0.005748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.043600</td>\n",
       "      <td>0.016137</td>\n",
       "      <td>0.008682</td>\n",
       "      <td>0.003248</td>\n",
       "      <td>0.000206914</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.00020691380811147902, 'penalty': 'l2'}</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.769853</td>\n",
       "      <td>0.717059</td>\n",
       "      <td>0.712681</td>\n",
       "      <td>0.672480</td>\n",
       "      <td>0.630949</td>\n",
       "      <td>0.497340</td>\n",
       "      <td>0.623116</td>\n",
       "      <td>0.638191</td>\n",
       "      <td>0.684156</td>\n",
       "      <td>0.665668</td>\n",
       "      <td>0.070828</td>\n",
       "      <td>26</td>\n",
       "      <td>0.684038</td>\n",
       "      <td>0.675348</td>\n",
       "      <td>0.676806</td>\n",
       "      <td>0.681107</td>\n",
       "      <td>0.678877</td>\n",
       "      <td>0.683331</td>\n",
       "      <td>0.695976</td>\n",
       "      <td>0.680995</td>\n",
       "      <td>0.686076</td>\n",
       "      <td>0.681664</td>\n",
       "      <td>0.682422</td>\n",
       "      <td>0.005468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.025807</td>\n",
       "      <td>0.014994</td>\n",
       "      <td>0.004584</td>\n",
       "      <td>0.003985</td>\n",
       "      <td>0.00233572</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.002335721469090121, 'penalty': 'l1'}</td>\n",
       "      <td>0.691176</td>\n",
       "      <td>0.729853</td>\n",
       "      <td>0.667794</td>\n",
       "      <td>0.697901</td>\n",
       "      <td>0.606267</td>\n",
       "      <td>0.592669</td>\n",
       "      <td>0.459503</td>\n",
       "      <td>0.535028</td>\n",
       "      <td>0.604345</td>\n",
       "      <td>0.629914</td>\n",
       "      <td>0.621541</td>\n",
       "      <td>0.077284</td>\n",
       "      <td>30</td>\n",
       "      <td>0.640650</td>\n",
       "      <td>0.632367</td>\n",
       "      <td>0.622729</td>\n",
       "      <td>0.641610</td>\n",
       "      <td>0.629721</td>\n",
       "      <td>0.634690</td>\n",
       "      <td>0.664220</td>\n",
       "      <td>0.636515</td>\n",
       "      <td>0.637153</td>\n",
       "      <td>0.628504</td>\n",
       "      <td>0.636816</td>\n",
       "      <td>0.010635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.023876</td>\n",
       "      <td>0.004288</td>\n",
       "      <td>0.003161</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.00233572</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.002335721469090121, 'penalty': 'l2'}</td>\n",
       "      <td>0.723235</td>\n",
       "      <td>0.787059</td>\n",
       "      <td>0.781324</td>\n",
       "      <td>0.737363</td>\n",
       "      <td>0.766184</td>\n",
       "      <td>0.690364</td>\n",
       "      <td>0.573160</td>\n",
       "      <td>0.761159</td>\n",
       "      <td>0.712977</td>\n",
       "      <td>0.765740</td>\n",
       "      <td>0.729900</td>\n",
       "      <td>0.059988</td>\n",
       "      <td>25</td>\n",
       "      <td>0.745732</td>\n",
       "      <td>0.742078</td>\n",
       "      <td>0.737704</td>\n",
       "      <td>0.744646</td>\n",
       "      <td>0.739129</td>\n",
       "      <td>0.749015</td>\n",
       "      <td>0.757674</td>\n",
       "      <td>0.738650</td>\n",
       "      <td>0.745703</td>\n",
       "      <td>0.739852</td>\n",
       "      <td>0.744018</td>\n",
       "      <td>0.005756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.074068</td>\n",
       "      <td>0.019794</td>\n",
       "      <td>0.004081</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>0.0263665</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.026366508987303555, 'penalty': 'l1'}</td>\n",
       "      <td>0.792353</td>\n",
       "      <td>0.776324</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>0.771357</td>\n",
       "      <td>0.809636</td>\n",
       "      <td>0.698049</td>\n",
       "      <td>0.628584</td>\n",
       "      <td>0.814957</td>\n",
       "      <td>0.773426</td>\n",
       "      <td>0.834614</td>\n",
       "      <td>0.776475</td>\n",
       "      <td>0.064875</td>\n",
       "      <td>24</td>\n",
       "      <td>0.785617</td>\n",
       "      <td>0.792043</td>\n",
       "      <td>0.778173</td>\n",
       "      <td>0.791066</td>\n",
       "      <td>0.787476</td>\n",
       "      <td>0.800062</td>\n",
       "      <td>0.804291</td>\n",
       "      <td>0.786848</td>\n",
       "      <td>0.790179</td>\n",
       "      <td>0.783933</td>\n",
       "      <td>0.789969</td>\n",
       "      <td>0.007232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.029025</td>\n",
       "      <td>0.003877</td>\n",
       "      <td>0.002712</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.0263665</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.026366508987303555, 'penalty': 'l2'}</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.782353</td>\n",
       "      <td>0.857059</td>\n",
       "      <td>0.773278</td>\n",
       "      <td>0.814218</td>\n",
       "      <td>0.702779</td>\n",
       "      <td>0.633018</td>\n",
       "      <td>0.821904</td>\n",
       "      <td>0.773278</td>\n",
       "      <td>0.829589</td>\n",
       "      <td>0.776786</td>\n",
       "      <td>0.062337</td>\n",
       "      <td>23</td>\n",
       "      <td>0.787321</td>\n",
       "      <td>0.791985</td>\n",
       "      <td>0.779695</td>\n",
       "      <td>0.791425</td>\n",
       "      <td>0.787416</td>\n",
       "      <td>0.799320</td>\n",
       "      <td>0.803386</td>\n",
       "      <td>0.786707</td>\n",
       "      <td>0.790449</td>\n",
       "      <td>0.784226</td>\n",
       "      <td>0.790193</td>\n",
       "      <td>0.006604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.611681</td>\n",
       "      <td>0.042185</td>\n",
       "      <td>0.002916</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.297635</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.2976351441631313, 'penalty': 'l1'}</td>\n",
       "      <td>0.820882</td>\n",
       "      <td>0.795147</td>\n",
       "      <td>0.880735</td>\n",
       "      <td>0.789388</td>\n",
       "      <td>0.847473</td>\n",
       "      <td>0.748892</td>\n",
       "      <td>0.677210</td>\n",
       "      <td>0.850133</td>\n",
       "      <td>0.804316</td>\n",
       "      <td>0.841709</td>\n",
       "      <td>0.805623</td>\n",
       "      <td>0.055659</td>\n",
       "      <td>16</td>\n",
       "      <td>0.819068</td>\n",
       "      <td>0.823668</td>\n",
       "      <td>0.812125</td>\n",
       "      <td>0.822438</td>\n",
       "      <td>0.816893</td>\n",
       "      <td>0.827154</td>\n",
       "      <td>0.832388</td>\n",
       "      <td>0.816735</td>\n",
       "      <td>0.820817</td>\n",
       "      <td>0.816451</td>\n",
       "      <td>0.820774</td>\n",
       "      <td>0.005608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.036989</td>\n",
       "      <td>0.004172</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.297635</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.2976351441631313, 'penalty': 'l2'}</td>\n",
       "      <td>0.819118</td>\n",
       "      <td>0.791176</td>\n",
       "      <td>0.885294</td>\n",
       "      <td>0.790127</td>\n",
       "      <td>0.838309</td>\n",
       "      <td>0.731156</td>\n",
       "      <td>0.672184</td>\n",
       "      <td>0.842004</td>\n",
       "      <td>0.801212</td>\n",
       "      <td>0.843187</td>\n",
       "      <td>0.801416</td>\n",
       "      <td>0.058275</td>\n",
       "      <td>22</td>\n",
       "      <td>0.812971</td>\n",
       "      <td>0.817464</td>\n",
       "      <td>0.805859</td>\n",
       "      <td>0.816188</td>\n",
       "      <td>0.811441</td>\n",
       "      <td>0.822333</td>\n",
       "      <td>0.827307</td>\n",
       "      <td>0.811299</td>\n",
       "      <td>0.814888</td>\n",
       "      <td>0.810019</td>\n",
       "      <td>0.814977</td>\n",
       "      <td>0.005929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.756662</td>\n",
       "      <td>0.783771</td>\n",
       "      <td>0.003812</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>3.35982</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 3.359818286283774, 'penalty': 'l1'}</td>\n",
       "      <td>0.818529</td>\n",
       "      <td>0.793088</td>\n",
       "      <td>0.879853</td>\n",
       "      <td>0.791014</td>\n",
       "      <td>0.850133</td>\n",
       "      <td>0.754656</td>\n",
       "      <td>0.687703</td>\n",
       "      <td>0.850724</td>\n",
       "      <td>0.806533</td>\n",
       "      <td>0.837422</td>\n",
       "      <td>0.806996</td>\n",
       "      <td>0.052486</td>\n",
       "      <td>11</td>\n",
       "      <td>0.820333</td>\n",
       "      <td>0.824647</td>\n",
       "      <td>0.813534</td>\n",
       "      <td>0.823957</td>\n",
       "      <td>0.818356</td>\n",
       "      <td>0.828981</td>\n",
       "      <td>0.833905</td>\n",
       "      <td>0.818562</td>\n",
       "      <td>0.822719</td>\n",
       "      <td>0.818061</td>\n",
       "      <td>0.822306</td>\n",
       "      <td>0.005621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.047447</td>\n",
       "      <td>0.004720</td>\n",
       "      <td>0.003416</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>3.35982</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 3.359818286283774, 'penalty': 'l2'}</td>\n",
       "      <td>0.819853</td>\n",
       "      <td>0.794559</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.791014</td>\n",
       "      <td>0.849098</td>\n",
       "      <td>0.752734</td>\n",
       "      <td>0.687999</td>\n",
       "      <td>0.849985</td>\n",
       "      <td>0.804759</td>\n",
       "      <td>0.840822</td>\n",
       "      <td>0.807364</td>\n",
       "      <td>0.053046</td>\n",
       "      <td>1</td>\n",
       "      <td>0.820249</td>\n",
       "      <td>0.824765</td>\n",
       "      <td>0.813343</td>\n",
       "      <td>0.823712</td>\n",
       "      <td>0.818321</td>\n",
       "      <td>0.828712</td>\n",
       "      <td>0.833767</td>\n",
       "      <td>0.818485</td>\n",
       "      <td>0.822252</td>\n",
       "      <td>0.817966</td>\n",
       "      <td>0.822157</td>\n",
       "      <td>0.005604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.653446</td>\n",
       "      <td>1.257749</td>\n",
       "      <td>0.003666</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>37.9269</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 37.92690190732238, 'penalty': 'l1'}</td>\n",
       "      <td>0.817059</td>\n",
       "      <td>0.793824</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.791014</td>\n",
       "      <td>0.850281</td>\n",
       "      <td>0.755690</td>\n",
       "      <td>0.688147</td>\n",
       "      <td>0.850429</td>\n",
       "      <td>0.806533</td>\n",
       "      <td>0.837422</td>\n",
       "      <td>0.807070</td>\n",
       "      <td>0.052242</td>\n",
       "      <td>2</td>\n",
       "      <td>0.820409</td>\n",
       "      <td>0.824687</td>\n",
       "      <td>0.813674</td>\n",
       "      <td>0.824016</td>\n",
       "      <td>0.818294</td>\n",
       "      <td>0.829104</td>\n",
       "      <td>0.834049</td>\n",
       "      <td>0.818657</td>\n",
       "      <td>0.822686</td>\n",
       "      <td>0.818108</td>\n",
       "      <td>0.822368</td>\n",
       "      <td>0.005639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.051638</td>\n",
       "      <td>0.005619</td>\n",
       "      <td>0.003376</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>37.9269</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 37.92690190732238, 'penalty': 'l2'}</td>\n",
       "      <td>0.818235</td>\n",
       "      <td>0.792794</td>\n",
       "      <td>0.880588</td>\n",
       "      <td>0.790866</td>\n",
       "      <td>0.849985</td>\n",
       "      <td>0.755247</td>\n",
       "      <td>0.687703</td>\n",
       "      <td>0.849690</td>\n",
       "      <td>0.805794</td>\n",
       "      <td>0.837570</td>\n",
       "      <td>0.806878</td>\n",
       "      <td>0.052449</td>\n",
       "      <td>12</td>\n",
       "      <td>0.820560</td>\n",
       "      <td>0.825095</td>\n",
       "      <td>0.813709</td>\n",
       "      <td>0.824247</td>\n",
       "      <td>0.818538</td>\n",
       "      <td>0.829195</td>\n",
       "      <td>0.834273</td>\n",
       "      <td>0.819010</td>\n",
       "      <td>0.822872</td>\n",
       "      <td>0.818325</td>\n",
       "      <td>0.822582</td>\n",
       "      <td>0.005654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.832217</td>\n",
       "      <td>0.929227</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>428.133</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 428.13323987193957, 'penalty': 'l1'}</td>\n",
       "      <td>0.817059</td>\n",
       "      <td>0.793676</td>\n",
       "      <td>0.879853</td>\n",
       "      <td>0.790866</td>\n",
       "      <td>0.850281</td>\n",
       "      <td>0.755690</td>\n",
       "      <td>0.688147</td>\n",
       "      <td>0.850429</td>\n",
       "      <td>0.806533</td>\n",
       "      <td>0.837422</td>\n",
       "      <td>0.807025</td>\n",
       "      <td>0.052230</td>\n",
       "      <td>3</td>\n",
       "      <td>0.820466</td>\n",
       "      <td>0.824701</td>\n",
       "      <td>0.813654</td>\n",
       "      <td>0.823983</td>\n",
       "      <td>0.818314</td>\n",
       "      <td>0.829125</td>\n",
       "      <td>0.834049</td>\n",
       "      <td>0.818642</td>\n",
       "      <td>0.822690</td>\n",
       "      <td>0.818105</td>\n",
       "      <td>0.822373</td>\n",
       "      <td>0.005642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.112245</td>\n",
       "      <td>0.053259</td>\n",
       "      <td>0.007293</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>428.133</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 428.13323987193957, 'penalty': 'l2'}</td>\n",
       "      <td>0.820441</td>\n",
       "      <td>0.788971</td>\n",
       "      <td>0.880441</td>\n",
       "      <td>0.791605</td>\n",
       "      <td>0.849394</td>\n",
       "      <td>0.752882</td>\n",
       "      <td>0.685930</td>\n",
       "      <td>0.845551</td>\n",
       "      <td>0.806533</td>\n",
       "      <td>0.838900</td>\n",
       "      <td>0.806096</td>\n",
       "      <td>0.052920</td>\n",
       "      <td>14</td>\n",
       "      <td>0.821144</td>\n",
       "      <td>0.826170</td>\n",
       "      <td>0.814312</td>\n",
       "      <td>0.824681</td>\n",
       "      <td>0.819250</td>\n",
       "      <td>0.829918</td>\n",
       "      <td>0.835466</td>\n",
       "      <td>0.820427</td>\n",
       "      <td>0.822693</td>\n",
       "      <td>0.819039</td>\n",
       "      <td>0.823310</td>\n",
       "      <td>0.005749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.781373</td>\n",
       "      <td>1.089044</td>\n",
       "      <td>0.003661</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>4832.93</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 4832.930238571752, 'penalty': 'l1'}</td>\n",
       "      <td>0.817059</td>\n",
       "      <td>0.793676</td>\n",
       "      <td>0.879853</td>\n",
       "      <td>0.790718</td>\n",
       "      <td>0.850281</td>\n",
       "      <td>0.755690</td>\n",
       "      <td>0.688147</td>\n",
       "      <td>0.850429</td>\n",
       "      <td>0.806533</td>\n",
       "      <td>0.837422</td>\n",
       "      <td>0.807011</td>\n",
       "      <td>0.052234</td>\n",
       "      <td>4</td>\n",
       "      <td>0.820467</td>\n",
       "      <td>0.824700</td>\n",
       "      <td>0.813654</td>\n",
       "      <td>0.823988</td>\n",
       "      <td>0.818307</td>\n",
       "      <td>0.829129</td>\n",
       "      <td>0.834058</td>\n",
       "      <td>0.818657</td>\n",
       "      <td>0.822690</td>\n",
       "      <td>0.818108</td>\n",
       "      <td>0.822376</td>\n",
       "      <td>0.005644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.063216</td>\n",
       "      <td>0.010547</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>4832.93</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 4832.930238571752, 'penalty': 'l2'}</td>\n",
       "      <td>0.822206</td>\n",
       "      <td>0.785294</td>\n",
       "      <td>0.880735</td>\n",
       "      <td>0.791457</td>\n",
       "      <td>0.850872</td>\n",
       "      <td>0.751552</td>\n",
       "      <td>0.684008</td>\n",
       "      <td>0.842152</td>\n",
       "      <td>0.807567</td>\n",
       "      <td>0.838457</td>\n",
       "      <td>0.805461</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>17</td>\n",
       "      <td>0.821340</td>\n",
       "      <td>0.826484</td>\n",
       "      <td>0.814360</td>\n",
       "      <td>0.825377</td>\n",
       "      <td>0.819597</td>\n",
       "      <td>0.830197</td>\n",
       "      <td>0.835678</td>\n",
       "      <td>0.820968</td>\n",
       "      <td>0.823814</td>\n",
       "      <td>0.819076</td>\n",
       "      <td>0.823689</td>\n",
       "      <td>0.005786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.589449</td>\n",
       "      <td>0.997271</td>\n",
       "      <td>0.003584</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>54555.9</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 54555.947811685146, 'penalty': 'l1'}</td>\n",
       "      <td>0.817059</td>\n",
       "      <td>0.793676</td>\n",
       "      <td>0.879853</td>\n",
       "      <td>0.790718</td>\n",
       "      <td>0.850281</td>\n",
       "      <td>0.755690</td>\n",
       "      <td>0.688147</td>\n",
       "      <td>0.850429</td>\n",
       "      <td>0.806533</td>\n",
       "      <td>0.837422</td>\n",
       "      <td>0.807011</td>\n",
       "      <td>0.052234</td>\n",
       "      <td>4</td>\n",
       "      <td>0.820467</td>\n",
       "      <td>0.824700</td>\n",
       "      <td>0.813654</td>\n",
       "      <td>0.823990</td>\n",
       "      <td>0.818307</td>\n",
       "      <td>0.829129</td>\n",
       "      <td>0.834060</td>\n",
       "      <td>0.818653</td>\n",
       "      <td>0.822690</td>\n",
       "      <td>0.818108</td>\n",
       "      <td>0.822376</td>\n",
       "      <td>0.005644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.061244</td>\n",
       "      <td>0.008285</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>54555.9</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 54555.947811685146, 'penalty': 'l2'}</td>\n",
       "      <td>0.822206</td>\n",
       "      <td>0.785441</td>\n",
       "      <td>0.880588</td>\n",
       "      <td>0.791309</td>\n",
       "      <td>0.850724</td>\n",
       "      <td>0.752439</td>\n",
       "      <td>0.684452</td>\n",
       "      <td>0.847916</td>\n",
       "      <td>0.808454</td>\n",
       "      <td>0.840083</td>\n",
       "      <td>0.806391</td>\n",
       "      <td>0.053870</td>\n",
       "      <td>13</td>\n",
       "      <td>0.821317</td>\n",
       "      <td>0.826447</td>\n",
       "      <td>0.814276</td>\n",
       "      <td>0.825424</td>\n",
       "      <td>0.819635</td>\n",
       "      <td>0.829901</td>\n",
       "      <td>0.835579</td>\n",
       "      <td>0.819963</td>\n",
       "      <td>0.823841</td>\n",
       "      <td>0.819017</td>\n",
       "      <td>0.823540</td>\n",
       "      <td>0.005803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.575207</td>\n",
       "      <td>0.977138</td>\n",
       "      <td>0.003693</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>615848</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 615848.2110660254, 'penalty': 'l1'}</td>\n",
       "      <td>0.817059</td>\n",
       "      <td>0.793676</td>\n",
       "      <td>0.879853</td>\n",
       "      <td>0.790718</td>\n",
       "      <td>0.850281</td>\n",
       "      <td>0.755690</td>\n",
       "      <td>0.688147</td>\n",
       "      <td>0.850429</td>\n",
       "      <td>0.806533</td>\n",
       "      <td>0.837422</td>\n",
       "      <td>0.807011</td>\n",
       "      <td>0.052234</td>\n",
       "      <td>4</td>\n",
       "      <td>0.820467</td>\n",
       "      <td>0.824700</td>\n",
       "      <td>0.813654</td>\n",
       "      <td>0.823990</td>\n",
       "      <td>0.818307</td>\n",
       "      <td>0.829129</td>\n",
       "      <td>0.834060</td>\n",
       "      <td>0.818653</td>\n",
       "      <td>0.822690</td>\n",
       "      <td>0.818108</td>\n",
       "      <td>0.822376</td>\n",
       "      <td>0.005644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.069957</td>\n",
       "      <td>0.009981</td>\n",
       "      <td>0.003136</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>615848</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 615848.2110660254, 'penalty': 'l2'}</td>\n",
       "      <td>0.822059</td>\n",
       "      <td>0.786471</td>\n",
       "      <td>0.881765</td>\n",
       "      <td>0.791457</td>\n",
       "      <td>0.850724</td>\n",
       "      <td>0.751995</td>\n",
       "      <td>0.684304</td>\n",
       "      <td>0.845995</td>\n",
       "      <td>0.805941</td>\n",
       "      <td>0.839787</td>\n",
       "      <td>0.806081</td>\n",
       "      <td>0.053897</td>\n",
       "      <td>15</td>\n",
       "      <td>0.821328</td>\n",
       "      <td>0.826482</td>\n",
       "      <td>0.814327</td>\n",
       "      <td>0.825378</td>\n",
       "      <td>0.819853</td>\n",
       "      <td>0.830071</td>\n",
       "      <td>0.835587</td>\n",
       "      <td>0.820351</td>\n",
       "      <td>0.822996</td>\n",
       "      <td>0.819045</td>\n",
       "      <td>0.823542</td>\n",
       "      <td>0.005778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.821500</td>\n",
       "      <td>0.988195</td>\n",
       "      <td>0.003888</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>6.95193e+06</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 6951927.961775591, 'penalty': 'l1'}</td>\n",
       "      <td>0.817059</td>\n",
       "      <td>0.793676</td>\n",
       "      <td>0.879853</td>\n",
       "      <td>0.790718</td>\n",
       "      <td>0.850281</td>\n",
       "      <td>0.755690</td>\n",
       "      <td>0.688147</td>\n",
       "      <td>0.850429</td>\n",
       "      <td>0.806533</td>\n",
       "      <td>0.837422</td>\n",
       "      <td>0.807011</td>\n",
       "      <td>0.052234</td>\n",
       "      <td>4</td>\n",
       "      <td>0.820467</td>\n",
       "      <td>0.824700</td>\n",
       "      <td>0.813654</td>\n",
       "      <td>0.823990</td>\n",
       "      <td>0.818307</td>\n",
       "      <td>0.829129</td>\n",
       "      <td>0.834060</td>\n",
       "      <td>0.818653</td>\n",
       "      <td>0.822690</td>\n",
       "      <td>0.818108</td>\n",
       "      <td>0.822376</td>\n",
       "      <td>0.005644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.069467</td>\n",
       "      <td>0.009397</td>\n",
       "      <td>0.003770</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>6.95193e+06</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 6951927.961775591, 'penalty': 'l2'}</td>\n",
       "      <td>0.822059</td>\n",
       "      <td>0.785441</td>\n",
       "      <td>0.880147</td>\n",
       "      <td>0.792492</td>\n",
       "      <td>0.851020</td>\n",
       "      <td>0.752291</td>\n",
       "      <td>0.680018</td>\n",
       "      <td>0.840822</td>\n",
       "      <td>0.806089</td>\n",
       "      <td>0.839787</td>\n",
       "      <td>0.805048</td>\n",
       "      <td>0.054293</td>\n",
       "      <td>20</td>\n",
       "      <td>0.821286</td>\n",
       "      <td>0.826475</td>\n",
       "      <td>0.814205</td>\n",
       "      <td>0.825251</td>\n",
       "      <td>0.819859</td>\n",
       "      <td>0.829960</td>\n",
       "      <td>0.835938</td>\n",
       "      <td>0.820930</td>\n",
       "      <td>0.822875</td>\n",
       "      <td>0.819030</td>\n",
       "      <td>0.823581</td>\n",
       "      <td>0.005829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.875596</td>\n",
       "      <td>0.986159</td>\n",
       "      <td>0.004126</td>\n",
       "      <td>0.002261</td>\n",
       "      <td>7.8476e+07</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 78475997.03514622, 'penalty': 'l1'}</td>\n",
       "      <td>0.817059</td>\n",
       "      <td>0.793676</td>\n",
       "      <td>0.879853</td>\n",
       "      <td>0.790718</td>\n",
       "      <td>0.850281</td>\n",
       "      <td>0.755690</td>\n",
       "      <td>0.688147</td>\n",
       "      <td>0.850429</td>\n",
       "      <td>0.806533</td>\n",
       "      <td>0.837422</td>\n",
       "      <td>0.807011</td>\n",
       "      <td>0.052234</td>\n",
       "      <td>4</td>\n",
       "      <td>0.820467</td>\n",
       "      <td>0.824700</td>\n",
       "      <td>0.813654</td>\n",
       "      <td>0.823990</td>\n",
       "      <td>0.818307</td>\n",
       "      <td>0.829129</td>\n",
       "      <td>0.834060</td>\n",
       "      <td>0.818653</td>\n",
       "      <td>0.822690</td>\n",
       "      <td>0.818108</td>\n",
       "      <td>0.822376</td>\n",
       "      <td>0.005644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.069157</td>\n",
       "      <td>0.013579</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>7.8476e+07</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 78475997.03514622, 'penalty': 'l2'}</td>\n",
       "      <td>0.822059</td>\n",
       "      <td>0.784412</td>\n",
       "      <td>0.879559</td>\n",
       "      <td>0.791162</td>\n",
       "      <td>0.850724</td>\n",
       "      <td>0.751995</td>\n",
       "      <td>0.682383</td>\n",
       "      <td>0.840231</td>\n",
       "      <td>0.808750</td>\n",
       "      <td>0.839787</td>\n",
       "      <td>0.805136</td>\n",
       "      <td>0.053717</td>\n",
       "      <td>18</td>\n",
       "      <td>0.821324</td>\n",
       "      <td>0.826318</td>\n",
       "      <td>0.813616</td>\n",
       "      <td>0.824810</td>\n",
       "      <td>0.819826</td>\n",
       "      <td>0.830060</td>\n",
       "      <td>0.835960</td>\n",
       "      <td>0.821003</td>\n",
       "      <td>0.823825</td>\n",
       "      <td>0.819041</td>\n",
       "      <td>0.823578</td>\n",
       "      <td>0.005916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.604302</td>\n",
       "      <td>0.986650</td>\n",
       "      <td>0.003369</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>8.85867e+08</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 885866790.4100796, 'penalty': 'l1'}</td>\n",
       "      <td>0.817059</td>\n",
       "      <td>0.793676</td>\n",
       "      <td>0.879853</td>\n",
       "      <td>0.790718</td>\n",
       "      <td>0.850281</td>\n",
       "      <td>0.755690</td>\n",
       "      <td>0.688147</td>\n",
       "      <td>0.850429</td>\n",
       "      <td>0.806533</td>\n",
       "      <td>0.837422</td>\n",
       "      <td>0.807011</td>\n",
       "      <td>0.052234</td>\n",
       "      <td>4</td>\n",
       "      <td>0.820467</td>\n",
       "      <td>0.824700</td>\n",
       "      <td>0.813654</td>\n",
       "      <td>0.823990</td>\n",
       "      <td>0.818307</td>\n",
       "      <td>0.829129</td>\n",
       "      <td>0.834060</td>\n",
       "      <td>0.818653</td>\n",
       "      <td>0.822690</td>\n",
       "      <td>0.818108</td>\n",
       "      <td>0.822376</td>\n",
       "      <td>0.005644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.068969</td>\n",
       "      <td>0.010186</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>8.85867e+08</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 885866790.4100796, 'penalty': 'l2'}</td>\n",
       "      <td>0.820735</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.880735</td>\n",
       "      <td>0.791753</td>\n",
       "      <td>0.850724</td>\n",
       "      <td>0.751108</td>\n",
       "      <td>0.680757</td>\n",
       "      <td>0.840970</td>\n",
       "      <td>0.805941</td>\n",
       "      <td>0.839787</td>\n",
       "      <td>0.805107</td>\n",
       "      <td>0.054190</td>\n",
       "      <td>19</td>\n",
       "      <td>0.821140</td>\n",
       "      <td>0.826375</td>\n",
       "      <td>0.814418</td>\n",
       "      <td>0.824874</td>\n",
       "      <td>0.819873</td>\n",
       "      <td>0.830293</td>\n",
       "      <td>0.835982</td>\n",
       "      <td>0.820966</td>\n",
       "      <td>0.823580</td>\n",
       "      <td>0.819041</td>\n",
       "      <td>0.823654</td>\n",
       "      <td>0.005826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.880528</td>\n",
       "      <td>1.205054</td>\n",
       "      <td>0.004279</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>1e+10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 10000000000.0, 'penalty': 'l1'}</td>\n",
       "      <td>0.817059</td>\n",
       "      <td>0.793676</td>\n",
       "      <td>0.879853</td>\n",
       "      <td>0.790718</td>\n",
       "      <td>0.850281</td>\n",
       "      <td>0.755690</td>\n",
       "      <td>0.688147</td>\n",
       "      <td>0.850429</td>\n",
       "      <td>0.806533</td>\n",
       "      <td>0.837422</td>\n",
       "      <td>0.807011</td>\n",
       "      <td>0.052234</td>\n",
       "      <td>4</td>\n",
       "      <td>0.820467</td>\n",
       "      <td>0.824700</td>\n",
       "      <td>0.813654</td>\n",
       "      <td>0.823990</td>\n",
       "      <td>0.818307</td>\n",
       "      <td>0.829129</td>\n",
       "      <td>0.834060</td>\n",
       "      <td>0.818653</td>\n",
       "      <td>0.822690</td>\n",
       "      <td>0.818108</td>\n",
       "      <td>0.822376</td>\n",
       "      <td>0.005644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.084600</td>\n",
       "      <td>0.007626</td>\n",
       "      <td>0.003203</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>1e+10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 10000000000.0, 'penalty': 'l2'}</td>\n",
       "      <td>0.822206</td>\n",
       "      <td>0.784412</td>\n",
       "      <td>0.881765</td>\n",
       "      <td>0.791457</td>\n",
       "      <td>0.851020</td>\n",
       "      <td>0.751108</td>\n",
       "      <td>0.679870</td>\n",
       "      <td>0.840526</td>\n",
       "      <td>0.807419</td>\n",
       "      <td>0.839787</td>\n",
       "      <td>0.804989</td>\n",
       "      <td>0.054721</td>\n",
       "      <td>21</td>\n",
       "      <td>0.821322</td>\n",
       "      <td>0.826327</td>\n",
       "      <td>0.814349</td>\n",
       "      <td>0.825371</td>\n",
       "      <td>0.819853</td>\n",
       "      <td>0.830289</td>\n",
       "      <td>0.835940</td>\n",
       "      <td>0.821019</td>\n",
       "      <td>0.823786</td>\n",
       "      <td>0.819061</td>\n",
       "      <td>0.823732</td>\n",
       "      <td>0.005827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time      param_C  \\\n",
       "0        0.007984      0.002946         0.003030        0.000725        1e-10   \n",
       "1        0.006980      0.001510         0.003417        0.001523        1e-10   \n",
       "2        0.005393      0.000826         0.002925        0.000744  1.12884e-09   \n",
       "3        0.007671      0.002829         0.003867        0.001962  1.12884e-09   \n",
       "4        0.006874      0.001249         0.002966        0.001159  1.27427e-08   \n",
       "5        0.007013      0.001414         0.002986        0.000729  1.27427e-08   \n",
       "6        0.005484      0.000700         0.002645        0.000551  1.43845e-07   \n",
       "7        0.008528      0.001776         0.003459        0.001153  1.43845e-07   \n",
       "8        0.005932      0.001200         0.002651        0.000666  1.62378e-06   \n",
       "9        0.008599      0.001901         0.002648        0.000228  1.62378e-06   \n",
       "10       0.005876      0.001072         0.002591        0.000452  1.83298e-05   \n",
       "11       0.010636      0.002454         0.003162        0.000742  1.83298e-05   \n",
       "12       0.013484      0.008109         0.004808        0.003271  0.000206914   \n",
       "13       0.043600      0.016137         0.008682        0.003248  0.000206914   \n",
       "14       0.025807      0.014994         0.004584        0.003985   0.00233572   \n",
       "15       0.023876      0.004288         0.003161        0.000815   0.00233572   \n",
       "16       0.074068      0.019794         0.004081        0.001784    0.0263665   \n",
       "17       0.029025      0.003877         0.002712        0.000214    0.0263665   \n",
       "18       0.611681      0.042185         0.002916        0.000608     0.297635   \n",
       "19       0.036989      0.004172         0.002994        0.000629     0.297635   \n",
       "20       2.756662      0.783771         0.003812        0.000664      3.35982   \n",
       "21       0.047447      0.004720         0.003416        0.001136      3.35982   \n",
       "22       1.653446      1.257749         0.003666        0.000687      37.9269   \n",
       "23       0.051638      0.005619         0.003376        0.001157      37.9269   \n",
       "24       1.832217      0.929227         0.003467        0.000494      428.133   \n",
       "25       0.112245      0.053259         0.007293        0.005013      428.133   \n",
       "26       1.781373      1.089044         0.003661        0.000686      4832.93   \n",
       "27       0.063216      0.010547         0.003003        0.000707      4832.93   \n",
       "28       1.589449      0.997271         0.003584        0.000386      54555.9   \n",
       "29       0.061244      0.008285         0.003444        0.001047      54555.9   \n",
       "30       1.575207      0.977138         0.003693        0.000780       615848   \n",
       "31       0.069957      0.009981         0.003136        0.000569       615848   \n",
       "32       1.821500      0.988195         0.003888        0.001020  6.95193e+06   \n",
       "33       0.069467      0.009397         0.003770        0.001200  6.95193e+06   \n",
       "34       1.875596      0.986159         0.004126        0.002261   7.8476e+07   \n",
       "35       0.069157      0.013579         0.003201        0.000660   7.8476e+07   \n",
       "36       1.604302      0.986650         0.003369        0.000152  8.85867e+08   \n",
       "37       0.068969      0.010186         0.003040        0.001055  8.85867e+08   \n",
       "38       1.880528      1.205054         0.004279        0.001824        1e+10   \n",
       "39       0.084600      0.007626         0.003203        0.000713        1e+10   \n",
       "\n",
       "   param_penalty                                          params  \\\n",
       "0             l1                   {'C': 1e-10, 'penalty': 'l1'}   \n",
       "1             l2                   {'C': 1e-10, 'penalty': 'l2'}   \n",
       "2             l1  {'C': 1.1288378916846883e-09, 'penalty': 'l1'}   \n",
       "3             l2  {'C': 1.1288378916846883e-09, 'penalty': 'l2'}   \n",
       "4             l1   {'C': 1.274274985703132e-08, 'penalty': 'l1'}   \n",
       "5             l2   {'C': 1.274274985703132e-08, 'penalty': 'l2'}   \n",
       "6             l1   {'C': 1.438449888287663e-07, 'penalty': 'l1'}   \n",
       "7             l2   {'C': 1.438449888287663e-07, 'penalty': 'l2'}   \n",
       "8             l1  {'C': 1.6237767391887209e-06, 'penalty': 'l1'}   \n",
       "9             l2  {'C': 1.6237767391887209e-06, 'penalty': 'l2'}   \n",
       "10            l1  {'C': 1.8329807108324338e-05, 'penalty': 'l1'}   \n",
       "11            l2  {'C': 1.8329807108324338e-05, 'penalty': 'l2'}   \n",
       "12            l1  {'C': 0.00020691380811147902, 'penalty': 'l1'}   \n",
       "13            l2  {'C': 0.00020691380811147902, 'penalty': 'l2'}   \n",
       "14            l1    {'C': 0.002335721469090121, 'penalty': 'l1'}   \n",
       "15            l2    {'C': 0.002335721469090121, 'penalty': 'l2'}   \n",
       "16            l1    {'C': 0.026366508987303555, 'penalty': 'l1'}   \n",
       "17            l2    {'C': 0.026366508987303555, 'penalty': 'l2'}   \n",
       "18            l1      {'C': 0.2976351441631313, 'penalty': 'l1'}   \n",
       "19            l2      {'C': 0.2976351441631313, 'penalty': 'l2'}   \n",
       "20            l1       {'C': 3.359818286283774, 'penalty': 'l1'}   \n",
       "21            l2       {'C': 3.359818286283774, 'penalty': 'l2'}   \n",
       "22            l1       {'C': 37.92690190732238, 'penalty': 'l1'}   \n",
       "23            l2       {'C': 37.92690190732238, 'penalty': 'l2'}   \n",
       "24            l1      {'C': 428.13323987193957, 'penalty': 'l1'}   \n",
       "25            l2      {'C': 428.13323987193957, 'penalty': 'l2'}   \n",
       "26            l1       {'C': 4832.930238571752, 'penalty': 'l1'}   \n",
       "27            l2       {'C': 4832.930238571752, 'penalty': 'l2'}   \n",
       "28            l1      {'C': 54555.947811685146, 'penalty': 'l1'}   \n",
       "29            l2      {'C': 54555.947811685146, 'penalty': 'l2'}   \n",
       "30            l1       {'C': 615848.2110660254, 'penalty': 'l1'}   \n",
       "31            l2       {'C': 615848.2110660254, 'penalty': 'l2'}   \n",
       "32            l1       {'C': 6951927.961775591, 'penalty': 'l1'}   \n",
       "33            l2       {'C': 6951927.961775591, 'penalty': 'l2'}   \n",
       "34            l1       {'C': 78475997.03514622, 'penalty': 'l1'}   \n",
       "35            l2       {'C': 78475997.03514622, 'penalty': 'l2'}   \n",
       "36            l1       {'C': 885866790.4100796, 'penalty': 'l1'}   \n",
       "37            l2       {'C': 885866790.4100796, 'penalty': 'l2'}   \n",
       "38            l1           {'C': 10000000000.0, 'penalty': 'l1'}   \n",
       "39            l2           {'C': 10000000000.0, 'penalty': 'l2'}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0            0.500000           0.500000           0.500000   \n",
       "1            0.674853           0.690147           0.650000   \n",
       "2            0.500000           0.500000           0.500000   \n",
       "3            0.679559           0.691765           0.652206   \n",
       "4            0.500000           0.500000           0.500000   \n",
       "5            0.701765           0.693529           0.662500   \n",
       "6            0.500000           0.500000           0.500000   \n",
       "7            0.705735           0.690294           0.667647   \n",
       "8            0.500000           0.500000           0.500000   \n",
       "9            0.712059           0.700441           0.661029   \n",
       "10           0.500000           0.500000           0.500000   \n",
       "11           0.696324           0.719853           0.664265   \n",
       "12           0.677353           0.675441           0.651176   \n",
       "13           0.710000           0.769853           0.717059   \n",
       "14           0.691176           0.729853           0.667794   \n",
       "15           0.723235           0.787059           0.781324   \n",
       "16           0.792353           0.776324           0.865000   \n",
       "17           0.780000           0.782353           0.857059   \n",
       "18           0.820882           0.795147           0.880735   \n",
       "19           0.819118           0.791176           0.885294   \n",
       "20           0.818529           0.793088           0.879853   \n",
       "21           0.819853           0.794559           0.882500   \n",
       "22           0.817059           0.793824           0.880000   \n",
       "23           0.818235           0.792794           0.880588   \n",
       "24           0.817059           0.793676           0.879853   \n",
       "25           0.820441           0.788971           0.880441   \n",
       "26           0.817059           0.793676           0.879853   \n",
       "27           0.822206           0.785294           0.880735   \n",
       "28           0.817059           0.793676           0.879853   \n",
       "29           0.822206           0.785441           0.880588   \n",
       "30           0.817059           0.793676           0.879853   \n",
       "31           0.822059           0.786471           0.881765   \n",
       "32           0.817059           0.793676           0.879853   \n",
       "33           0.822059           0.785441           0.880147   \n",
       "34           0.817059           0.793676           0.879853   \n",
       "35           0.822059           0.784412           0.879559   \n",
       "36           0.817059           0.793676           0.879853   \n",
       "37           0.820735           0.788235           0.880735   \n",
       "38           0.817059           0.793676           0.879853   \n",
       "39           0.822206           0.784412           0.881765   \n",
       "\n",
       "    split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0            0.500000           0.500000           0.500000   \n",
       "1            0.695537           0.638487           0.613361   \n",
       "2            0.500000           0.500000           0.500000   \n",
       "3            0.695093           0.632870           0.610996   \n",
       "4            0.500000           0.500000           0.500000   \n",
       "5            0.691250           0.610257           0.598286   \n",
       "6            0.500000           0.500000           0.500000   \n",
       "7            0.678096           0.580993           0.581732   \n",
       "8            0.500000           0.500000           0.500000   \n",
       "9            0.681791           0.588383           0.579959   \n",
       "10           0.500000           0.500000           0.500000   \n",
       "11           0.686816           0.611440           0.587201   \n",
       "12           0.668342           0.546409           0.604789   \n",
       "13           0.712681           0.672480           0.630949   \n",
       "14           0.697901           0.606267           0.592669   \n",
       "15           0.737363           0.766184           0.690364   \n",
       "16           0.771357           0.809636           0.698049   \n",
       "17           0.773278           0.814218           0.702779   \n",
       "18           0.789388           0.847473           0.748892   \n",
       "19           0.790127           0.838309           0.731156   \n",
       "20           0.791014           0.850133           0.754656   \n",
       "21           0.791014           0.849098           0.752734   \n",
       "22           0.791014           0.850281           0.755690   \n",
       "23           0.790866           0.849985           0.755247   \n",
       "24           0.790866           0.850281           0.755690   \n",
       "25           0.791605           0.849394           0.752882   \n",
       "26           0.790718           0.850281           0.755690   \n",
       "27           0.791457           0.850872           0.751552   \n",
       "28           0.790718           0.850281           0.755690   \n",
       "29           0.791309           0.850724           0.752439   \n",
       "30           0.790718           0.850281           0.755690   \n",
       "31           0.791457           0.850724           0.751995   \n",
       "32           0.790718           0.850281           0.755690   \n",
       "33           0.792492           0.851020           0.752291   \n",
       "34           0.790718           0.850281           0.755690   \n",
       "35           0.791162           0.850724           0.751995   \n",
       "36           0.790718           0.850281           0.755690   \n",
       "37           0.791753           0.850724           0.751108   \n",
       "38           0.790718           0.850281           0.755690   \n",
       "39           0.791457           0.851020           0.751108   \n",
       "\n",
       "    split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0            0.500000           0.500000           0.500000   \n",
       "1            0.464972           0.566066           0.629027   \n",
       "2            0.500000           0.500000           0.500000   \n",
       "3            0.462459           0.565622           0.628289   \n",
       "4            0.500000           0.500000           0.500000   \n",
       "5            0.449897           0.562666           0.625185   \n",
       "6            0.500000           0.500000           0.500000   \n",
       "7            0.438368           0.536210           0.615726   \n",
       "8            0.500000           0.500000           0.500000   \n",
       "9            0.436890           0.533993           0.606562   \n",
       "10           0.500000           0.500000           0.500000   \n",
       "11           0.451670           0.547000           0.608631   \n",
       "12           0.455365           0.545965           0.609666   \n",
       "13           0.497340           0.623116           0.638191   \n",
       "14           0.459503           0.535028           0.604345   \n",
       "15           0.573160           0.761159           0.712977   \n",
       "16           0.628584           0.814957           0.773426   \n",
       "17           0.633018           0.821904           0.773278   \n",
       "18           0.677210           0.850133           0.804316   \n",
       "19           0.672184           0.842004           0.801212   \n",
       "20           0.687703           0.850724           0.806533   \n",
       "21           0.687999           0.849985           0.804759   \n",
       "22           0.688147           0.850429           0.806533   \n",
       "23           0.687703           0.849690           0.805794   \n",
       "24           0.688147           0.850429           0.806533   \n",
       "25           0.685930           0.845551           0.806533   \n",
       "26           0.688147           0.850429           0.806533   \n",
       "27           0.684008           0.842152           0.807567   \n",
       "28           0.688147           0.850429           0.806533   \n",
       "29           0.684452           0.847916           0.808454   \n",
       "30           0.688147           0.850429           0.806533   \n",
       "31           0.684304           0.845995           0.805941   \n",
       "32           0.688147           0.850429           0.806533   \n",
       "33           0.680018           0.840822           0.806089   \n",
       "34           0.688147           0.850429           0.806533   \n",
       "35           0.682383           0.840231           0.808750   \n",
       "36           0.688147           0.850429           0.806533   \n",
       "37           0.680757           0.840970           0.805941   \n",
       "38           0.688147           0.850429           0.806533   \n",
       "39           0.679870           0.840526           0.807419   \n",
       "\n",
       "    split9_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0            0.500000         0.500000        0.000000               35   \n",
       "1            0.634348         0.625739        0.064657               27   \n",
       "2            0.500000         0.500000        0.000000               35   \n",
       "3            0.632131         0.625163        0.065827               28   \n",
       "4            0.500000         0.500000        0.000000               35   \n",
       "5            0.622081         0.621824        0.071941               29   \n",
       "6            0.500000         0.500000        0.000000               35   \n",
       "7            0.604936         0.610074        0.077574               33   \n",
       "8            0.500000         0.500000        0.000000               35   \n",
       "9            0.611440         0.611358        0.079669               32   \n",
       "10           0.500000         0.500000        0.000000               35   \n",
       "11           0.630801         0.620494        0.075683               31   \n",
       "12           0.594591         0.602993        0.067627               34   \n",
       "13           0.684156         0.665668        0.070828               26   \n",
       "14           0.629914         0.621541        0.077284               30   \n",
       "15           0.765740         0.729900        0.059988               25   \n",
       "16           0.834614         0.776475        0.064875               24   \n",
       "17           0.829589         0.776786        0.062337               23   \n",
       "18           0.841709         0.805623        0.055659               16   \n",
       "19           0.843187         0.801416        0.058275               22   \n",
       "20           0.837422         0.806996        0.052486               11   \n",
       "21           0.840822         0.807364        0.053046                1   \n",
       "22           0.837422         0.807070        0.052242                2   \n",
       "23           0.837570         0.806878        0.052449               12   \n",
       "24           0.837422         0.807025        0.052230                3   \n",
       "25           0.838900         0.806096        0.052920               14   \n",
       "26           0.837422         0.807011        0.052234                4   \n",
       "27           0.838457         0.805461        0.053571               17   \n",
       "28           0.837422         0.807011        0.052234                4   \n",
       "29           0.840083         0.806391        0.053870               13   \n",
       "30           0.837422         0.807011        0.052234                4   \n",
       "31           0.839787         0.806081        0.053897               15   \n",
       "32           0.837422         0.807011        0.052234                4   \n",
       "33           0.839787         0.805048        0.054293               20   \n",
       "34           0.837422         0.807011        0.052234                4   \n",
       "35           0.839787         0.805136        0.053717               18   \n",
       "36           0.837422         0.807011        0.052234                4   \n",
       "37           0.839787         0.805107        0.054190               19   \n",
       "38           0.837422         0.807011        0.052234                4   \n",
       "39           0.839787         0.804989        0.054721               21   \n",
       "\n",
       "    split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0             0.500000            0.500000            0.500000   \n",
       "1             0.623128            0.621057            0.626077   \n",
       "2             0.500000            0.500000            0.500000   \n",
       "3             0.622364            0.621001            0.625685   \n",
       "4             0.500000            0.500000            0.500000   \n",
       "5             0.616388            0.617623            0.621436   \n",
       "6             0.500000            0.500000            0.500000   \n",
       "7             0.604838            0.607090            0.610869   \n",
       "8             0.500000            0.500000            0.500000   \n",
       "9             0.607907            0.608514            0.614479   \n",
       "10            0.500000            0.500000            0.500000   \n",
       "11            0.628514            0.621815            0.629026   \n",
       "12            0.597305            0.599752            0.600064   \n",
       "13            0.684038            0.675348            0.676806   \n",
       "14            0.640650            0.632367            0.622729   \n",
       "15            0.745732            0.742078            0.737704   \n",
       "16            0.785617            0.792043            0.778173   \n",
       "17            0.787321            0.791985            0.779695   \n",
       "18            0.819068            0.823668            0.812125   \n",
       "19            0.812971            0.817464            0.805859   \n",
       "20            0.820333            0.824647            0.813534   \n",
       "21            0.820249            0.824765            0.813343   \n",
       "22            0.820409            0.824687            0.813674   \n",
       "23            0.820560            0.825095            0.813709   \n",
       "24            0.820466            0.824701            0.813654   \n",
       "25            0.821144            0.826170            0.814312   \n",
       "26            0.820467            0.824700            0.813654   \n",
       "27            0.821340            0.826484            0.814360   \n",
       "28            0.820467            0.824700            0.813654   \n",
       "29            0.821317            0.826447            0.814276   \n",
       "30            0.820467            0.824700            0.813654   \n",
       "31            0.821328            0.826482            0.814327   \n",
       "32            0.820467            0.824700            0.813654   \n",
       "33            0.821286            0.826475            0.814205   \n",
       "34            0.820467            0.824700            0.813654   \n",
       "35            0.821324            0.826318            0.813616   \n",
       "36            0.820467            0.824700            0.813654   \n",
       "37            0.821140            0.826375            0.814418   \n",
       "38            0.820467            0.824700            0.813654   \n",
       "39            0.821322            0.826327            0.814349   \n",
       "\n",
       "    split3_train_score  split4_train_score  split5_train_score  \\\n",
       "0             0.500000            0.500000            0.500000   \n",
       "1             0.620984            0.626527            0.629457   \n",
       "2             0.500000            0.500000            0.500000   \n",
       "3             0.620536            0.626606            0.629438   \n",
       "4             0.500000            0.500000            0.500000   \n",
       "5             0.617649            0.625868            0.627256   \n",
       "6             0.500000            0.500000            0.500000   \n",
       "7             0.608446            0.618108            0.619221   \n",
       "8             0.500000            0.500000            0.500000   \n",
       "9             0.611031            0.621278            0.621919   \n",
       "10            0.500000            0.500000            0.500000   \n",
       "11            0.627730            0.635144            0.634329   \n",
       "12            0.598996            0.608058            0.605577   \n",
       "13            0.681107            0.678877            0.683331   \n",
       "14            0.641610            0.629721            0.634690   \n",
       "15            0.744646            0.739129            0.749015   \n",
       "16            0.791066            0.787476            0.800062   \n",
       "17            0.791425            0.787416            0.799320   \n",
       "18            0.822438            0.816893            0.827154   \n",
       "19            0.816188            0.811441            0.822333   \n",
       "20            0.823957            0.818356            0.828981   \n",
       "21            0.823712            0.818321            0.828712   \n",
       "22            0.824016            0.818294            0.829104   \n",
       "23            0.824247            0.818538            0.829195   \n",
       "24            0.823983            0.818314            0.829125   \n",
       "25            0.824681            0.819250            0.829918   \n",
       "26            0.823988            0.818307            0.829129   \n",
       "27            0.825377            0.819597            0.830197   \n",
       "28            0.823990            0.818307            0.829129   \n",
       "29            0.825424            0.819635            0.829901   \n",
       "30            0.823990            0.818307            0.829129   \n",
       "31            0.825378            0.819853            0.830071   \n",
       "32            0.823990            0.818307            0.829129   \n",
       "33            0.825251            0.819859            0.829960   \n",
       "34            0.823990            0.818307            0.829129   \n",
       "35            0.824810            0.819826            0.830060   \n",
       "36            0.823990            0.818307            0.829129   \n",
       "37            0.824874            0.819873            0.830293   \n",
       "38            0.823990            0.818307            0.829129   \n",
       "39            0.825371            0.819853            0.830289   \n",
       "\n",
       "    split6_train_score  split7_train_score  split8_train_score  \\\n",
       "0             0.500000            0.500000            0.500000   \n",
       "1             0.645975            0.634794            0.628349   \n",
       "2             0.500000            0.500000            0.500000   \n",
       "3             0.645569            0.634433            0.627912   \n",
       "4             0.500000            0.500000            0.500000   \n",
       "5             0.642545            0.631262            0.624454   \n",
       "6             0.500000            0.500000            0.500000   \n",
       "7             0.632460            0.622303            0.615126   \n",
       "8             0.500000            0.500000            0.500000   \n",
       "9             0.635881            0.625717            0.618944   \n",
       "10            0.500000            0.500000            0.500000   \n",
       "11            0.650334            0.639969            0.635286   \n",
       "12            0.617500            0.609197            0.603981   \n",
       "13            0.695976            0.680995            0.686076   \n",
       "14            0.664220            0.636515            0.637153   \n",
       "15            0.757674            0.738650            0.745703   \n",
       "16            0.804291            0.786848            0.790179   \n",
       "17            0.803386            0.786707            0.790449   \n",
       "18            0.832388            0.816735            0.820817   \n",
       "19            0.827307            0.811299            0.814888   \n",
       "20            0.833905            0.818562            0.822719   \n",
       "21            0.833767            0.818485            0.822252   \n",
       "22            0.834049            0.818657            0.822686   \n",
       "23            0.834273            0.819010            0.822872   \n",
       "24            0.834049            0.818642            0.822690   \n",
       "25            0.835466            0.820427            0.822693   \n",
       "26            0.834058            0.818657            0.822690   \n",
       "27            0.835678            0.820968            0.823814   \n",
       "28            0.834060            0.818653            0.822690   \n",
       "29            0.835579            0.819963            0.823841   \n",
       "30            0.834060            0.818653            0.822690   \n",
       "31            0.835587            0.820351            0.822996   \n",
       "32            0.834060            0.818653            0.822690   \n",
       "33            0.835938            0.820930            0.822875   \n",
       "34            0.834060            0.818653            0.822690   \n",
       "35            0.835960            0.821003            0.823825   \n",
       "36            0.834060            0.818653            0.822690   \n",
       "37            0.835982            0.820966            0.823580   \n",
       "38            0.834060            0.818653            0.822690   \n",
       "39            0.835940            0.821019            0.823786   \n",
       "\n",
       "    split9_train_score  mean_train_score  std_train_score  \n",
       "0             0.500000          0.500000         0.000000  \n",
       "1             0.627686          0.628403         0.007050  \n",
       "2             0.500000          0.500000         0.000000  \n",
       "3             0.627342          0.628089         0.007044  \n",
       "4             0.500000          0.500000         0.000000  \n",
       "5             0.625110          0.624959         0.007406  \n",
       "6             0.500000          0.500000         0.000000  \n",
       "7             0.615793          0.615425         0.007813  \n",
       "8             0.500000          0.500000         0.000000  \n",
       "9             0.617709          0.618338         0.008112  \n",
       "10            0.500000          0.500000         0.000000  \n",
       "11            0.631848          0.633399         0.007410  \n",
       "12            0.605561          0.604599         0.005748  \n",
       "13            0.681664          0.682422         0.005468  \n",
       "14            0.628504          0.636816         0.010635  \n",
       "15            0.739852          0.744018         0.005756  \n",
       "16            0.783933          0.789969         0.007232  \n",
       "17            0.784226          0.790193         0.006604  \n",
       "18            0.816451          0.820774         0.005608  \n",
       "19            0.810019          0.814977         0.005929  \n",
       "20            0.818061          0.822306         0.005621  \n",
       "21            0.817966          0.822157         0.005604  \n",
       "22            0.818108          0.822368         0.005639  \n",
       "23            0.818325          0.822582         0.005654  \n",
       "24            0.818105          0.822373         0.005642  \n",
       "25            0.819039          0.823310         0.005749  \n",
       "26            0.818108          0.822376         0.005644  \n",
       "27            0.819076          0.823689         0.005786  \n",
       "28            0.818108          0.822376         0.005644  \n",
       "29            0.819017          0.823540         0.005803  \n",
       "30            0.818108          0.822376         0.005644  \n",
       "31            0.819045          0.823542         0.005778  \n",
       "32            0.818108          0.822376         0.005644  \n",
       "33            0.819030          0.823581         0.005829  \n",
       "34            0.818108          0.822376         0.005644  \n",
       "35            0.819041          0.823578         0.005916  \n",
       "36            0.818108          0.822376         0.005644  \n",
       "37            0.819041          0.823654         0.005826  \n",
       "38            0.818108          0.822376         0.005644  \n",
       "39            0.819061          0.823732         0.005827  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameter tuning on Logistic regression\n",
    "skf = StratifiedKFold(n_splits = 10, random_state = 600)\n",
    "\n",
    "param_grid = {'penalty' : ['l1', 'l2'],\n",
    "              'C' : np.logspace(-10, 10, 20)\n",
    "              }\n",
    "\n",
    "opt_model = GridSearchCV(log_model,\n",
    "                         param_grid,\n",
    "                         cv=skf,\n",
    "                         scoring='roc_auc',\n",
    "                         return_train_score=True)\n",
    "\n",
    "opt_model.fit(X_train,y_train)\n",
    "\n",
    "pd.DataFrame(opt_model.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values of the optimised hyperparameters\n",
      "for the best model found:\n",
      " {'C': 3.359818286283774, 'penalty': 'l2'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8073644343094155"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Values of the optimised hyperparameters\\nfor the best model found:\\n',opt_model.best_params_)\n",
    "opt_model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest Classifier seems to be the best performing model out of the three. However, since the difference in roc_score is not massive we'll adopt Decision Tree as our final model due to higher interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Winning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating the prevalence in this context based on this article:\n",
    "https://customergauge.com/benchmarks/blog/telecommunications-nps-benchmarks-and-cx-trends\n",
    "\n",
    "Prevalence Rate calculated as people actively churning is at **22%** in the US Telco sector. This falls just slightly higher than the figures found on our dataset (circa 14%). We are assuming that the Syrian telco market has a similar churn rate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the underlying costs for TP, FP, TN and FN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average cost for telco prospecting in the US is around 315 US dollars made up of marketing initiatives dedicated to make our prospects convert. Retaining an existing customer (and generally speaking keeping them satisfied) is roughly 5 times cheaper with an estimate of $60 per customer. Below costs associated to each scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FN** = That would be when the model predicted the user wouldn't churn when they actually would. After some research we have found that the cost per acquisition of a new customer is around $315. This is the most expensive scenario and what Syriatel wants to avoid the most.\n",
    "\n",
    "**TP** = In this case, model would predict that the customer is churning when they actually would and we need to spend $60 to keep them happy.\n",
    "\n",
    "**FP** = Model is predicting that the customer would churn but in reality, they wouldn't. We still spend $60 to keep them happy.\n",
    "\n",
    "**TN** = This is the scenario with less impact as we are corretly identifying happy customers ($0).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The m (Metz) parameter that we need to calculate the ideal threashold is given by the following formula:\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metz parameter is 0.8342245989304813 \n"
     ]
    }
   ],
   "source": [
    "prevalence = .22\n",
    "FN = 315\n",
    "TP = 60\n",
    "FP = 60\n",
    "TN = 0\n",
    "\n",
    "m = ((1.0 - prevalence)/(prevalence)) * ((60-0)/(315-60))\n",
    "print(f'Metz parameter is {m} ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying optimal threshold given our Metz value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8870633450563439"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# refitting my best model with optimal max_depth 11 and min_sample_leafs 15\n",
    "model_tree_f = DecisionTreeClassifier(max_depth=11,min_samples_leaf=10,random_state=39, class_weight = 'balanced' )\n",
    "# fitting the model\n",
    "model_tree_f.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_hat_decision_tree = model_tree_f.predict_proba(X_test)[:,1]\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_hat_decision_tree)\n",
    "\n",
    "\n",
    "# good stats for the test environment\n",
    "roc_auc_score(y_test, y_hat_decision_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 2.0),\n",
       " (0.4256000023039628, 1.0),\n",
       " (0.47455105125501174, 0.9813973846911419),\n",
       " (0.535541265653147, 0.9670063076176613),\n",
       " (0.6044979113137532, 0.9555419953798544),\n",
       " (0.6515021117258745, 0.9425714478751436),\n",
       " (0.6705342841659679, 0.9318682786720993),\n",
       " (0.6845202981519819, 0.9036499659941056),\n",
       " (0.7165650603086254, 0.8913807424445722),\n",
       " (0.7186909459543134, 0.8865658362989324),\n",
       " (0.723916141515153, 0.8724282408854981),\n",
       " (0.7299357242386962, 0.8542648949849978),\n",
       " (0.7192280572745944, 0.7885930699225594),\n",
       " (0.7026798446937097, 0.7786170074228415),\n",
       " (0.6978127233463907, 0.6614669764354464),\n",
       " (0.6890519049212165, 0.626138862708137),\n",
       " (0.686131632112825, 0.6151867476077785),\n",
       " (0.6765764265249473, 0.5943930808231435),\n",
       " (0.6806491607095629, 0.5943930808231433),\n",
       " (0.6757820393622439, 0.5657110417258019),\n",
       " (0.6998603702564167, 0.5567557500698389),\n",
       " (0.7120785728102634, 0.5396696452748444),\n",
       " (0.7062380271934806, 0.5396696452748443),\n",
       " (0.7103107613780961, 0.5159202692208128),\n",
       " (0.6958884344428994, 0.39441915693647334),\n",
       " (0.6939415859039718, 0.3695531244205451),\n",
       " (0.6435025609986142, 0.3476364904936333),\n",
       " (0.6357151668429037, 0.3281738844063889),\n",
       " (0.1657754010695187, 0.0)]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the \n",
    "fm_list = (tpr_test) -(m*(fpr_test))\n",
    "list(zip(fm_list.tolist(), thresholds_test.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest FM is 0.7120 which corresponds to a threshold of **0.53**. We will now use the latter as our ideal threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Plotting Confusion Matrix for selected threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34763649, 0.        , 1.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.98139738, 0.        ,\n",
       "       0.77861701, 0.        , 1.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.51592027, 0.        ,\n",
       "       0.        , 0.32817388, 0.96700631, 0.        , 0.        ,\n",
       "       0.87242824, 0.87242824, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "       0.        , 0.88656584, 0.        , 0.55675575, 0.        ,\n",
       "       0.        , 0.90364997, 0.955542  , 0.        , 0.        ,\n",
       "       0.34763649, 1.        , 0.        , 0.        , 0.34763649,\n",
       "       0.        , 0.        , 0.34763649, 0.        , 0.        ,\n",
       "       0.85426489, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "       0.55675575, 0.34763649, 0.        , 1.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "       0.78859307, 0.53966965, 0.        , 0.        , 0.        ,\n",
       "       0.34763649, 0.        , 0.        , 0.        , 1.        ,\n",
       "       0.        , 0.98139738, 0.98139738, 0.        , 0.        ,\n",
       "       0.98139738, 0.89138074, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.78859307,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.53966965, 0.        , 0.        ,\n",
       "       0.77861701, 0.        , 0.        , 0.96700631, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.89138074,\n",
       "       0.53966965, 1.        , 0.89138074, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.78859307, 0.62613886, 0.34763649,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.53966965, 0.        , 0.        , 1.        , 0.        ,\n",
       "       0.39441916, 0.39441916, 0.        , 0.        , 1.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.34763649, 0.59439308, 0.56571104, 0.        ,\n",
       "       0.77861701, 0.39441916, 0.        , 0.39441916, 0.96700631,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.32817388,\n",
       "       0.        , 0.        , 0.53966965, 0.96700631, 0.89138074,\n",
       "       0.        , 0.        , 0.        , 0.34763649, 0.        ,\n",
       "       0.        , 1.        , 1.        , 0.94257145, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.59439308, 0.        ,\n",
       "       0.        , 0.94257145, 0.        , 0.        , 0.        ,\n",
       "       0.39441916, 0.        , 0.34763649, 0.        , 0.        ,\n",
       "       0.        , 0.39441916, 0.61518675, 0.        , 0.        ,\n",
       "       0.34763649, 0.        , 0.59439308, 0.        , 0.94257145,\n",
       "       0.        , 0.        , 0.94257145, 0.55675575, 0.        ,\n",
       "       0.        , 0.        , 0.96700631, 0.88656584, 0.        ,\n",
       "       0.77861701, 0.34763649, 0.66146698, 0.59439308, 1.        ,\n",
       "       0.        , 0.        , 0.        , 0.34763649, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.62613886, 0.        , 0.        , 0.        , 0.        ,\n",
       "       1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.53966965, 0.        , 0.        , 0.        , 0.53966965,\n",
       "       0.        , 0.        , 0.        , 0.51592027, 0.        ,\n",
       "       0.        , 0.34763649, 0.        , 1.        , 0.93186828,\n",
       "       0.        , 0.        , 1.        , 0.39441916, 0.        ,\n",
       "       1.        , 0.        , 1.        , 0.34763649, 0.955542  ,\n",
       "       0.        , 0.36955312, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.62613886, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.34763649, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "       0.        , 0.34763649, 0.        , 0.        , 0.56571104,\n",
       "       1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 1.        , 0.        , 1.        ,\n",
       "       0.        , 0.34763649, 0.        , 0.        , 0.        ,\n",
       "       1.        , 0.56571104, 0.87242824, 0.        , 0.34763649,\n",
       "       0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.55675575, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.34763649, 0.        , 0.955542  , 0.        ,\n",
       "       0.        , 0.98139738, 0.        , 0.        , 0.        ,\n",
       "       1.        , 0.        , 0.        , 0.        , 0.93186828,\n",
       "       0.        , 0.        , 0.96700631, 0.78859307, 0.        ,\n",
       "       0.        , 0.56571104, 0.        , 0.        , 0.        ,\n",
       "       0.77861701, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.59439308, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.39441916, 0.        , 0.        , 0.93186828, 0.        ,\n",
       "       0.        , 0.        , 0.        , 1.        , 0.94257145,\n",
       "       0.34763649, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.955542  , 0.93186828, 1.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.34763649, 0.89138074, 0.78859307,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       1.        , 0.        , 0.59439308, 0.98139738, 0.34763649,\n",
       "       1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.59439308, 0.34763649, 0.59439308,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.34763649, 0.        , 1.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.34763649, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.32817388, 0.        ,\n",
       "       0.34763649, 0.        , 0.66146698, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.34763649, 1.        ,\n",
       "       0.87242824, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.87242824, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.77861701, 0.        , 0.87242824,\n",
       "       1.        , 0.34763649, 0.        , 0.34763649, 0.        ,\n",
       "       0.34763649, 0.        , 0.53966965, 0.        , 0.        ,\n",
       "       0.59439308, 0.59439308, 0.        , 1.        , 0.        ,\n",
       "       0.        , 1.        , 0.        , 0.53966965, 0.        ,\n",
       "       0.32817388, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.53966965, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.93186828, 0.        , 0.        ,\n",
       "       0.39441916, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.59439308, 0.        ,\n",
       "       0.        , 0.87242824, 0.        , 0.        , 0.77861701,\n",
       "       0.        , 0.        , 0.77861701, 0.        , 0.78859307,\n",
       "       0.        , 0.        , 0.        , 0.39441916, 0.66146698,\n",
       "       0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.77861701, 0.        , 0.        , 0.39441916, 0.62613886,\n",
       "       0.        , 0.        , 0.34763649, 0.34763649, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.56571104,\n",
       "       1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.87242824, 0.34763649, 0.        , 0.59439308, 0.        ,\n",
       "       1.        , 0.        , 0.        , 0.34763649, 0.        ,\n",
       "       0.34763649, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.94257145, 0.39441916, 0.        ,\n",
       "       0.78859307, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.955542  , 0.        , 0.96700631,\n",
       "       0.        , 0.        , 0.        , 0.59439308, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.59439308,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.955542  ,\n",
       "       0.        , 0.77861701, 0.39441916, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.34763649,\n",
       "       0.53966965, 0.89138074, 0.        , 0.77861701, 1.        ,\n",
       "       0.32817388, 0.        , 0.        , 0.        , 1.        ,\n",
       "       1.        , 0.        , 1.        , 1.        , 0.        ,\n",
       "       0.66146698, 0.        , 0.39441916, 0.        , 0.55675575,\n",
       "       1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 1.        , 0.34763649, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.34763649, 0.        , 0.        , 0.34763649,\n",
       "       0.        , 0.955542  , 0.34763649, 0.34763649, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.955542  , 0.        ,\n",
       "       0.        , 0.        , 0.87242824, 0.88656584, 0.        ,\n",
       "       0.        , 0.34763649, 0.        , 0.        , 0.        ,\n",
       "       0.59439308, 0.        , 0.94257145, 0.        , 0.88656584,\n",
       "       0.        , 0.        , 0.88656584, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "       0.77861701, 1.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.51592027, 0.        , 0.        ,\n",
       "       0.62613886, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 1.        , 0.66146698, 0.        , 0.53966965,\n",
       "       0.955542  , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.96700631, 0.        , 0.        , 0.        , 0.51592027,\n",
       "       0.        , 0.        , 0.34763649, 1.        , 0.53966965,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.39441916, 0.        , 0.55675575, 0.        ,\n",
       "       0.34763649, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.59439308, 0.        ,\n",
       "       0.77861701, 0.34763649, 0.96700631, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.39441916, 0.77861701, 0.34763649,\n",
       "       1.        , 0.        , 0.        , 0.96700631, 0.        ,\n",
       "       0.        , 0.34763649, 0.55675575, 0.62613886, 0.        ,\n",
       "       0.34763649, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.59439308, 0.        ,\n",
       "       0.        , 0.59439308, 0.        , 0.        , 0.        ,\n",
       "       0.        , 1.        , 0.34763649, 0.        , 0.        ,\n",
       "       0.        , 0.        , 1.        , 1.        , 0.        ,\n",
       "       0.77861701, 0.59439308, 0.        , 0.53966965, 0.        ,\n",
       "       0.        , 0.90364997, 0.        , 0.34763649, 0.96700631,\n",
       "       0.34763649, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.85426489,\n",
       "       0.        , 0.78859307, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.62613886, 0.        ,\n",
       "       0.        , 0.        , 0.87242824, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.78859307, 0.        , 0.39441916,\n",
       "       0.53966965, 0.59439308, 0.        , 0.34763649, 0.        ,\n",
       "       0.32817388, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.39441916, 0.        , 0.        , 0.39441916, 0.        ,\n",
       "       1.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.94257145, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.34763649, 0.        ,\n",
       "       0.34763649, 0.        , 0.89138074, 0.32817388, 0.        ,\n",
       "       0.59439308, 0.        , 0.        , 0.        , 0.955542  ,\n",
       "       0.        , 0.        , 0.53966965, 0.53966965, 0.59439308,\n",
       "       0.        , 0.        , 0.61518675, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.34763649, 0.39441916, 0.        , 0.39441916,\n",
       "       0.        , 0.        , 0.        , 0.55675575, 0.        ,\n",
       "       0.        , 0.        , 0.34763649, 0.61518675, 0.        ,\n",
       "       0.        , 1.        , 1.        , 0.        , 0.        ,\n",
       "       0.34763649, 0.        , 0.32817388, 1.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.94257145, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.62613886, 0.98139738, 0.        , 0.34763649,\n",
       "       0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.36955312, 0.        ,\n",
       "       0.        , 1.        , 0.34763649, 0.955542  , 0.        ,\n",
       "       0.        , 0.77861701, 0.87242824, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.53966965, 0.        ,\n",
       "       0.        , 0.        , 0.89138074, 0.88656584, 0.77861701,\n",
       "       0.        , 0.        , 0.62613886, 0.39441916, 0.        ,\n",
       "       0.        , 0.78859307, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.39441916, 0.78859307, 1.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a new list with threshold 0.53 separating churn 1 and non-churn 0\n",
    "probs_list_test = model_tree_f.predict_proba(X_test)[:,1]\n",
    "\n",
    "final_res =[]\n",
    "for x in probs_list_test:\n",
    "    if x > 0.5396696452748444:\n",
    "        final_res.append(1)\n",
    "    else:\n",
    "        final_res.append(0)\n",
    "final_res\n",
    "len(final_res)\n",
    "probs_list_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[757, 100],\n",
       "       [ 29, 114]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, final_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.871\n",
      "ROC_score  0.8870633450563439\n",
      "Precision  0.5327102803738317\n",
      "Recall or TPR  0.7972027972027972\n",
      "F1 score  0.6386554621848739\n"
     ]
    }
   ],
   "source": [
    "accuracy = print('Accuracy Score', accuracy_score(y_test, final_res))\n",
    "roc_score = print('ROC_score ', roc_auc_score(y_test, y_hat_decision_tree))\n",
    "precision = print('Precision ', precision_score(y_test, final_res))\n",
    "recall= print('Recall or TPR ', recall_score(y_test, final_res))\n",
    "f1__score = print('F1 score ', f1_score(y_test, final_res))\n",
    "\n",
    "# power\n",
    "# alpha\n",
    "# precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.11668611435239207\n",
      "power =  0.7972027972027972\n",
      "precision =  0.5327102803738317\n",
      "accuracy =  0.871\n"
     ]
    }
   ],
   "source": [
    "alpha = 100/ (757 + 100)\n",
    "print(\"alpha = \", alpha)\n",
    "\n",
    "power = 114/(114 + 29)\n",
    "print(\"power = \", power)\n",
    "\n",
    "precision = 114/(114+ 100)\n",
    "print(\"precision = \", precision)\n",
    "\n",
    "accuracy = (114 + 757 )/(757+ 114 + 100+ 29)\n",
    "print(\"accuracy = \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) The value Alpha is the probability of our model saying that someone will churn when they actually wouldn't. That happens roughly once out of ten.\n",
    "\n",
    "2) Power describes how capable our model is to identify someone who will churn and it will be 8 times out of 10.\n",
    "\n",
    "3) Everytime our model predicts someone to be likely to churn, it will be correct half of the times. However we will systematically be saving more money by being safe rather than sorry. Being wrong here would just cost 60 dollars while not being able to recognise someone about to churn would incur in 5 times as much marketing spend. Luckily enough that happens only about two customers in ten.\n",
    "\n",
    "4) Also, overall the model will be able to identify 87% of the times both customers who would and wold not churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01392359, 0.19217315, 0.        , 0.02754788, 0.061117  ,\n",
       "       0.02099324, 0.1872362 , 0.03649239, 0.01657457, 0.05054225,\n",
       "       0.02076185, 0.0352393 , 0.01564582, 0.02925835, 0.07224612,\n",
       "       0.01495212, 0.20529619])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tree_f.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'account length': 0.013923592690314552,\n",
       " 'international plan': 0.19217314906561553,\n",
       " 'voice mail plan': 0.0,\n",
       " 'number vmail messages': 0.02754787555574603,\n",
       " 'total day minutes': 0.06111699884182065,\n",
       " 'total day calls': 0.020993236481241094,\n",
       " 'total day charge': 0.18723619644866568,\n",
       " 'total eve minutes': 0.03649239100577808,\n",
       " 'total eve calls': 0.01657456600540585,\n",
       " 'total eve charge': 0.05054224527350006,\n",
       " 'total night minutes': 0.020761849350970713,\n",
       " 'total night calls': 0.035239295139192814,\n",
       " 'total night charge': 0.015645815157415033,\n",
       " 'total intl minutes': 0.02925835474357247,\n",
       " 'total intl calls': 0.07224611932874382,\n",
       " 'total intl charge': 0.014952121905480698,\n",
       " 'customer service calls': 0.20529619300653706}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_coef = dict(zip(df.columns, model_tree_f.feature_importances_ ))\n",
    "all_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['account length',\n",
       " 'international plan',\n",
       " 'voice mail plan',\n",
       " 'number vmail messages',\n",
       " 'total day minutes',\n",
       " 'total day calls',\n",
       " 'total day charge',\n",
       " 'total eve minutes',\n",
       " 'total eve calls',\n",
       " 'total eve charge',\n",
       " 'total night minutes',\n",
       " 'total night calls',\n",
       " 'total night charge',\n",
       " 'total intl minutes',\n",
       " 'total intl calls',\n",
       " 'total intl charge',\n",
       " 'customer service calls']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_coef = dict(zip(df.columns, model_tree_f.feature_importances_ ))\n",
    "x = list(df.columns)\n",
    "x = x[:-1]\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.013924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.192173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.027548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.061117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.020993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.187236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.036492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.016575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.050542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.020762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.035239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.015646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.029258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.072246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.014952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.205296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature importance\n",
       "0             0.013924\n",
       "1             0.192173\n",
       "2             0.000000\n",
       "3             0.027548\n",
       "4             0.061117\n",
       "5             0.020993\n",
       "6             0.187236\n",
       "7             0.036492\n",
       "8             0.016575\n",
       "9             0.050542\n",
       "10            0.020762\n",
       "11            0.035239\n",
       "12            0.015646\n",
       "13            0.029258\n",
       "14            0.072246\n",
       "15            0.014952\n",
       "16            0.205296"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_feature_importance = pd.DataFrame(model_tree_f.feature_importances_, columns=['feature importance'])\n",
    "df_feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>account length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>international plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>voice mail plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>number vmail messages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>total day minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>total day calls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>total day charge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>total eve minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>total eve calls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>total eve charge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>total night minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>total night calls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>total night charge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>total intl minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>total intl calls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>total intl charge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>customer service calls</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature\n",
       "0           account length\n",
       "1       international plan\n",
       "2          voice mail plan\n",
       "3    number vmail messages\n",
       "4        total day minutes\n",
       "5          total day calls\n",
       "6         total day charge\n",
       "7        total eve minutes\n",
       "8          total eve calls\n",
       "9         total eve charge\n",
       "10     total night minutes\n",
       "11       total night calls\n",
       "12      total night charge\n",
       "13      total intl minutes\n",
       "14        total intl calls\n",
       "15       total intl charge\n",
       "16  customer service calls"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_ = pd.DataFrame(x, columns=['feature'])\n",
    "second_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
